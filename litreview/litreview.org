#+TITLE: \textbf{Addressing the Perceptual Limitations of Cortical Implants for Restoring Vision}
#+AUTHOR: {{{NEWLINE}}}\textbf{Student:} Jamin Wu {{{NEWLINE}}} \textbf{Student ID:} 27025861 {{{NEWLINE}}} {{{NEWLINE}}} \textbf{Supervisor:} Dr Yan Tat Wong {{{NEWLINE}}} \textbf{Co-Supervisor:} Dr Nicholas Price {{{NEWLINE}}} {{{NEWLINE}}} Department of Physiology {{{NEWLINE}}} Department of Electrical & Computer Systems Engineering {{{NEWLINE}}} \textbf{School of Biomedical Sciences, Monash University} {{{NEWLINE}}} {{{NEWLINE}}} Word Count: 7149 words
#+OPTIONS: date:nil toc:nil
#+LATEX_HEADER: \usepackage{todonotes}
#+LATEX_HEADER: \usepackage{helvet}
#+LATEX_HEADER: \usepackage{gensymb}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{microtype}
#+LATEX_HEADER: \renewcommand{\familydefault}{\sfdefault}
#+LATEX_HEADER: \linespread{1.5}
#+LATEX_HEADER: \usepackage{tabularx}
#+LATEX_HEADER: \usepackage{tabu}
#+LATEX_HEADER: \usepackage[margin=1.4in]{geometry}
#+LATEX_HEADER: \usepackage[sort&compress,numbers]{natbib}
#+LATEX_HEADER: \usepackage[font=small,labelfont=bf]{caption}
#+MACRO: NEWLINE @@latex:\\@@

#+LATEX: \clearpage

#+LATEX: \setcounter{tocdepth}{2}
#+LATEX:\tableofcontents
#+LATEX: \clearpage
#+LATEX:\listoftables
#+LATEX: \clearpage
#+LATEX:\listoffigures
#+LATEX: \clearpage

#+LATEX: \section*{List of Abbreviations}

- CNN :: Convolutional neural network
- CPU :: Computer processing unit
- ICVP :: Intracortical Visual Prosthesis

#+LATEX: \clearpage

#+LATEX: \section*{Declaration}
The original concept for this project was devised by Dr Yan Tat Wong. Dr Yan Tat
Wong, Dr Nicholas Price, and I (Jamin Wu) discussed and developed the research
aims, hypotheses and methods for this project.

I conducted and wrote this literature review. Dr Yan Tat Wong, Dr Nicholas Price
and I discussed the contents of this literature review. Dr Yan Tat Wong and Dr
Nicholas Price provided feedback on concepts and drafts of this literature
review. I would like to thank both of my supervisors for their continuous support.

I declare that the contents of this literature review are my own work unless
explicit reference indicating otherwise has been made in the text. I declare
that this work has not been submitted for the award of any other degrees or
diplomas.

#+LATEX: \clearpage

* Introduction

Around 36 million people worldwide were blind in 2015. cite:bourne_magnitude_2017,flaxman_global_2017
Many patients are left permanently blind when there is irreversible damage to the visual system such as from glaucoma or trauma. cite:lee_glaucoma_2005,zachariades_blindness_1996
However these patients often still have portions of the visual system intact, which could be leveraged to restore vision artificially.
*Cortical visual prostheses* are devices which aim to achieve exactly that - devices implanted on the brain which stimulate neurons to directly inject visual sensations into awareness. cite:normann_toward_2009,lewis_restoration_2015,foroushani_cortical_2018

Studies in the late 20th century showed that electrically stimulating the brain could indeed produce spot-like sensations of light, known as *phosphenes*. cite:brindley_sensations_1968,dobelle_phosphenes_1974,bak_visual_1990,bosking_electrical_2017
But these studies also revealed that we can exert only very limited control over what phosphenes look like, where they are located, and how they interact. cite:rushton_properties_1978,dobelle_phosphenes_1974,schmidt_feasibility_1996
Of these studies, those conducted in small groups also demonstrated wide variation in the appearance of phosphenes between people. cite:dobelle_phosphenes_1974,bak_visual_1990
Therefore, whilst we now know we can produce these spots of light by stimulating the brain, it is not clear how to assemble these unyielding percepts into useful vision for all implantees. cite:fernandez_development_2005,beyeler_learning_2017

To address this, new proposals of cortical visual prostheses are exploring the use of sophisticated computer processing to assemble phosphenes /strategically/ so implantees can interpret them in useful ways. cite:foroushani_cortical_2018,barnes_role_2012
These methods generally focus on addressing two significant difficulties of prosthetic vision: its low resolution, and its lack of color and brightness levels, both of which are easy to simulate on graphical displays and test.  cite:buffoni_image_2005,chang_facial_2012,sharmili_comparative_2017
However it is unclear how well these image processing algorithms could cope with the much wider range of phosphene experiences reported by perceptual studies in humans.
Thus, the primary issue facing these algorithms is how they can be made flexible to accommodate the large, uncontrollable variation in what phosphenes look like.

Recently, there have been remarkable advances in the ability of computers to /derive/ image processing algorithms rather than having algorithms being programmed by hand.
In this paradigm, computers iteratively "learn" and integrate patterns between data inputs and outputs through a process known as *machine learning*.  cite:guo_deep_2016
By using machine learning methods on top of layered image processing architectures called *convolutional neural networks* (CNNs) , computers are able to achieve near-human performance in image processing feats such as handwritten digit recognition cite:ciresan_multi-column_2012, segmenting images cite:ciresan_deep_2012, and replicating image styles. cite:gatys_image_2016
Machine learning principles could be similarly applied to prosthetic vision, using inferred patterns to derive image processing algorithms from performance rather than building algorithms around conceptions of what phosphenes look like.
This could improve the flexibility of cortical implants for different perceptual experiences and improve the usefulness of cortical visual prostheses for future implantees.

In this review, we first briefly describe the relevant background of cortical visual prostheses in [[sec:what][Section 2]].
We then discuss the empirical studies on the features and limitations of phosphenes produced by cortical implants in [[sec:see][Section 3]].
Finally, we describe computational approaches which address these perceptual limitations and their implications for future research in [[sec:useful][Section 4]].

#+LATEX: \clearpage

* What is a cortical visual prosthesis?
<<sec:what>>

** Overview of Cortical Visual Prostheses

A *prosthesis* is an artificial, implanted device which aims to restore a lost function to the human body. cite:thurston_pare_2007
A *visual prosthesis* is such a device which aims to restore vision to people with visual impairment. cite:weiland_visual_2008,ong_bionic_2012
A *cortical visual prosthesis* specifically refers to a vision restoration device implanted on the cortical surface of the brain, as opposed to other portions of the visual system such as the eye, optic nerve or thalamus. cite:lewis_restoration_2015
As a cortical prosthesis is implanted directly on the brain, implantees only require a functional cortical portion of the visual system; the device bypasses any damage to the eyes or nerves leading up to the brain.
While visual prostheses at other locations in the visual pathway are also capable of producing visual sensations cite:humayun_visual_1996,stingl_interim_2017,veraart_visual_1998,panetsos_consistent_2011, their use-case, implementation and evoked vision differ from those produced by cortical prostheses and are outside the scope of this review.

Research into stimulating the brain to produce vision was first pioneered by Brindley & Lewin cite:brindley_sensations_1968 and later Dobelle & Mladejovsky cite:dobelle_phosphenes_1974 in the late 20th century.
Using rudimentary hardware, these early experiments showed that a temporary implant composed of a array of electrodes could stimulate the brain in an awake patient and make them see artificial sensations of light. cite:brindley_sensations_1968,dobelle_phosphenes_1974
These artificial sensations of light are known as *phosphenes*.
Phosphenes are highly variable, but most often appear as dots of light likened to "a star in the sky". cite:dobelle_phosphenes_1974
These early successes in evoking phosphenes were instrumental in demonstrating the feasibility of cortical prostheses cite:schmidt_feasibility_1996, which have adopted phosphenes as the fundamental building blocks of prosthetic vision.

In the past 50 years since, a small number of research groups have proposed modern cortical prostheses based on the principles of these early results.
These include the Gennaris bionic vision system cite:lowery_restoration_2015,lowery_monash_2017, the Intracortical Visual Prosthesis (ICVP) Project cite:troyk_intracortical_2017, CORTIVIS cite:fernandez_cortivis_2017 and the Orion Visual Cortical Prosthesis. cite:secondsight_second_nodate
To illustrate what modern conceptions of a visual cortical prosthesis may look like, Figure [[fig:headgear]] shows a simulated render of the headgear for the Gennaris bionic vision system.

#+NAME: fig:headgear
#+CAPTION: A modelled render of the Gennaris bionic vision headgear. Figure courtesy of Monash Vision Group.
file:./graphics/litreview/headgear2.jpg

These devices, while still early in development, may eventually be an option for restoring a crude form of vision to patients who would otherwise be left permanently blind.
The expectation is that these devices could provide gross light perception which might allow the recognition of basic forms and movement. cite:lowery_monash_2017,lowery_restoration_2015
Current technology cannot reproduce anything close to the trichromatic, approximately 15 million pixel resolution of the human eye cite:deering_limits_1998, and as such, these devices are not yet a full replacement for vision.
The development of cortical prostheses has been reviewed previously cite:niketeghad_brain_2019; we briefly summarise the current progress of these devices in Table [[tab:devices]].

#+LATEX: \renewcommand{\arraystretch}{1.5}

#+NAME: tab:devices
#+CAPTION: Current progress of cortical visual prostheses. The number of electrodes places a hard upper bound on the resolution (and visual acuity) these devices can provide, so are noted here.
#+ATTR_LATEX: :environment tabu :width \textwidth :align XXXl :font \scriptsize
| Device                                                     | Electrodes                            | Progress                                                                                                              | References                                                                    |
|------------------------------------------------------------+---------------------------------------+-----------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------|
| *Orion* \newline (Second Sight)                            | 60 subdural surface electrodes        | FDA-approved clinical trial ongoing 2018-2023, six patients implanted (public scientific results yet to be released). | cite:secondsight_early_nodate,secondsight_second_nodate,niketeghad_brain_2019 |
| *Gennaris* \newline (Monash Vision Group)                  | Up to 473 penetrating microelectrodes | Ethics approved to begin clinical trials, recruiting.                                                                 | cite:lowery_monash_2017,lowery_restoration_2015,anzctr_first_2018             |
| *ICVP Project* \newline (Illinois Institute of Technology) | 16 penetrating microelectrodes        | Preclinical phase                                                                                                     | cite:troyk_intracortical_2017                                                 |
| *CORTIVIS* \newline (Universidad Miguel Hernández)         | 100 penetrating microelectrodes       | Preclinical phase.                                                                                                    | cite:fernandez_cortivis_2017                                                  |

** Mechanism of Cortical Visual Prostheses

While the specific hardware of each device differs, the fundamental mechanism of these devices is similar.
Patients must first undergo an operation to surgically implant an electrode array in the primary visual cortex at the back of the brain. cite:lewis_restoration_2015
Historically, these were subdural surface electrodes sitting atop (but not penetrating) the brain. cite:brindley_sensations_1968,dobelle_phosphenes_1974
However, modern prostheses tend to opt for penetrating microelectrodes cite:lowery_monash_2017,troyk_intracortical_2017,fernandez_cortivis_2017 which are finer and can operate succesfully at lower electrical current. cite:bak_visual_1990,schmidt_feasibility_1996

After implantation, the physical components of the system are in place.
The system will need to be calibrated and tested before use to determine electrical stimulation thresholds and the spatial correpondence between electrodes and phosphenes in the visual fields. cite:lowery_restoration_2015,fernandez_cortivis_2017

When in use, an external camera (e.g. on glasses worn by the user) first captures an image. cite:lowery_monash_2017,lewis_restoration_2015
This image is transmitted to a portable processor, and is converted into electrical parameters for each electrode in the implanted array.
Each electrode in the implanted array then delivers pulses of electrical charge into the brain based on its parameters, which electrically stimulates nearby neurons in the cortical tissue.
Stimulating neurons in the visual cortex produces patterns of phosphenes which the patient can then perceive and interpret. cite:brindley_sensations_1968,dobelle_phosphenes_1974,bak_visual_1990
While these patterns may be difficult to decipher at first, it is expected that patients will eventually learn to match phosphene patterns to useful information such as letterforms. cite:fernandez_cortivis_2017

This process from camera image to neural stimulation loops continuously to produce a stream of images like frames of a video.
Essentially, this system provides an artificial real-time link between environmental light and visual information; a link ordinarily present in natural vision, but not present in blindness.
Figure [[fig:flowchart]] depicts the basic process of prosthetic vision in comparison to normal vision.

#+NAME: fig:flowchart
#+CAPTION: A basic flowchart of the process of prosthetic vision compared to normal vision. Figure made by the author.
[[file:./graphics/litreview/flowchart.png]]

* What do patients with cortical implants see?
<<sec:see>>

Because cortical visual prostheses use phosphenes as the fundamental building block of prosthetic vision, it is imperative that we be able to compose multiple phosphenes into meaningful imagery.
Whether phosphenes can be composed meaningfully depends on the visual and perceptual properties of phosphenes such as their size, color and interaction with other phosphenes.

Unfortunately, due to the technical and ethical issues surrounding stimulating peoples' brains, the number of studies characterising these properties of phosphenes in humans is understandably small.
Studies which characterise phosphenes evoked /in vivo/ typically fall into two distinct groups:

1. Historical experiments with rudimentary hardware on noble volunteers cite:brindley_sensations_1968,dobelle_artificial_1974,bak_visual_1990, or
2. Modern but conservative experiments in epilepsy patients who already have electrodes implanted for clinical monitoring. cite:lee_mapping_2000,winawer_linking_2016,murphey_perceiving_2009,bosking_electrical_2017,collins_preserved_2019
   
As the pool of phosphene studies in humans is small and the demographics of these studies are skewed towards specific populations, we summarise the pertinent methodological features of each study in Table [[tab:populations]].
These studies constitute the major perceptual evidence that a cortical visual prosthesis can produce vision, and point towards what type of vision might be possible.

There are several studies which also attempt to characterise phosphenes in non-human primates from trained behavioural responses. cite:tehovnik_phosphene_2005,tehovnik_phosphene_2007,tehovnik_microstimulation_2007,tehovnik_microstimulation_2009
While the qualitative perceptual information offered by these studies is limited, they provide some additional information about the spatial properties of phosphenes inferred from sacaddes (rapid eye movements).

#+LATEX: \linespread{1.1}
#+LATEX: \newgeometry{margin=2cm}
#+NAME: tab:populations
#+CAPTION: The participant demographics of studies which have looked at cortical phosphenes evoked /in vivo/ in humans.
#+ATTR_LATEX: :float sideways :environment tabu  :align rlXX[2]X[2]X[2]X[2] :font \scriptsize :placement [!htpb]
|       Date | Reference                                             | Setting                                                    | Electrodes                                                                                       | Parameters                                                                                     | Patient Demographic                                                                                                                                                                              |
|------------+-------------------------------------------------------+------------------------------------------------------------+--------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|       1968 | cite:brindley_sensations_1968                         | Acute                                                      | 80 surface electrodes (array) on occipital cortex                                                | Monophasic trains with 0.2ms pulses of unknown current (power 90mW) at 100Hz                   | 1 patient blind from  glaucoma and retinal detachment approx 1 year prior  (female, 52 years)                                                                                                    |
|       1974 | cite:dobelle_phosphenes_1974                          | Acute                                                      | Variable number of surface electrodes on occipial cortex                                         | Monophasic or biphasic trains with 0.25-2ms/phase pulses of up to 1-5mA at 30-200Hz for 1000ms | 15 patients with cerebral tumours and partial visual field defects or normal sight (11 male, 4 female, 20-71 years)                                                                              |
|       1974 | cite:dobelle_artificial_1974                          | Acute                                                      | 64 subdural surface electrodes (array) on occipital cortex                                       | Biphasic trains with 0.5ms/phase pulses of up to 8mA at 50Hz for unknown duration              | 1 patient blind from congenital cataract in one eye and glaucoma and retinal detachment in the other for 28 years (male, 45 years); and 1 patient blind from trauma for 7 years (male, 28 years) |
|       1978 | cite:rushton_properties_1978                          | Chronic \newline {\tiny 5\textonehalf  years post implant} | Unknown                                                                                          | Unknown-phase trains with with up to 2ms pulses of ?mA at 2-1000Hz for 1-8 pulses              | Unknown                                                                                                                                                                                          |
| 1976, 1979 | cite:dobelle_braille_1976,dobelle_mapping_1979        | Chronic \newline {\tiny unknown years post implant}        | 64 subdural surface electrodes (array) on occipital cortex                                       | Biphasic trains with 0.25ms/phase pulses of 0.5-4.0mA at 50Hz for 500-1000ms                   | 1 patient blind from trauma 10 years prior to implantation (male, 33 and 35 years)                                                                                                               |
|       1990 | cite:bak_visual_1990                                  | Acute                                                      | 1-3 intracortical penetrating microelectrodes on occipital cortex                                | Biphasic trains with 0.2ms/phase pulses of up to 200\mu A at 100Hz for 100-1000ms              | 3 sighted patients with epilepsy (unknown demographic?)                                                                                                                                          |
|       1996 | cite:schmidt_feasibility_1996                         | Acute                                                      | 38 intracortical penetrating microelectrodes on occipital cortex                                 | Biphasic trains with 0.2-0.8ms pulses of up to 80\mu A at 75-200Hz for 125-250ms               | 1 patient blind from glaucoma 22 years prior (female, 42 years)                                                                                                                                  |
| 1994, 1999 | cite:allison_face_1994,puce_electrophysiological_1999 | Acute                                                      | Unknown number of surface electrodes on extrastriate visual cortex                               | Biphasic trains with 0.2ms pulses of 2-10mA at 50Hz for 5000ms                                 | Unknown                                                                                                                                                                                          |
|       2000 | cite:dobelle_artificial_2000                          | Chronic \newline {\tiny 21 years post implant}             | 64 (subdural?) surface electrodes (array) on on occipital cortex                                 | Biphasic trains with 0.5ms/phase of (10-20V) at 30Hz for 1-50 pulses                           | 1 patient blind from trauma 5 years prior to implantation (male, 62 years)                                                                                                                       |
|       2000 | cite:lee_mapping_2000                                 | Acute                                                      | Total 271 subdural surface electrodes on occipital cortex and adjacent areas across all subjects | Biphasic trains with 0.3ms pulses of 1-15mA at 50Hz for 5000ms                                 | 23 sighted patients with epilepsy (12 male, 11 female, 16-41 years)                                                                                                                              |
|       2009 | cite:murphey_perceiving_2009                          | Acute                                                      | Total 50 subdural surface electrodes on 11 different visual areas across all subjects            | Biphasic trains with 0.2ms pulses of 0.49-7mA at 200Hz for 300ms                               | 10 sighted patients with epilepsy (6 male, 4 female, 19-67 years)                                                                                                                                |
|       2016 | cite:winawer_linking_2016                             | Acute                                                      | 1 or 2 subdural surface electrodes on V1 studied per subject                                     | Biphasic trains with 0.2-1ms pulses of 0.2-5mA at 5-100Hz for 200-1000ms                       | 4 sighted patients with epilepsy (3 male, 1 female, 24-40 years)                                                                                                                                 |
|       2017 | cite:bosking_saturation_2017                          | Acute                                                      | Up to 16 subdural surface electrodes (array) on early occipital cortex per subject               | Biphasic trains with 0.1ms/phase pulses of 0.3-4.0mA at 200Hz for 200-300ms                    | 15 sighted patients with epilepsy (5 male, 10 female, 22-61 years)                                                                                                                               |
|       2018 | cite:bosking_rules_2018                               | Acute                                                      | Up to 16 subdural surface electrodes (array) on early occipital cortex per subject               | Biphasic trains with 0.1ms/phase pulses of 0.3-4.0mA at 200Hz for 200-300ms                    | 8 sighted patients with epilepsy                                                                                                                                                                 |
|       2018 | cite:beauchamp_dynamic_2018                           | Acute                                                      | 16 or 24 subdural surface electrodes (array) on early occipital cortex per subject               | Biphasic trains with 0.1ms/phase pulses of 0.3-4.0mA at 200Hz for 50-300ms                     | 4 sighted patients with epilepsy (all male, 20-54 years) and 1 patient blind 8 years prior, unspecified reason (female, 35 years)                                                                |
|       2019 | cite:collins_preserved_2019                           | Acute                                                      | 16 subdural surface electrodes (array) on occipital cortex                                       | Biphasic trains with 1ms pulses of up to 11mA at 60Hz                                          | 1 patient with epilepsy and a partial visual fied defect for 30 years from AVM haemorrhage (male, 45 years)                                                                                      |
#+LATEX: \restoregeometry
#+LATEX: \linespread{1.5}

** Phosphenes Produced by Stimulating a Single Electrode

The most common result of stimulating a single electrode is a single phosphene characterised as a small, localisable dot of light likened to a star. cite:brindley_sensations_1968,dobelle_phosphenes_1974,schmidt_feasibility_1996,lee_mapping_2000
Every study has, however, demonstrated large variation on this basic percept.

*** The Quality of a Phosphene

Being able to perceive qualities of light such as brightness and colour gives us richer, more specific information about the world. cite:solomon_machinery_2007,vladusich_brightness_2007
Composing images with phosphenes of different brightness and colour would enable us to mimic the richness of natural visual information.

It therefore seems promising that one of the most consistently reported features of phosphenes is that different levels of brightness /are/ perceivable and even modifiable.
The brightness of a phosphenes reproducibly increases with stimulation amplitude, pulse duration and pulse frequency. cite:dobelle_phosphenes_1974,dobelle_artificial_1974,rushton_properties_1978,schmidt_feasibility_1996,dobelle_artificial_2000,winawer_linking_2016
An early study estimated up to 12 distinguishable levels of brightness by varying the stimulation amplitude of a surface electrode. cite:rushton_properties_1978

The colour of phosphenes, however, is not as promising.
Phosphene colours range from colourless to vididly coloured with large inter-individual variation.
Some patients only report seeing white or colourless phosphenes. cite:brindley_sensations_1968,dobelle_phosphenes_1974,bak_visual_1990,dobelle_artificial_2000
Others have reported a spectrum across almost every reportable colour and beyond to 'other-wordly' colours. cite:dobelle_phosphenes_1974,rushton_properties_1978,bak_visual_1990,schmidt_feasibility_1996,puce_electrophysiological_1999,lee_mapping_2000,murphey_perceiving_2009
Sighted patients looking at a white background have also reported seeing black phosphenes, though this finding is not well reported elsewhere. cite:lee_mapping_2000
While it was previously speculated that blind patients saw colourless phosphenes due to long-term sight deprivation cite:dobelle_phosphenes_1974, this is not consistently the case, and coloured percepts have also been reported by a patient blind for 22 years. cite:schmidt_feasibility_1996
Least promising is that colour is not consistently modifiable using different parameters of electrical stimulation, meaning phosphenes are most often randomly coloured. cite:rushton_properties_1978

*** Spatial Properties of Phosphenes

Of great concern to cortical visual prostheses is how phosphenes are arranged in visual space, which may affect the shapes of patterns that can be formed by prosthetic devices.
The visual cortex, as a sensory surface, is mapped retinotopically i.e. such that regions in the visual field which are next to each other are also next to each other on the cortex (though they may be distorted). cite:fox_retinotopic_1987,engel_retinotopic_1997
Electrodes placed over visual cortex appear to follow this mapping, and relationships between adjacent electrodes are roughly conserved. cite:brindley_sensations_1968,dobelle_mapping_1979,beauchamp_dynamic_2018
Figure [[fig:map]] illustrates the mapping of a 64-electrode array to phosphene locations measured by perceptual testing.

#+NAME: fig:map
#+CAPTION: Spatial distribution of phosphenes mapped to the visual fields (left) in a patient implanted with an early 64-electrode array (right). Figure from Dobelle et al. 1979 cite:dobelle_mapping_1979
[[./graphics/litreview/map.png]]

However, while we can very grossly estimate positions of phosphenes in the visual field (especially in relation to the calcarine sulcus, below which phosphenes correspond to superior fields), the distortion of retinotopy on the visual cortex means /precise/ mapping is not possible until post-implantation.
In sighted patients, phosphene locations can be mapped with receptive fields in response to visual stimuli, to which they closely correspond. cite:bosking_saturation_2017,bosking_rules_2018,beauchamp_dynamic_2018
This is clearly not possible in blind patients, so phosphenes are often mapped by indicating directions or relative positions of pairwise phosphenes. cite:schmidt_feasibility_1996,beauchamp_dynamic_2018,brindley_sensations_1968,dobelle_mapping_1979
The implication is that while we can roughly determine the quadrant of a phosphene in the visual field at implantation, we cannot know precisely where it is located until stimulation is trialled.
In addition, sometimes stimulating one electrode produces more than one phosphene, which may be either adjacent or inverted about the horizontal meridian of the visual field. cite:brindley_sensations_1968,dobelle_phosphenes_1974,schmidt_feasibility_1996
This is most likely attributable to off-target stimulation of tissue across a sulcus, supported by observations that this phenomena occurs less severely with penetrating microelectrodes (which discharge less than surface electrodes). cite:dobelle_mapping_1979,schmidt_feasibility_1996

The space a phosphene occupies in the visual fields varies with eccentricity and stimulation current.
Early evaluations of phosphene size using various objects at arm's length cite:brindley_sensations_1968,dobelle_phosphenes_1974,dobelle_artificial_2000,dobelle_artificial_1974,schmidt_feasibility_1996 have generally been agreeable with more formal estimates using degrees of visual field. cite:bak_visual_1990,bosking_saturation_2017,winawer_linking_2016
Most phosphenes are 1-2\degree  of visual field in diameter and range from 0.1-10\degree  (a "grain of sago" to a coin at arm's length) . cite:bak_visual_1990,bosking_saturation_2017,brindley_sensations_1968
The size of phosphenes depends on where they are located in the visual fields; more peripheral phosphenes are larger and reportedly have less distinct borders. cite:rushton_properties_1978,winawer_linking_2016,bosking_saturation_2017
The variation of phosphenes with size is consistent with behavioural studies in non-human primary undergoing cortical stimulation cite:tehovnik_phosphene_2007 and the phenomenon of cortical mangnification, where the central visual field is overproportionately represented on the surface of the brain. cite:born_cortical_2015
Phosphenes also appear to increase in size with stimulation amplitude cite:rushton_properties_1978,winawer_linking_2016,bosking_saturation_2017, though one early report of microelectrode stimulation also described instances where phosphene size decreased which have not been subsequently reproduced. cite:schmidt_feasibility_1996

While circular phosphenes are ubiquitous cite:brindley_sensations_1968,dobelle_phosphenes_1974,bak_visual_1990,schmidt_feasibility_1996,lee_mapping_2000, other phosphenes shapes have been reported.
The most consistently reported shape other than circles are elongated elliptical or linear phosphenes oriented in horizontal, oblique or vertical orientations. cite:brindley_sensations_1968,dobelle_phosphenes_1974,rushton_properties_1978,bak_visual_1990,beauchamp_dynamic_2018
A few reports identify shapes ranging from triangles and stars, to checkerboards, to face or eye-like hallucinatory sensations. cite:lee_mapping_2000,murphey_perceiving_2009
Often, more abstract phosphenes appear on stimulation of later visual areas of the brain, which may not be relevant for prostheses targeting only primary visual cortex. cite:murphey_perceiving_2009
While phosphene shapes appear loosely related to the putative role of different brain regions cite:lee_mapping_2000, no studies have been able to deliberately control the shape of phosphenes.

Finally, phosphenes have been repeatedly shown to move with eye movements and have been likened to the movement of retinal afterimages. cite:brindley_sensations_1968,dobelle_artificial_1974,schmidt_feasibility_1996
It appears the whole map of phosphenes moves as multiple phosphenes maintain their relative positions after movement. cite:dobelle_artificial_1974,schmidt_feasibility_1996

*** Temporal Properties of a Phosphene

Phosphenes generally appear synchronous with stimulation. cite:schmidt_feasibility_1996,beauchamp_dynamic_2018
It is difficult to measure the latency of percepts without also including motor reaction time, but studies comparing phosphene onset reaction times to auditory stimuli suggest that additional latency is minimal. cite:rushton_properties_1978
In multiple studies, phosphenes have been sporadically reported to persist for up to 20 minutes after stimulation ceased, particularly after a high-discharge stimulation prior. cite:brindley_sensations_1968,dobelle_artificial_1974,rushton_properties_1978,schmidt_feasibility_1996
Perhaps paradoxically, phosphenes purposefully sustained by continuous stimulation demonstrate significant fading in as little as 15 seconds. cite:dobelle_phosphenes_1974,schmidt_feasibility_1996
The fading effect of phosphenes is also reflected over separate trials, where phosphenes progressively dim in each subsequent trial (though they "reset" the next day). cite:schmidt_feasibility_1996

On a shorter time scale, phosphenes elicited by surface stimulation may also flicker.
The phosphene flicker produced by surface electrodes is fixed, fast, and asynchronous with hardware or physiological pulses. cite:brindley_sensations_1968,dobelle_artificial_1974,dobelle_phosphenes_1974,rushton_properties_1978,dobelle_artificial_2000
This differs from the "flicker" produced by two separate successive stimulations, which disappears at stimulation frequencies of approximately 33Hz (though an overlying intrinsic flicker remains). cite:rushton_properties_1978
It is unknown whether flicker also occurs in stimulation with microelectrodes; of the few studies of stimlation with penetrating microelectrodes, flicker was not reported.   cite:bak_visual_1990,schmidt_feasibility_1996

In summary, we can exert only very limited control over what individual phosphenes look like.
Phosphenes are also highly variable, both between-individuals and between-electrodes.
While there are points of agreement between studies, such as the effect of stimulation current on brightness, other phenomena, such as colour and flickering, remain contentious.
It remains unclear whether these disagreements are due to differences in stimulation parameters, hardware, participants or pathology.

** Phosphenes Produced by Stimulating Multiple Electrodes

The appearance of images containing multiple phosphenes is fundamental to modern cortical prostheses as very little information can be transmitted through only a single electrode at once. cite:niketeghad_brain_2019,lewis_restoration_2015
The intention for cortical prostheses is to produce perceivable /patterns/ which can be interpreted.
The eventual hope is to approximate natural images with phosphenes used like pixels of a graphical display.
Early chronic implants operated on this principle, albeit with very low resolution. cite:dobelle_artificial_2000

However, the empirical evidence on /what/ is perceived when multiple electrodes are stimulated is surprisingly scarce.

At the most simple level, two electrodes which produce individual phosphenes appear to also produce two separate perceivable phosphenes when stimulated simultaneously.  cite:brindley_sensations_1968,dobelle_phosphenes_1974
Sometimes, the size of each phosphene decreases compared to individual stimulation, and the distance between phosphenes may increase. cite:bosking_rules_2018
When close together, these phosphenes may fuse together into a single percept. cite:brindley_sensations_1968,dobelle_phosphenes_1974
However, this is not always the case; in fact, dimmer phosphenes may not be perceived at all cite:bosking_rules_2018,dobelle_artificial_1974,dobelle_phosphenes_1974, though there is some evidence that increasing the stimulation amplitude may reintroduce the dimmer percept. cite:schmidt_feasibility_1996
As a result, increasing the number of electrodes may not linearly increase the number of perceived phosphenes.

Several studies have characterised greater numbers of simultaneous phosphenes.
Early evidence suggested that four-phosphene patterns (e.g. a square) could be recognised, but not reliably as spurious phosphenes appeared and some expected phosphenes were not perceived. cite:dobelle_artificial_1974
Another patient was able to perceive a six-phosphene vertical line. cite:schmidt_feasibility_1996
Modern studies, however, have provided conflicting results.
In one study in an epilepsy patient, five electrodes stimulated at once were only able to produce two perceivable phosphenes that was not simply the aggregate of each of the five phosphenes. cite:beauchamp_dynamic_2018
In non-human-primates, stimulation of visual cortex simultaneously at two spacially distant points did not sum to an joint signal, further suggesting a separation of processing of simultaneous stimulation. cite:ghose_strong_2012

The reasoning behind this difficulty is thought to be because cortical visual prostheses unselectively stimulate local regions of the brain.
In normal primary visual cortex, neurons are typically selectively stimulated by specific image features such as the orientation of lines in the visual fields. cite:ben-yishai_theory_1995
When electrodes instead unselectively stimulate neurons, the pattern of neural stimulation is unnatural and later visual areas may not immediately be able to decode the unrecognisable stimulus. cite:beauchamp_dynamic_2018

Despite the difficulties of these temporary experiments, chronic studies suggest that patients are able to use this information usefully after a learning period.
There are brief reports of a patient with a chronic implant being able to read phosphene patterns on a 64-electrode implant at 30 letters per minute, similar to Braille cite:dobelle_braille_1976
Reports on a different patient from the same group described the ability to recognise symbols and letters at an estimated visual acuity of 20/1200 (seeing at 20 metres what could normally be seen at 1200 metres). cite:dobelle_artificial_2000
However, due to the absence of any further chronic studies of implants in blind patients, the upper limit to which people can learn to recognise phosphene patterns is unknown.

Given these limited studies of combinations of phosphenes, there is a tremendous gap between the current knowledge of phosphene patterns and the proposed mechanism of cortical prostheses.
It is entirely unclear whether people can perceive phosphene patterns on the order of tens or hundreds, whether people can learn to perceive these patterns in useful ways, or to what degree these patterns may change.

** Summary of the Perceptual Limitations of Phosphenes

The major issues surrounding the current literature on phosphenes are therefore:

1. *There are no modern studies of phosphenes evoked in blind but otherwise-healthy patients, the primary demographic of cortical visual prostheses*.
   There are also scant chronic studies, none of which have been conducted with penetrating microeletrodes. cite:rushton_properties_1978,dobelle_artificial_2000,dobelle_braille_1976
   Emerging clinical trials will help resolve this issue, but until such studies bear fruit, our knowledge on what cortical prosthetic vision looks like may not be readily applicable to new devices.
2. *Phosphenes are highly variable*.
   Almost all features of phosphenes display uncontrollable variability, and the only two properties of phosphenes we have been shown to reliably control are phosphene brightness and size. cite:rushton_properties_1978
   This variability permeates between electrodes, between patients and between studies.
   The heterogeneity, low sample size and skewed populations of the literature have made it difficult to distinguish the root cause of such variation.
3. *The interpretibility of patterns formed by multiple phosphenes is unclear.*
   There is conflict amongst studies on whether multiple phosphenes at once can be integrated simultaneously, or whether people can learn can compensate for initial difficulties with interpreting phosphenes.

As a result, there is considerable uncertainty on exactly what visual sensations modern devices can give to implantees on a case-by-case basis.

\clearpage

* How can we make what people see most useful?
<<sec:useful>>

Our ability to control the appearance of individual phosphenes and their patterns is clearly limited. 
In this section, we briefly review current literature on how images can be represented strategically in phophene space to overcome these limitations.

** The Role of Simulated Prosthetic Vision

Because of the difficulties of implanting electrode arrays, little research has been conducted on what methods of representing information in phosphene space are most useful /in vivo/.
The only cortical implant which has been connected to a camera in humans was the Dobelle Implant in 2000. cite:dobelle_artificial_2000.
The Dobelle Implant used direct image processing techniques fitting of the software capabilities of the time, which essentially downsampled the camera image and directly mapped the brightness to implant electrodes. cite:dobelle_artificial_2000.
The group briefly entertained the idea of using edge-detection for more selective stimulation, but no subsequent studies reported the outcomes of this idea.

To allow the testing of new image processing algorithms in the absence of access to real implantees, research in image processing algorithms has largely moved to simulations of prosthetic vision. cite:chen_simulating_2009-1,chen_simulating_2009
Simulated prosthetic vision is the primary vehicle through which most new image processing algorithms are tested.
The features of simulated prosthetic vision have been reviewed previously. cite:chen_simulating_2009-1
Briefly, camera information is processed and rendered onto a head-mounted or other display as simulated phosphenes.
Typically, these simulated phosphenes are rendered as the most commonly reported percept - white dots with a Gaussian blur filter applied. cite:chen_simulating_2009-1
In this way, phosphene "images" are displayed for the user with the aim to approximate the prosthetic vision of an implantee.
Examples of these simulated renders are shown in Figure [[fig:simulated]].

#+NAME: fig:simulated
#+CAPTION: Examples of different simulated renders of phosphenes. Figure from Chen et al. 2009. cite:chen_simulating_2009-1
[[file:./graphics/litreview/simulated.png]]


** A Brief Outline of Current Image Processing Approaches
*** Direct Methods

The prevailing paradigm of image processing for early cortical prostheses was to directly map camera images to a grid of electrodes as though they were superimposed. cite:schmidt_feasibility_1996,dobelle_artificial_2000
This produces a phosphene image like a mask full of holes placed on top of the original image.
In this way, prosthetic vision began by attempting to emulate natural vision as closely as possible.

Such an approach may work with a large number of electrodes if all phosphenes could be interpreted correctly as "pixels".
One study estimated that approximately 625 phosphenes would be sufficient to reach a visual acuity of 20/30, suitable for most general tasks cite:cha_simulation_1992.

However, there are several issues of direct methods when compared with the perceptual limitations of phosphenes:
Direct methods, by virtue of keeping faithful to the original image, tend to produce simulated phosphene renders with large numbers of "on" phosphenes, particularly in well-lit environments.
As the ability to interpret multiple phosphenes simultaneously is not well established, stimulating many electrodes at once may not produce the expected visual percept.
Because of the high variability of phosphenes, it is also unlikely that the quality and spatial distribution of pixels of a transformed image could be reproduced as faithfully as intended.

Moreover, the quality of these methods very rapidly degrades once resolution drops. cite:li_image_2018
No new implants are capable of producing 625 distinct phosphenes. cite:lewis_restoration_2015
Without the resolution to support the interpretation of low-level features of directly processed images, images can be uninterpretable.

*** Edge-Based Methods

Edge-detection refers to image processing algorithms methods which highlight the edges of objects only. cite:canny_readings_1987
Edges require less phosphenes at once and may reduce the amount of redundant information in an image.
This is important when we can consider that the number of perceivable phosphenes may not increase linearly with the number of stimulated electrodes. cite:bosking_rules_2018

Edge detectors such as the Canny cite:canny_readings_1987 edge detector are widely used.
These edge detectors are able to detect fast pixel gradients in images, which typically occur at boundaries.
If additional inputs to the processing algorithm are possible, then more sophisticated techniques can be used.
For example, the use of a range camera or other depth sensing devices can be used to more intelligently find non-background edges. cite:lui_transformative_2012
State-of-the-art convolutional neural networks (CNNs) have also been applied to edge detection for prosthetic vision by semantic pixel labelling of images of rooms and determining edges by boundaries between walls. cite:sanchez-garcia_structural_2018
An illustration of an edge-detection algorithm combined with a object-filling algorithm is shown in Figure [[fig:edgeandfill]].

#+NAME: fig:edgeandfill
#+CAPTION: An example of an edge-detection algorithm with a CNN-driven object-filling algorithm to render a clean simulated phosphene image. Figure from cite:sanchez-garcia_structural_2018
[[file:./graphics/litreview/edgeandfill.png]]

The difficulty with edge-based methods is that edges easily degrade when resolution drops, similar to direct methods. cite:buffoni_image_2005
One method which aimed to resolve the fragility of edges combined edge-based methods with saliency-based methods to give greater form to objects. cite:han_object_2015
Such hybrid methods may be more robust than the use of pure edges when faced with significant downsampling.

*** Saliency-Based Methods

As opposed to naively translating brightness values of camera images to electrode stimulation, saliency-based measures more intelligently identify the semantics of objects in a scene.
Using this semantic structure, the image can be divided or /segmented/ into regions of interest which carry a common semantic meaning (e.g. "background" or "foreground"). cite:pal_review_1993

With this approach, more deliberate differences between foregound and background can be made as depicted in Figure [[fig:saliency]]. cite:guo_optimization_2018
When applied to an image classification task, saliency-based methods improved the recognition accuracy of common objects. cite:han_object_2015,li_image_2018

Object detection neural networks have also been applied to highlight particular salient features of an image. cite:mace_simulated_2015
In these methods, powerful image classification algorithms are able to detect a specified object and solely highlight that object on the simulated phosphene render.
While these methods were constrained to only specific objects, they demonstrate leverage of modern progressions in image processing to intelligently identify objects.

#+NAME: fig:saliency
#+CAPTION: An example of a saliency-based algorithm to highlight a region of interest of the image. Figure from cite:li_image_2018
[[file:./graphics/litreview/saliency.png]]

The methods help highlight what is most likely to be relevant in an image and suppress background, which may otherwise interfere.
However the usefulness of this masking approach is importantly constrained by the implantee's ability to subsequently recognise what is being shown.
While simulations have demonstrated the utility of this approach, the fidelity of the mask form when phosphenes are irregularly shaped and sized is not clear.
While these methods are advantageous compared to direct methods in that irrelevant information may be reduced, it faces the same limitations that low-level forms may be obscured by phosphene distortions.

*** Transformative Methods

Recent advances in machine learning have meant that computers are now reaching human-level abilities for tasks such as image classification using deep learning methods. cite:rawat_deep_2017,guo_deep_2016
Because the processor in a cortical visual prosthesis has access to the full camera image (as opposed to the user, who can only see the phosphene version), the processor has more information available to interpret.
Instead of expecting the user to interpret high-level information from degraded phosphene images, some interpretation could be relegated to the computer which can then intelligently re-encode the information in a deliberate manner.

Numerous patents have been filed for such a system. cite:chichilnisky_eduardo-jose_smart_2018,li_going_2013
In these systems, important visual cues such as stairs, faces and bank notes are recognised by the computer, which can then remove unnecessary low-level detail and produce compact, abstract images that represent the /concept/ of what is seen, not what is actually seen.
For example, faces can be recognised and re-encoded as emoticons which cleanly fit in low-resolution space. cite:lui_transformative_2012
An example of this approach is shown in [[fig:transformative]]

#+NAME: fig:transformative
#+CAPTION: An example of a transformative approach to image processing to re-encode information. Figure from cite:lui_transformative_2012
[[file:./graphics/litreview/transformative.png]]

The chief benefit of such methods is that useful information can be communicated with less phosphenes.
Since many low-level details (e.g. "is this bank note folded at the corner?") are not always relevant, the information burden to the user can be reduced to only what is necessary.

The perceptual issues facing these methods are that these typically rely on producing phosphene images that "mimic" real life (e.g. emoticons, which attempt to mimic faces). cite:lui_transformative_2012
However, the perceptual distortions and variability of phosphenes make it unclear whether these mimics could be replicated and thus the ability to specifically evoke these "mimics" /in vivo/ with phosphenes is not well established.
What may appear cleanly represented in simulated phosphene space may be heavily distorted and even unrecognisable in real implantee settings.
A potential rebuttal is that as these methods re-encode information at the bequest of the algorithm implementer, they could be optimised on a case-by-case basis for the particular phosphenes an implantee sees.
Individual-level implementations of image processing algorithms are yet to be explored.

*** Temporal Methods

Given the challenges already faced by patients when trying to interpret multiple simultaneous phosphenes, some groups have begun to explore non-simultaneous methods of conveying patterned information.
/Dynamic current steering/, where phosphene patterns are "traced" in quick succession rather than presented all at once have shown sigificant benefits for letter recognition tasks. cite:beauchamp_dynamic_2018,spencer_creating_2018
Figure [[fig:temporal]] illustrates the principle behind this approach.
Patients, without prior training, were able to trace the path of phosphenes and interpret simple letterforms accurately.
Unlike most of these other methods, dynamic current steering /has/ been tested /in vivo/ in patients with epilepsy with subdural surface electrodes and in fact arose out of perceptual difficulties noted by the investigators. cite:beauchamp_dynamic_2018
This highlights one of the issues with simulated prosthetic vision tests; fundamental perceptual differences of electrical neural stimulation may not be discovered and accounted for until tested in real patients.

#+NAME: fig:temporal
#+CAPTION: An example of a temporal approach to conveying information through phosphenes, where electrodes are stimulated in succession instead of simultaneously. Figure taken from cite:beauchamp_dynamic_2018
[[file:./graphics/litreview/temporal.png]]

These methods attempt to resolve the issues surrounding interpreting multiple simultaneous phosphenes by tapping into the brain's natural ability to interpret gross motion. cite:grossman_brain_2002
While temporal methods may be slower at conveying information per unit time, they have the advantage of not requiring simultaneous presentations of phosphenes, and requiring less current as only a limited number of phosphenes need to be conveyed for a single frame.
It is clear, however, that the difference between temporal methods and form-based methods cannot be assessed in simulated prosthetic vision as the differences between these two methods is based on differences in /in vivo/ perception.
More clinical trials are needed to establish whether temporal methods of information transfer as opposed to spatial methods are better suited for cortical prosthetic devices.

** The Limitations of Simulated Prosthetic Vision

The crux of many of these methods rests on tests of simulated prosthetic vision, faces significant limitations for generalisability to /in vivo/ implants:

1) *The possible difficulties /in vivo/ of interpreting phosphenes are not accounted for.*
   One of the key unknowns in phosphene space are how well the brain can learn to decipher the unselective unnatural stimulation of visual cortex by multiple electrodes simultaneously. cite:beyeler_learning_2017
   Because our uncertainty in this area relates to the unnatural neural stimulation of the visual cortex, this cannot be assessed in a simulated setting.
   When phosphenes are simply shown on a display, a sighted subject naturally is able to process the displayed patterns making full use of the retinal and neural circuity distal to the brain.
   This is most certainly not the case for an implantee.
   While normal-sighted subjects have often been shown to be able to recognise complex patterns with many simultaneous phosphenes in a simulated setting cite:chen_simulating_2009, it is still unclear whether this can be replicated in real implantees.
2) *Phosphene simulation often does not account for all known properties of phosphenes.*
   The properties we have described above are rarely all accounted for.
   For example, temporal effects such as fading and accommodation are not implemented in most simulations.
   Additionally, most simulations render phosphene images as low-resolution greyscale images with uniform circular cite:mccarthy_mobility_2014,hu_recognition_2014,sanchez-garcia_structural_2018,li_image_2018 or hexagonal pixels. cite:chen_effect_2004, though some studies have also incorporated biologically-based retinotopic distortion. cite:josh_real-time_2011,josh_psychophysics_2013
   Indeed, many simulated prosthetic vision algorithms approach the problem as chiefly one of low resolution, loss of colour and distortion.
   This does not accurately reflect the rich (but uncontrollable) perceptual experiences previously reported by /in vivo/ experiments in shape, size, colour or flicker.
3) *Many simulations use regular and higher-resolution phosphene grids than have previously been achieved.*
   Sometimes, psychophysical experiments render on the order of a thousand phosphenes cite:sanchez-garcia_structural_2018,li_image_2018,guo_optimization_2018
   This far outstrips the number of phosphenes which have been tested simultaneously /in vivo/ so far (less than a hundred) cite:dobelle_artificial_2000, and also surpasses the estimates of capabilities of modern prostheses. cite:lewis_restoration_2015
   Ultimately, the ability to reliably evoke many cortical phosphenes regularly and of the calibre of many simulations has not been established.
4) *Most simulations do not specifically target cortical phosphenes.*
   Most advances in image processing methods for simulated prosthetic vision are targeted at retinal prostheses, for which there are already commercially available devices. cite:stingl_interim_2017,luo_argus_2016,markowitz_rehabilitation_2018
   The lack of distinction between different biological methods of evoking phosphenes in some experiments of simulated prosthetic vision mean results may not be directly translatable.

The implication of these issues is that studies of image processing algorithms in simulated prosthetic vision are not flexible for different phosphene percepts.
The methods we have described are dependent on being able to replicate the simulated renders in /in vivo/ implants, but little research has been conducted on this area.
It is unclear how the image processing algorithms produced by studies of simulated prosthetic vision could be made flexible for the variability in phosphenes we have described in Section [[sec:see]]

** Future Directions from Advances in Machine Learning

The remaining goal for better addressing the perceptual limitations for phosphenes is to find flexible ways to reconcile image processing algorithms in simulated phosphene space with the wide variability in what phosphenes look like.
Image processing outside of prosthetic vision has experienced a wealth of improvements from advances in machine learning, where computers learn patterns from data without prior knowledge of those patterns. cite:guo_deep_2016
Machine learning for image processing is most often applied to the training of *convolutional neural networks* (CNNs), which are layered architectures of image filters modelled after the function of physiological neurons. cite:rawat_deep_2017
CNNs have already discovered widespread use in image recognition tasks cite:krizhevsky_imagenet_2012, video recognition tasks cite:karpathy_large-scale_2014 and style transfer tasks, where images are modified to mimic the style of other images. cite:gatys_image_2016

The benefit of CNNs is that they produce image processing algorithms that are trainable from data without requiring explicit programming.
This could be applied to the current gap between simulated prosthetic vision and perceptual limitations of phosphenes.
By training CNNs on task performance data rather than programming algorithms to produce explicit patterns of phosphenes, CNNs could learn to process images in phosphene-agnostic ways.
CNNs could also be tailored for individuals' perceptions of phosphenes, as the dependency of the algorithm shifts towards task performance tests rather than perceptual tests.
This essentially posiions the problem of deriving image processing algorithms from bottom-up (from phosphenes to algorithm) to top-down (from performance to algorithm).

To our knowledge, CNNs have not been applied in this way to derive image processing algorithms for prosthetic vision, and thus research on this topic is scant.
While CNNs and other neural network architectures have been applied to prosthetic vision to construct new algorithms cite:mace_simulated_2015,ge_spiking_2017,sanchez-garcia_structural_2018, these have typically been object detection networks involved in segmentation-based processing.
There has also been growing interest in using machine learning recognition algorithms for transformative techniques in prosthetic vision. cite:chichilnisky_eduardo-jose_smart_2018
With continuous improvements in the capacity of hardware to support advanced processing cite:moore_cramming_1998, it is possible that emergent research in using machine learning to produce flexible, trainable algorithms could improve the utility of a cortical visual prosthesis.

\clearpage

* Conclusion

Cortical visual prostheses are a promising enabling technology for the blind.
As the development of these prostheses is still in early stages, it is still not precisely known what type of vision implantees will be able to achieve with a prosthesis.
However, early studies of cortical stimulation seem to suggest that the visual percepts produced will be highly variable and difficult to control.
Whilst there have been many progressions in image processing algorithms in simulated prosthetic vision, the ability of these algorithms to translate to the diverse range of /in vivo/ phosphenes is unclear.
This is because many of these algorithms are based on conceptions of the appearance of phosphenes which we do not know if we can replicate, particularly between different people.
There is therefore a gap in the literature between how image processing algorithms could be derived flexibly in a phosphene-agnostic way.
Modern advances in machine learning have shown outstanding achievements of layer image filter architectures, or convolutional neural networks, to learn image processing algorithms from data without explicit programming.
As these methods have not been applied to prosthetic vision before, preliminary studies which assess the feasibility of using machine learning methods to address the perceptual limitations of phosphenes may be greatly informative.

#+LATEX: \clearpage

* Aims & Hypotheses
<<sec:aims>>

The aims and hypotheses of this project are:

- Aim 1 :: To investigate the performance benefit of a CNN-based image processor trained on task-performance on a simple digit recognition task.
- Hypothesis 1 :: A CNN-based image processor trained on task performance improves participants' accuracy on a digit recognition task under simulated prosthetic vision, compared to a brightness-based control.

#+LATEX: \linebreak

- Aim 2 :: To investigate the flexibility of a CNN-based image image processor trained on task-performance on a simple digit recognition task.
- Hypothesis 2 :: A CNN-based image processor trained on task performance achieves greater performance consistency between different simulated prosthetic vision renders, compared to a brightness-based control.

#+LATEX: \clearpage

* Project Outline

** Rationale

In this literature review, we have identified a gap in the literature; the absence of flexible image processing algorithms to address the perceptual limitations of phosphenes.
We aim to approach this gap in the literature using methods from modern advances in machine learning applied to image processing with CNNs.
As CNNs have experienced significant uptake within the image processing community, we believe that a preliminary study into the feasibility of CNNs for image processing in prosthetic vision would be informative.
As no prior literature has addressed a similar top-down phosphene-agnostic approach before, we believe this topic is novel and can inform the future development of image processing algorithms for prosthetic vision.

** Brief Outline of Proposed Methods

*** Planning Phase (May - Jun)
This experiment is comprised of a digit recognition task in six different conditions, composed of different combinations of a phosphene renderer (which aims to simulate the limitations of phosphenes we have addressed in Section [[sec:see]]) and an image processor (including the CNN-based model).

In this experiment, we will test 2 different simulated phosphene renderers with 3 different image processing methods.

The 2 image processing methods will be:
1. A brightness-based algorithm, which controls the brightness of phosphenes by their brightness of the image at the corresponding location
2. A trained CNN-architecture, which is first pretrained on a computational model before being further trained by task performance.
   First, the weights of a CNN image decoder network are trained on the original digit images to classify digits.
   The weights of the image decoder network are then kept stable.
   Then, an image encoder network (which feeds into the selected phosphene renderer) is placed between the image and the decoder.
   The weights of the image encoder network are then trained to optimise the performance of the stable image decoder network, which now sees the phosphene render.
   This pretrained image encoder network is then used as the base image processor.

The 3 simulated phosphene renderers, informed by Section [[sec:see]] of this literature review, will be:
1. A regular log-polar grid of 100 circular Gaussian-blurred phosphenes
2. A base grid comprising Render 1, with a random set of per-phosphene distortions of phosphene shape, size, location, colour, and multiplicity
3. A base grid comprising  Render 2, with non-linear phosphene interactions  (i.e. multiple simultaneous phosphenes produce dropout of nearby dimmer phosphenes)

These combinations are summarised in Figure  [[fig:experiment]]

#+NAME: fig:experiment
#+CAPTION: Basic overview of the processor and renderer combinations to be tested in this experiment. Figure made by the author.
[[file:./graphics/litreview/experiment.png]]

There are a total of 6 combinations of phosphene renderers and image processing methods.
The regular-grid, brightness-based combination will serve as the control for this experiment.

*** Experimental Phase (Jul - Sep)

The full methods of this phase will be informed by progress during the planning phase in May and June.

10 normal-sighted participants will be recruited from students and staff at Monash University and informed consent will be obtained for a psychophysics study.
Each participant will be allocated to the control combination of phosphene and renderer, and one of the remaining five combinations of phosphene renderer/image processing method, for a total of two participants per non-control combination.

Each participant will be introduced to a psychophysics room with a computer graphical display.
Each participant will undergo a training and a testing phase.
During the training phase, the participant is shown a single digit and is asked to input what they believe is the correct digit.
They will receive feedback on their response with the intention to improve their ability to recognise patterns as would occur during the training phase for actual implantees.
The participant will repeat this process for 30 trials of 20 digits, subject to pilot trials in early July.
During this training phase, if the participant is allocated to the CNN group, the encoder will iteratively modify its network weights based on the correctness of the responses of the participant.

During the testing phase, the participant will undergo the same process of classifying a single digit, but without feedback.
The accuracy of classification during the testing phase will be recorded.
The classification accuracy of the CNN model with the brightness-based image processor wil be evaluated with a t-test separately for each phosphene renderer to address Hypothesis 1.
The classification accuracy of each image processor across renderers will be compared with an ANOVA to address Hypothesis 2.

#+LATEX: \clearpage

bibliographystyle:vancouver
bibliography:refs.bib
