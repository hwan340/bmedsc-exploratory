
@article{dobelle_artificial_1974,
	title = {Artificial {Vision} for the {Blind}: {Electrical} {Stimulation} of {Visual} {Cortex} {Offers} {Hope} for a {Functional} {Prosthesis}},
	volume = {183},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Artificial {Vision} for the {Blind}},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.183.4123.440},
	doi = {10.1126/science.183.4123.440},
	language = {en},
	number = {4123},
	urldate = {2019-05-01},
	journal = {Science},
	author = {Dobelle, W. H. and Mladejovsky, M. G. and Girvin, J. P.},
	month = feb,
	year = {1974},
	pages = {440--444},
	annote = {Preliminary experiments on phosphenes elicitied by a grid of surface electrodes.
 
IMportantly pattern recognition is tested and had problems. 
 },
	file = {Dobelle et al. - 1974 - Artificial Vision for the Blind Electrical Stimul.pdf:/Users/wjmn/Zotero/storage/F54FQ3E2/Dobelle et al. - 1974 - Artificial Vision for the Blind Electrical Stimul.pdf:application/pdf}
}

@article{dobelle_braille_1976,
	title = {‘{Braille}’ reading by a blind volunteer by visual cortex stimulation},
	volume = {259},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/259111a0},
	doi = {10.1038/259111a0},
	language = {en},
	number = {5539},
	urldate = {2019-05-01},
	journal = {Nature},
	author = {Dobelle, Wm H. and Mladejovsky, Michael G. and Evans, Jerald R. and Roberts, T. S. and Girvin, J. P.},
	month = jan,
	year = {1976},
	pages = {111--112},
	annote = {Braille reading (same as 1979 patient?) for pattern recognition. Seems like it's possible.},
	file = {Dobelle et al. - 1976 - ‘Braille’ reading by a blind volunteer by visual c.pdf:/Users/wjmn/Zotero/storage/UP5BIJSI/Dobelle et al. - 1976 - ‘Braille’ reading by a blind volunteer by visual c.pdf:application/pdf}
}

@article{dobelle_mapping_1979,
	title = {Mapping the {Representation} of the {Visual} {Field} by {Electrical} {Stimulation} of {Human} {Visual} {Cortex}},
	volume = {88},
	issn = {00029394},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0002939479906731},
	doi = {10.1016/0002-9394(79)90673-1},
	language = {en},
	number = {4},
	urldate = {2019-05-02},
	journal = {American Journal of Ophthalmology},
	author = {Dobelle, Wm. H. and Turkel, Joseph and Henderson, David C. and Evans, Jerald R.},
	month = oct,
	year = {1979},
	pages = {727--735},
	annote = {Extensive mapping of the phosphene and brain
1. Calcarine sulcus is important. Par of the sulcus is inaccessible, so there'll be a gap (at least for surface electrodes). The sulcus separates upper and lower visual fields. 
2. Further away from occipital pole = more eccentric.
3. There "may" be a way to actually get some regular ordering of phosphenes...maybe? There seem to be soe rough patterns...},
	file = {Dobelle et al. - 1979 - Mapping the Representation of the Visual Field by .pdf:/Users/wjmn/Zotero/storage/R4WXCU6T/Dobelle et al. - 1979 - Mapping the Representation of the Visual Field by .pdf:application/pdf}
}

@inproceedings{rushton_properties_1978,
	series = {Springer {Series} in {Optical} {Sciences}},
	title = {Properties of {Cortical} {Electrical} {Phosphenes}},
	isbn = {978-3-540-35397-3},
	abstract = {The second patient with an inductively-linked visual prosthetic implant (F.B.) has now been tested at intervals for 5 1/2 years. Reports on this patient have considered the extent of visual cortex that gives fixed phosphenes (1); mapping methods and phosphene Braille reading (2); the degree of stability of phosphenes in the map (3); aspects of the representation of the visual field (4); and a method for generating an optimum phosphene map from a large number of observations of the relations between phosphene pairs (5).},
	language = {en},
	booktitle = {Frontiers in {Visual} {Science}},
	publisher = {Springer Berlin Heidelberg},
	author = {Rushton, D. N. and Brindley, G. S.},
	editor = {Cool, Steven J. and Smith, Earl L.},
	year = {1978},
	keywords = {Difference Threshold, Pulse Current, Pulse Frequency, Pulse Length, Pulse Repetition Rate},
	pages = {574--593},
	annote = {Second patient, FB, looking at stimulus parameters and how they affect phosphene brightness etc. 
 },
	file = {Rushton-Brindley1978_Chapter_PropertiesOfCorticalElectrical.pdf:/Users/wjmn/Zotero/storage/5RAFBCUK/Rushton-Brindley1978_Chapter_PropertiesOfCorticalElectrical.pdf:application/pdf}
}

@article{brindley_sensations_1968,
	title = {The sensations produced by electrical stimulation of the visual cortex},
	volume = {196},
	issn = {00223751},
	url = {http://doi.wiley.com/10.1113/jphysiol.1968.sp008519},
	doi = {10.1113/jphysiol.1968.sp008519},
	language = {en},
	number = {2},
	urldate = {2019-05-03},
	journal = {The Journal of Physiology},
	author = {Brindley, G. S. and Lewin, W. S.},
	month = may,
	year = {1968},
	pages = {479--493},
	file = {Brindley and Lewin - 1968 - The sensations produced by electrical stimulation .pdf:/Users/wjmn/Zotero/storage/57IF2GLJ/Brindley and Lewin - 1968 - The sensations produced by electrical stimulation .pdf:application/pdf}
}

@incollection{berlucchi_sensory_1973,
	address = {Berlin, Heidelberg},
	title = {Sensory {Effects} of {Electrical} {Stimulation} of the {Visual} and {Paravisual} {Cortex} in {Man}},
	volume = {7 / 3 / 3 B},
	isbn = {978-3-642-65497-8 978-3-642-65495-4},
	url = {http://link.springer.com/10.1007/978-3-642-65495-4_14},
	language = {en},
	urldate = {2019-05-03},
	booktitle = {Visual {Centers} in the {Brain}},
	publisher = {Springer Berlin Heidelberg},
	author = {Brindley, Giles S.},
	editor = {Jung, Richard},
	collaborator = {Berlucchi, G. and Brindley, G. S. and Brooks, B. and Creutzfeldt, O. D. and Dodt, E. and Doty, R. W. and Freund, H.-J. and Gross, C. G. and Jeffreys, D. A. and Jung, R. and Kuhnt, U. and MacKay, D. M. and Marg, E. and Negrão, N. and Rizzolatti, G. and Sprague, J. M. and Székely, G. and Szentágothai, J. and Whitteridge, D.},
	year = {1973},
	doi = {10.1007/978-3-642-65495-4_14},
	pages = {583--594},
	file = {Brindley - 1973 - Sensory Effects of Electrical Stimulation of the V.pdf:/Users/wjmn/Zotero/storage/9ACVIXK9/Brindley - 1973 - Sensory Effects of Electrical Stimulation of the V.pdf:application/pdf}
}

@article{dobelle_phosphenes_1974,
	title = {Phosphenes produced by electrical stimulation of human occipital cortex, and their application to the development of a prosthesis for the blind},
	volume = {243},
	issn = {00223751},
	url = {http://doi.wiley.com/10.1113/jphysiol.1974.sp010766},
	doi = {10.1113/jphysiol.1974.sp010766},
	language = {en},
	number = {2},
	urldate = {2019-05-03},
	journal = {The Journal of Physiology},
	author = {Dobelle, W. H. and Mladejovsky, M. G.},
	month = dec,
	year = {1974},
	pages = {553--576},
	annote = {Comprehensive look at phosphene properties. Some interest effects ("pinwheels") and spinning on multiple phosphenes shown,},
	file = {Dobelle and Mladejovsky - 1974 - Phosphenes produced by electrical stimulation of h.pdf:/Users/wjmn/Zotero/storage/K8E2T6C4/Dobelle and Mladejovsky - 1974 - Phosphenes produced by electrical stimulation of h.pdf:application/pdf}
}

@article{bak_feasibility_nodate,
	title = {Feasibility of a visual prosthesis for the blind based on intracorticai microstimulation of the visual cortex},
	language = {en},
	author = {Bak, M J and Hambrecht, F T and Kufta, C V and O'Rourke, D K and Vallabhanath, P},
	pages = {16},
	file = {Bak et al. - Feasibility of a visual prosthesis for the blind b.pdf:/Users/wjmn/Zotero/storage/Z8UQPZIM/Bak et al. - Feasibility of a visual prosthesis for the blind b.pdf:application/pdf}
}

@article{dobelle_artificial_2000,
	title = {Artificial {Vision} for the {Blind} by {Connecting} a {Television} {Camera} to the {Visual} {Cortex}},
	volume = {46},
	issn = {1058-2916},
	url = {https://journals.lww.com/asaiojournal/Fulltext/2000/01000/Artificial_Vision_for_the_Blind_by_Connecting_a.2.aspx},
	abstract = {Blindness is more feared by the public than any ailment with the exception of cancer and AIDS. We report the development of the first visual prosthesis providing useful “artificial vision” to a blind volunteer by connecting a digital video camera, computer, and associated electronics to the visual cortex of his brain. This device has been the objective of a development effort begun by our group in 1968 and represents realization of the prediction of an artificial vision system made by Benjamin Franklin in his report on the “kite and key” experiment, with which he discovered electricity in 1751.*},
	language = {en-US},
	number = {1},
	urldate = {2019-05-03},
	journal = {ASAIO Journal},
	author = {Dobelle, Wm H.},
	month = feb,
	year = {2000},
	pages = {3},
	annote = {Chronic follow up of a patient 20 years post implantation. 
He's able to do things like read letters at visual acuity of 20/1200},
	file = {Snapshot:/Users/wjmn/Zotero/storage/8J5Q38CW/Artificial_Vision_for_the_Blind_by_Connecting_a.2.html:text/html}
}

@article{winawer_linking_2016,
	title = {Linking {Electrical} {Stimulation} of {Human} {Primary} {Visual} {Cortex}, {Size} of {Affected} {Cortical} {Area}, {Neuronal} {Responses}, and {Subjective} {Experience}},
	volume = {92},
	issn = {08966273},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316308467},
	doi = {10.1016/j.neuron.2016.11.008},
	abstract = {Electrical brain stimulation (EBS) complements neural measurements by probing the causal relationship between brain and perception, cognition, and action. Many fundamental questions about EBS remain unanswered, including the spatial extent of cortex responsive to stimulation, and the relationship between the circuitry engaged by EBS and the types of neural responses elicited by sensory stimulation. Here, we measured neural responses and the effects of EBS in primary visual cortex in four patients implanted with intracranial electrodes. Using stimulation, behavior, and retinotopic mapping, we show the relationship between the size of affected cortical area and the magnitude of electrical charge. Furthermore, we show that the spatial location of electrically induced visual sensations is matched to the receptive ﬁeld of the cortical site measured with broadband ﬁeld potentials, and less so with event related potentials. Together, these ﬁndings broaden our knowledge about the mechanism of EBS and the neuromodulation of the human brain.},
	language = {en},
	number = {6},
	urldate = {2019-05-03},
	journal = {Neuron},
	author = {Winawer, Jonathan and Parvizi, Josef},
	month = dec,
	year = {2016},
	pages = {1213--1219},
	annote = {Basically show that:
1. Size increases with charge, and
2. Mappings follow receptive fields.},
	file = {Winawer and Parvizi - 2016 - Linking Electrical Stimulation of Human Primary Vi.pdf:/Users/wjmn/Zotero/storage/TTG8NH4F/Winawer and Parvizi - 2016 - Linking Electrical Stimulation of Human Primary Vi.pdf:application/pdf;Winawer and Parvizi - 2016 - Linking Electrical Stimulation of Human Primary Vi.pdf:/Users/wjmn/Zotero/storage/DEZARXN7/Winawer and Parvizi - 2016 - Linking Electrical Stimulation of Human Primary Vi.pdf:application/pdf}
}

@article{beauchamp_dynamic_2018,
	title = {Dynamic {Electrical} {Stimulation} of {Sites} in {Visual} {Cortex} {Produces} {Form} {Vision} in {Sighted} and {Blind} {Humans}},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/462697v1},
	doi = {10.1101/462697},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Visual cortical prosthetics (VCPs) offer the promise of restoring sight to blind patients. Electrical stimulation of a single site in visual cortex can reliably produce a percept of a spot of light in a fixed visual field location, known as a phosphene. Researchers developing VCPs have assumed that multiple phosphenes produced by concurrent stimulation of multiple sites in visual cortex can combine to form a coherent form, like pixels in a visual display. However, existing data do not support this assumption. Therefore, we developed a novel stimulation paradigm for VCPs termed \textit{dynamic current steering} in which the visual form to be conveyed is traced on the surface of visual cortex by electrically stimulating electrodes in a dynamic sequence. When tested in sighted and blind subjects, this method of stimulating visual cortex allowed for the immediate recognition of a variety of letter shapes without training and with high accuracy.{\textless}/p{\textgreater}{\textless}h3{\textgreater}One Sentence Summary{\textless}/h3{\textgreater} {\textless}p{\textgreater}Stimulating human visual cortex using dynamic patterns of activity allows both blind and sighted patients to perceive visual percepts of useful forms.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-03},
	journal = {bioRxiv},
	author = {Beauchamp, Michael S. and Bosking, William and Sun, Ping and Foster, Brett and Niketeghad, Soroush and Pouratian, Nader and Yoshor, Daniel},
	month = nov,
	year = {2018},
	pages = {462697},
	annote = {Had issues trying to get people to interpret multiple simultaneous phosphenes (but it's not clear to me whether they actually tried to get people to interpret letters like they did here with simultaneous?)
 },
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/38NF7SJS/Beauchamp et al. - 2018 - Dynamic Electrical Stimulation of Sites in Visual .pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/CMX7IUX4/462697v1.html:text/html}
}

@article{schmidt_feasibility_1996,
	title = {Feasibility of a visual prosthesis for the blind based on intracortical micro stimulation of the visual cortex},
	volume = {119},
	issn = {0006-8950},
	url = {https://academic.oup.com/brain/article/119/2/507/382434},
	doi = {10.1093/brain/119.2.507},
	abstract = {Abstract.  The feasibility of producing a visual prosthesis for the blind using intracortical microstimulation (ICMS) of the visual cortex was studied in a 42-y},
	language = {en},
	number = {2},
	urldate = {2019-05-03},
	journal = {Brain},
	author = {Schmidt, E. M. and Bak, M. J. and Hambrecht, F. T. and Kufta, C. V. and O'Rourke, D. K. and Vallabhanath, P.},
	month = apr,
	year = {1996},
	pages = {507--522},
	annote = {Comprehensive study on stimulation with microelectrodes. Basically discusses everything...
A lot of it is related to parameters. },
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/LGC7ZQK6/Schmidt et al. - 1996 - Feasibility of a visual prosthesis for the blind b.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/ZCEFICG4/382434.html:text/html}
}

@article{bak_visual_1990,
	title = {Visual sensations produced by intracortical microstimulation of the human occipital cortex},
	volume = {28},
	doi = {10.1007/BF02442682},
	journal = {Medical and Biological Engineering and Computing},
	author = {Bak, Martin and Girvin, JohnP and Hambrecht, Dr F. T. and Kufta, Conrad V. and Loeb, Gerald Eli and Schmidt, Edward M.},
	year = {1990},
	keywords = {Occipital lobe, Optic Nerve Glioma, Childhood},
	pages = {257--259},
	annote = {A starting study in the quality of phosphenes produced by microstimulation vs surface stimulation.
 },
	file = {Bak1990_Article_VisualSensationsProducedByIntr.pdf:/Users/wjmn/Zotero/storage/6IGH2I2J/Bak1990_Article_VisualSensationsProducedByIntr.pdf:application/pdf}
}

@article{dobelle_artificial_1979,
	title = {Artificial vision for the blind by electrical stimulation of the visual cortex},
	volume = {5},
	issn = {0148-396X},
	abstract = {Artificial vision for the blind may be feasible by interfacing a television camera with electronics stimulating the visual cortex. The status of a major collaborative effort involving the College of Physicians and Surgeons of Columbia University, the University of Utah, and the University of Western Ontario is reviewed. Results have been very encouraging, although much work remains to be done.},
	language = {eng},
	number = {4},
	journal = {Neurosurgery},
	author = {Dobelle, W. H. and Quest, D. O. and Antunes, J. L. and Roberts, T. S. and Girvin, J. P.},
	month = oct,
	year = {1979},
	pmid = {534058},
	keywords = {Blindness, Electric Stimulation, Electrodes, Implanted, Humans, Phosphenes, Sensory Aids, Visual Cortex},
	pages = {521--527},
	annote = {Mostly just a review of Dobelle's research by Dobelle.
 },
	file = {00006123-197910000-00022.pdf:/Users/wjmn/Zotero/storage/ERRRB6WG/00006123-197910000-00022.pdf:application/pdf}
}

@article{murphey_perceiving_2009,
	title = {Perceiving electrical stimulation of identified human visual areas},
	volume = {106},
	copyright = {© 2009},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/106/13/5389},
	doi = {10.1073/pnas.0804998106},
	abstract = {We studied whether detectable percepts could be produced by electrical stimulation of intracranial electrodes placed over human visual areas identified with fMRI. Identification of areas was confirmed by recording local-field potentials from the electrode, such as face-selective electrical responses from electrodes over the fusiform face area (FFA). The probability of detecting electrical stimulation of a visual area varied with the position of the area in the visual cortical hierarchy. Stimulation of early visual areas including V1, V2, and V3 was almost always detected, whereas stimulation of late visual areas such as FFA was rarely detected. When percepts were elicited from late areas, subjects reported that they were simple shapes and colors, similar to the descriptions of percepts from early areas. There were no reports of elaborate percepts, such as faces, even in areas like FFA, where neurons have complex response properties. For sites eliciting percepts, the detection threshold was determined by varying the stimulation current as subjects performed a forced-choice detection task. Current thresholds were similar for late and early areas. The similarity between both percept quality and threshold across early and late areas suggests the presence of functional microcircuits that link electrical stimulation with perception.},
	language = {en},
	number = {13},
	urldate = {2019-05-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Murphey, Dona K. and Maunsell, John H. R. and Beauchamp, Michael S. and Yoshor, Daniel},
	month = mar,
	year = {2009},
	pmid = {19276119},
	keywords = {fMRI, human visual cortex, visual perception},
	pages = {5389--5393},
	annote = {Looked at different visual areas. 
1. VIsual areas generally produced relatively simple percepts, even later ones (though some interesting percepts are noted)
2. Authors raise some very good points e.g. subjective reports may be the same/different for different/same percepts, differences between penetrating and surface elctrode studies, TRAINING may be significant difference that may eventually produce percepts/different percepts in places which had no percepts originally. ALso, particularly in late areas, stimulation may be uninterpretable (with blindfold on) but might affect perception if actually viewing things.},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/HN42ECUS/Murphey et al. - 2009 - Perceiving electrical stimulation of identified hu.pdf:application/pdf;Murphey et al. - 2009 - Perceiving electrical stimulation of identified hu.pdf:/Users/wjmn/Zotero/storage/MAFUN4Z8/Murphey et al. - 2009 - Perceiving electrical stimulation of identified hu.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/PH73H8PL/5389.html:text/html}
}

@techreport{bosking_rules_2018,
	type = {preprint},
	title = {Rules {Governing} {Perception} of {Multiple} {Phosphenes} by {Human} {Observers}},
	url = {http://biorxiv.org/lookup/doi/10.1101/302547},
	abstract = {Stimulation of single sites in primary visual cortex results in the perception of a small flash of light known as a phosphene. Little is known about how phosphenes from multiple electrodes can be combined to form perception of coherent patterns. Here we examine the percepts reported by human observers as various spatial configurations of 2 to 5 electrodes in visual cortex were stimulated simultaneously. When two electrodes were stimulated simultaneously, subjects reliably perceived either one or two phosphenes depending on the physical distance separating the electrodes. In cases where two phosphenes were perceived, they were located in the same visual field location as when the two electrodes were stimulated separately. Adding a third electrode produced similar results. In several subjects, we obtained combination of 4 to 5 electrodes that generated individual phosphenes when stimulated concurrently. Subjects were able to reliably discriminate between different multiple electrode stimulation patterns that were presented in random order. These results demonstrate that simple pattern information can be conveyed to subjects with surface electrodes spaced at millimeters apart on the cortex.},
	language = {en},
	urldate = {2019-05-03},
	institution = {Neuroscience},
	author = {Bosking, William H and Foster, Brett and Sun, Ping and Beauchamp, Michael S and Yoshor, Daniel},
	month = apr,
	year = {2018},
	doi = {10.1101/302547},
	annote = {1. Phosphenes elicited simultaneously have slightly different features (decrease in size, increase in separation)...maybe?
2. Simultaneously stimulating phosphenes can be interpreted as patterns above chance (BUT THE ANALYSIS OF THIS IS VERY CURSORY, YET THIS IS THE MAIN POINT OF THE ABSTRACT...).
 },
	file = {Bosking et al. - 2018 - Rules Governing Perception of Multiple Phosphenes .pdf:/Users/wjmn/Zotero/storage/2AR6HC45/Bosking et al. - 2018 - Rules Governing Perception of Multiple Phosphenes .pdf:application/pdf}
}

@article{bosking_saturation_2017,
	title = {Saturation in {Phosphene} {Size} with {Increasing} {Current} {Levels} {Delivered} to {Human} {Visual} {Cortex}},
	volume = {37},
	issn = {1529-2401},
	doi = {10.1523/JNEUROSCI.2896-16.2017},
	abstract = {Electrically stimulating early visual cortex results in a visual percept known as a phosphene. Although phosphenes can be evoked by a wide range of electrode sizes and current amplitudes, they are invariably described as small. To better understand this observation, we electrically stimulated 93 electrodes implanted in the visual cortex of 13 human subjects who reported phosphene size while stimulation current was varied. Phosphene size increased as the stimulation current was initially raised above threshold, but then rapidly reached saturation. Phosphene size also depended on the location of the stimulated site, with size increasing with distance from the foveal representation. We developed a model relating phosphene size to the amount of activated cortex and its location within the retinotopic map. First, a sigmoidal curve was used to predict the amount of activated cortex at a given current. Second, the amount of active cortex was converted to degrees of visual angle by multiplying by the inverse cortical magnification factor for that retinotopic location. This simple model accurately predicted phosphene size for a broad range of stimulation currents and cortical locations. The unexpected saturation in phosphene sizes suggests that the functional architecture of cerebral cortex may impose fundamental restrictions on the spread of artificially evoked activity and this may be an important consideration in the design of cortical prosthetic devices.SIGNIFICANCE STATEMENT Understanding the neural basis for phosphenes, the visual percepts created by electrical stimulation of visual cortex, is fundamental to the development of a visual cortical prosthetic. Our experiments in human subjects implanted with electrodes over visual cortex show that it is the activity of a large population of cells spread out across several millimeters of tissue that supports the perception of a phosphene. In addition, we describe an important feature of the production of phosphenes by electrical stimulation: phosphene size saturates at a relatively low current level. This finding implies that, with current methods, visual prosthetics will have a limited dynamic range available to control the production of spatial forms and that more advanced stimulation methods may be required.},
	language = {eng},
	number = {30},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	author = {Bosking, William H. and Sun, Ping and Ozker, Muge and Pei, Xiaomei and Foster, Brett L. and Beauchamp, Michael S. and Yoshor, Daniel},
	year = {2017},
	pmid = {28652411},
	pmcid = {PMC5546398},
	keywords = {Electric Stimulation, Humans, Phosphenes, Visual Cortex, Adult, direct cortical stimulation, electrical brain stimulation, electrical stimulation, Evoked Potentials, Visual, Female, magnification factor, Male, Middle Aged, Nerve Net, phosphene, visual cortex, Visual Fields},
	pages = {7188--7197},
	annote = {Phosphene size varies with current (to a saturation point) and cortical magnification factor. },
	file = {Full Text:/Users/wjmn/Zotero/storage/JAAQISE8/Bosking et al. - 2017 - Saturation in Phosphene Size with Increasing Curre.pdf:application/pdf}
}

@inproceedings{gerboni_cortical_2018,
	title = {Cortical {Brain} {Stimulation} with {Endovascular} {Electrodes}},
	doi = {10.1109/EMBC.2018.8512971},
	abstract = {Electrical stimulation of neural tissue and recording of neural activity are the bases of emerging prostheses and treatments for spinal cord injury, stroke, sensory deficits, and drug-resistant neurological disorders. Safety and efficacy are key aspects for the clinical acceptance of therapeutic neural stimulators. The cortical vasculature has been shown to be a safe site for implantation of electrodes for chronically recording neural activity, requiring no craniotomy to access high-bandwidth, intracranial EEG. This work presents the first characterization of endovascular cortical stimulation measured using cortical subdural surface recordings. Visual stimulation was used to verify electrode viability and cortical activation was compared with electrically evoked activity. Due to direct activation of the neural tissue, the latency of responses to electrical stimulation was shorter than for that of visual stimulation. We also found that the center of neural activation was different for visual and electrical stimulation indicating an ability of the stentrode to provide localized activation of neural tissue.},
	booktitle = {2018 40th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Gerboni, G. and John, S. E. and Ronayne, S. M. and Rind, G. S. and May, C. N. and Oxley, T. J. and Grayden, D. B. and Opie, N. L. and Wong, Y. T.},
	month = jul,
	year = {2018},
	keywords = {electrical stimulation, Animals, Band-pass filters, bioelectric phenomena, biological tissues, biomedical electrodes, cortical activation, cortical brain stimulation, cortical subdural surface recordings, cortical vasculature, direct activation, drug-resistant neurological disorders, drugs, Electric potential, Electrical stimulation, electrically evoked activity, electrode viability, Electrodes, electroencephalography, endovascular cortical stimulation, endovascular electrodes, high-bandwidth intracranial EEG, injuries, localized activation, neural activation, neural activity, Neural activity, neural tissue, neurophysiology, spinal cord injury, stentrode, stents, therapeutic neural stimulators, visual stimulation, Visualization},
	pages = {3088--3091},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/M2DCUK7N/8512971.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/7ET2NARD/Gerboni et al. - 2018 - Cortical Brain Stimulation with Endovascular Elect.pdf:application/pdf}
}

@article{bartlett_exploration_1980,
	title = {An exploration of the ability of macaques to detect microstimulation of striate cortex},
	volume = {40},
	issn = {0065-1400},
	abstract = {With its head steadied within a form-fitting mask, a macaque was first taught to signal when it detected the application of 0.2-ms electrical pulses at 50 Hz through electrodes chronically implanted within its striate cortex. Stimuli were then applied via a movable microelectrode and the threshold for the animals detection determined at intervals of 50-250 micrometers. With permanently implanted 130- 200-micrometers diameter electrodes such thresholds range between 50 and 250 microamperes (and are highly stable), whereas with the microelectrodes sites were encountered, estimated to be primarily within cortical layers V-VI, where the monkey could reliably detect as little as 2-4 microamperes. The threshold at most sites within striate cortex with the microelectrode, however, was 15-25 microamperes. Background unit activity recorded with the microelectrode varied greatly in different laminae and survived the microstimulation, but has so far provided no clear basis for predicting threshold. It is tentatively hypothesized that the relatively rare points where the threshold is as much as 10 times less than that in the surround arise because the giant, solitary cells of Meynert provide the exclusively effective output for the behavioral response. This hypothesis would also explain the singular uniformity of sensation (a "phosphene") evoked in human subjects by such stimuli, and the equivalence of all such stimuli in striate cortex found for the macaque.},
	language = {eng},
	number = {4},
	journal = {Acta Neurobiologiae Experimentalis},
	author = {Bartlett, J. R. and Doty, R. W.},
	year = {1980},
	pmid = {7435271},
	keywords = {Electric Stimulation, Visual Cortex, Male, Animals, Macaca nemestrina, Perception},
	pages = {713--727},
	file = {Bartlett and Doty - 1980 - An Exploration of the Ability of Macaques to Detec.pdf:/Users/wjmn/Zotero/storage/J46GTL52/Bartlett and Doty - 1980 - An Exploration of the Ability of Macaques to Detec.pdf:application/pdf}
}

@article{fernandes_artificial_2012,
	series = {Bioengineering {Approaches} to {Nervous} {System} {Repair}},
	title = {Artificial vision through neuronal stimulation},
	volume = {519},
	issn = {0304-3940},
	url = {http://www.sciencedirect.com/science/article/pii/S0304394012001449},
	doi = {10.1016/j.neulet.2012.01.063},
	abstract = {Introduction
The term visual prosthesis refers to any device capable of eliciting visual percepts in an individual through electrical stimulation of any part of the visual system.
Background
Blindness can be due to eye pathology or due to damage of the lateral geniculate or visual cortex. Eye pathology other than diseases that affect the cornea and lens are numerous and some of the leading causes are diabetic retinopathy, age-related macular degeneration, retinal detachment, glaucoma, and retinal vascular occlusions. The visual prosthesis can be divided into non-retinal and retinal approaches. Non-retinal approaches include cortical and optic nerve prosthesis. Retinal approaches are aimed at eye pathologies in which at least part of the optic nerve remains intact whereas when the optic nerve is nearly completely damaged and/or the eye itself is disfigured or degenerated then a non-retinal approach is warranted. The retinal prosthesis can be placed on the surface of the retina, in the subretinal space or in the suprachoroidal space.
Results
Several independent groups related variable degrees of success in promoting visual sensations through electrical stimulation of the visual system. Every technique, equipment and anatomical target has its advantages and disadvantages, and the biological/electrical–mechanical interface is still the aspect of the research towards a chronic, long term, reliable biomimetic implant.
Conclusions
The visual prostheses have achieved significant developments in recent years. We see continued improvement in visual acuity with increasing number and density of electrodes. Even though the visual acuity is still poor relative to normal vision, these subjects can read letters using their implants. Perhaps more importantly, blind patients can use these devices for mobility and orientation.},
	number = {2},
	urldate = {2019-05-03},
	journal = {Neuroscience Letters},
	author = {Fernandes, Rodrigo A. Brant and Diniz, Bruno and Ribeiro, Ramiro and Humayun, Mark},
	month = jun,
	year = {2012},
	keywords = {Blindness, Artificial vision, Retinal prosthesis, Visual prosthesis},
	pages = {122--128},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/GKM4C3ZE/Fernandes et al. - 2012 - Artificial vision through neuronal stimulation.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/LZMVDZJH/S0304394012001449.html:text/html}
}

@inproceedings{troyk_intracortical_2005,
	title = {Intracortical {Visual} {Prosthesis} {Research} - {Approach} and {Progress}},
	doi = {10.1109/IEMBS.2005.1616216},
	abstract = {Following the early work of Brindley in the late 1960's, the NIH began intramural and extramural funding for stimulation of the primary visual cortex using fine-wire electrodes that are inserted into area V1 for the purpose of restoring vision in individuals with blindness. More recently researchers with experience in this project became part of our multi-institutional team with the intention to identify and close technological gaps so that the intracortical approach might be tested in humans on a chronic basis. Our team has formulated an approach for testing a prototype system in a human volunteer. Here, we describe our progress and expectations},
	booktitle = {2005 {IEEE} {Engineering} in {Medicine} and {Biology} 27th {Annual} {Conference}},
	author = {Troyk, P. R. and Bradley, D. and Bak, M. and Cogan, S. and Erickson, R. and Hu, Z. and Kufta, C. and McCreery, D. and Schmidt, E. and Sung, S. and Towle, V.},
	month = jan,
	year = {2005},
	keywords = {biomedical electrodes, Visual prosthesis, AIROF, anodic bias, Biomedical engineering, blindness, charge-injection, fine-wire electrodes, intracortical visual prosthesis, iridium, microelectrodes, Microelectrodes, neural stimulation, primary visual cortex, prosthetics, vision defects, vision restoration, visual Prosthesis, waverforms},
	pages = {7376--7379},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/NJNWH7RW/1616216.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/2QMWNICR/Troyk et al. - 2005 - Intracortical Visual Prosthesis Research - Approac.pdf:application/pdf}
}

@article{musallam_floating_2007,
	title = {A floating metal microelectrode array for chronic implantation},
	volume = {160},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S016502700600450X},
	doi = {10.1016/j.jneumeth.2006.09.005},
	abstract = {Implantation of multi-electrode arrays is becoming increasingly more prevalent within the neuroscience research community and has become important for clinical applications. Many of these studies have been directed towards the development of sensory and motor prosthesis. Here, we present a multi-electrode system made from biocompatible material that is electrically and mechanically stable, and employs design features allowing flexibility in the geometric layout and length of the individual electrodes within the array. We also employ recent advances in laser machining of thin ceramic substrates, application of ultra-fine line gold conductors to ceramic, fabrication of extremely flexible cables, and fine wire management techniques associated with juxtaposing metal microelectrodes within a few hundred microns of each other in the development of a floating multi-electrode array (FMA). We implanted the FMA in rats and show that the FMA is capable of recording both spikes and local field potentials.},
	number = {1},
	urldate = {2019-05-03},
	journal = {Journal of Neuroscience Methods},
	author = {Musallam, Sam and Bak, Martin J. and Troyk, Philip R. and Andersen, Richard A.},
	month = feb,
	year = {2007},
	keywords = {Brain–machine interface, Multi-electrode arrays, Neural prosthesis, Rats},
	pages = {122--127},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/BA2227UF/Musallam et al. - 2007 - A floating metal microelectrode array for chronic .pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/WALKV6HG/S016502700600450X.html:text/html}
}

@inproceedings{lowery_restoration_2015,
	title = {Restoration of vision using wireless cortical implants: {The} {Monash} {Vision} {Group} project},
	shorttitle = {Restoration of vision using wireless cortical implants},
	doi = {10.1109/EMBC.2015.7318543},
	abstract = {Monash Vision Group is developing a bionic vision system based on implanting several small tiles in the V1 region of the visual cortex. This cortical approach could benefit a greater proportion of people with total blindness than other approaches, as it bypasses the eyes and optic nerve. Each tile has 43 active electrodes on its base, and a wirelessly powered electronic system to decode control signals and drive the electrodes with biphasic pulses. The tiles are fed with power and data using a common transmitting coil at the back of the patient's head. Sophisticated image processing, described in a companion paper, ensures that the user experiences maximum benefit from the small number of electrodes. This paper describes key features of this system.},
	booktitle = {2015 37th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Lowery, A. J. and Rosenfeld, J. V. and Lewis, P. M. and Browne, D. and Mohan, A. and Brunton, E. and Yan, E. and Maller, J. and Mann, C. and Rajan, R. and Rosa, M. and Pritchard, J.},
	month = aug,
	year = {2015},
	keywords = {Humans, Visual Cortex, visual cortex, biomedical electrodes, Electrodes, neurophysiology, Visualization, blindness, prosthetics, vision restoration, active electrodes, biomedical electronics, bionic vision system, Bionics, biphasic pulses, control signal decoding, eye, eyes, Image processing, Implants, medical image processing, Monash Vision Group project, optic nerve, Optical transmitters, patient head, Prostheses and Implants, Retina, sophisticated image processing, transmitting coil, V1 region, vision, Vision, Ocular, Wireless communication, wireless cortical implants, wirelessly powered electronic system},
	pages = {1041--1044},
	annote = {Description of MVG design.
1. Penetrating electrodes, 300 - 500 on tiles with 43 electrodes. 
2. Mention transformative reality processing.},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/H6YLJPBF/7318543.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/V2X9NRRI/Lowery et al. - 2015 - Restoration of vision using wireless cortical impl.pdf:application/pdf}
}

@article{fernandez_development_2005,
	title = {Development of a cortical visual neuroprosthesis for the blind: the relevance of neuroplasticity},
	volume = {2},
	issn = {1741-2552},
	shorttitle = {Development of a cortical visual neuroprosthesis for the blind},
	url = {https://doi.org/10.1088%2F1741-2560%2F2%2F4%2Fr01},
	doi = {10.1088/1741-2560/2/4/R01},
	abstract = {Clinical applications such as artificial vision require extraordinary, diverse, lengthy and intimate collaborations among basic scientists, engineers and clinicians. In this review, we present the state of research on a visual neuroprosthesis designed to interface with the occipital visual cortex as a means through which a limited, but useful, visual sense could be restored in profoundly blind individuals. We review the most important physiological principles regarding this neuroprosthetic approach and emphasize the role of neural plasticity in order to achieve desired behavioral outcomes. While full restoration of fine detailed vision with current technology is unlikely in the immediate near future, the discrimination of shapes and the localization of objects should be possible allowing blind subjects to navigate in a unfamiliar environment and perhaps even to read enlarged text. Continued research and development in neuroprosthesis technology will likely result in a substantial improvement in the quality of life of blind and visually impaired individuals.},
	language = {en},
	number = {4},
	urldate = {2019-05-03},
	journal = {Journal of Neural Engineering},
	author = {Fernández, E. and Pelayo, F. and Romero, S. and Bongard, M. and Marin, C. and Alfaro, A. and Merabet, L.},
	month = nov,
	year = {2005},
	pages = {R1--R12},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/LE798TGP/Fernández et al. - 2005 - Development of a cortical visual neuroprosthesis f.pdf:application/pdf}
}

@article{puce_electrophysiological_1999,
	title = {Electrophysiological {Studies} of {Human} {Face} {Perception}. {III}: {Effects} of {Top}-down {Processing} on {Face}-specific {Potentials}},
	volume = {9},
	issn = {1047-3211},
	shorttitle = {Electrophysiological {Studies} of {Human} {Face} {Perception}. {III}},
	url = {https://academic.oup.com/cercor/article/9/5/445/310738},
	doi = {10.1093/cercor/9.5.445},
	abstract = {Abstract.  This is the last in a series of papers dealing with intracranial event-related potential (ERP) correlates of face perception. Here we describe the re},
	language = {en},
	number = {5},
	urldate = {2019-05-03},
	journal = {Cerebral Cortex},
	author = {Puce, Aina and Allison, Truett and McCarthy, Gregory},
	month = jul,
	year = {1999},
	pages = {445--458},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/D8YBNAIB/Puce et al. - 1999 - Electrophysiological Studies of Human Face Percept.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/7MCJH5EC/310738.html:text/html}
}

@article{tong_primary_2003,
	title = {Primary visual cortex and visual awareness},
	volume = {4},
	copyright = {2003 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1055},
	doi = {10.1038/nrn1055},
	abstract = {There are two main theories that pertain to the role of the primary visual cortex (V1) in visual awareness. Hierarchical models propose that although V1 provides necessary input, only high-level extrastriate areas that project to frontal-parietal attentional areas are directly involved in awareness. Interactive models propose that dynamic recurrent circuits between V1 and higher areas are necessary to maintain a visual representation in awareness. These models yield different predictions about whether awareness will be impaired by V1 disruption if extrastriate activity remains intact. 
                  
                  
                    V1 damage severely impairs visual awareness, indicating that this region is necessary for normal conscious vision. Lesions to extrastriate areas lead to more specific visual deficits, whereas damage to parietal and/or superior-temporal areas can lead to gross visual neglect of contralateral space. Therefore, no single brain area is sufficient for visual awareness. Nonetheless, V1 seems to be the only single cortical area that is crucial for visual awareness. 
                  
                  
                    Some subjects with V1 lesions can make accurate forced-choice visual discriminations in the absence of reported awareness. These implicit residual abilities (blindsight) presumably reflect the sustained activity that is found in many extrastriate areas, including motion-sensitive areas MT and V3A, and object-sensitive areas V4/V8 and the lateral occipital area. Similarly, motion phosphenes elicited by transcranial magnetic stimulation of area MT can be disrupted by subsequent stimulation to V1, indicating that extrastriate activity alone might be insufficient for awareness and that feedback projections from MT to V1 may be important for awareness of motion. 
                  
                  
                    V1 activity is strongly associated with awareness under certain ambiguous perceptual conditions. During binocular rivalry, awareness spontaneously alternates between two competing monocular images. Human neuroimaging studies have revealed strong awareness-related modulations in V1 during rivalry. Likewise, neurophysiological and functional magnetic resonance imaging studies of visual detection tasks have found that V1 activity is greater for perceived than unperceived targets, and that the degree of response enhancement can predict detection performance. 
                  
                  
                    However, not all studies have found a consistent relationship between V1 activity and awareness, including those of internally generated visual experiences (such as hallucinations, dreaming or imagery). In some studies, changes in perception are associated with increased extrastriate activity and concomitant decreases in V1 activity, indicating a more complex relationship. 
                  
                  
                    Current evidence indicates that V1 activity is necessary for normal conscious perception and is closely associated with some forms of visual awareness. Further investigation of V1 and its interactions with higher areas might provide important insights into the neural basis of visual awareness.
                  
                
               There are two main theories that pertain to the role of the primary visual cortex (V1) in visual awareness. Hierarchical models propose that although V1 provides necessary input, only high-level extrastriate areas that project to frontal-parietal attentional areas are directly involved in awareness. Interactive models propose that dynamic recurrent circuits between V1 and higher areas are necessary to maintain a visual representation in awareness. These models yield different predictions about whether awareness will be impaired by V1 disruption if extrastriate activity remains intact.  V1 damage severely impairs visual awareness, indicating that this region is necessary for normal conscious vision. Lesions to extrastriate areas lead to more specific visual deficits, whereas damage to parietal and/or superior-temporal areas can lead to gross visual neglect of contralateral space. Therefore, no single brain area is sufficient for visual awareness. Nonetheless, V1 seems to be the only single cortical area that is crucial for visual awareness.  Some subjects with V1 lesions can make accurate forced-choice visual discriminations in the absence of reported awareness. These implicit residual abilities (blindsight) presumably reflect the sustained activity that is found in many extrastriate areas, including motion-sensitive areas MT and V3A, and object-sensitive areas V4/V8 and the lateral occipital area. Similarly, motion phosphenes elicited by transcranial magnetic stimulation of area MT can be disrupted by subsequent stimulation to V1, indicating that extrastriate activity alone might be insufficient for awareness and that feedback projections from MT to V1 may be important for awareness of motion.  V1 activity is strongly associated with awareness under certain ambiguous perceptual conditions. During binocular rivalry, awareness spontaneously alternates between two competing monocular images. Human neuroimaging studies have revealed strong awareness-related modulations in V1 during rivalry. Likewise, neurophysiological and functional magnetic resonance imaging studies of visual detection tasks have found that V1 activity is greater for perceived than unperceived targets, and that the degree of response enhancement can predict detection performance.  However, not all studies have found a consistent relationship between V1 activity and awareness, including those of internally generated visual experiences (such as hallucinations, dreaming or imagery). In some studies, changes in perception are associated with increased extrastriate activity and concomitant decreases in V1 activity, indicating a more complex relationship.  Current evidence indicates that V1 activity is necessary for normal conscious perception and is closely associated with some forms of visual awareness. Further investigation of V1 and its interactions with higher areas might provide important insights into the neural basis of visual awareness.},
	language = {En},
	number = {3},
	urldate = {2019-05-03},
	journal = {Nature Reviews Neuroscience},
	author = {Tong, Frank},
	month = mar,
	year = {2003},
	pages = {219},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/R9XN8EEV/Tong - 2003 - Primary visual cortex and visual awareness.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/PXAEWI2G/nrn1055.html:text/html}
}

@inproceedings{li_going_2013,
	address = {Melbourne, Australia},
	title = {Going beyond vision to improve bionic vision},
	isbn = {978-1-4799-2341-0},
	url = {http://ieeexplore.ieee.org/document/6738320/},
	doi = {10.1109/ICIP.2013.6738320},
	abstract = {Currently, most implanted visual prosthetic systems generate vision by translating sensor data from a headworn camera into electrical stimulation of the human vision system. Unfortunately, the resulting bionic vision has low spatial resolution and limited dynamic range. This dramatically reduces the usefulness of bionic vision in many real world scenarios. Historically, this problem is treated as immutable pathology. Recently, image processing has been proposed as a potential remedy to improve the useability of bionic vision. We explore another alternative: Combining multiple sensing modalities and robotic sensing algorithms. This paper gives a top level summary of ongoing research exploring this alternative.},
	language = {en},
	urldate = {2019-05-03},
	booktitle = {2013 {IEEE} {International} {Conference} on {Image} {Processing}},
	publisher = {IEEE},
	author = {Li, Wai Ho and Tang, Titus Jia Jie and Lui, Wen Lik Dennis},
	month = sep,
	year = {2013},
	pages = {1555--1558},
	file = {Li et al. - 2013 - Going beyond vision to improve bionic vision.pdf:/Users/wjmn/Zotero/storage/9VIX2AUZ/Li et al. - 2013 - Going beyond vision to improve bionic vision.pdf:application/pdf}
}

@article{allison_face_1994,
	title = {Face recognition in human extrastriate cortex},
	volume = {71},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1994.71.2.821},
	doi = {10.1152/jn.1994.71.2.821},
	abstract = {1. Twenty-four patients with electrodes chronically implanted on the surface of extrastriate visual cortex viewed faces, equiluminant scrambled faces, cars, scrambled cars, and butterflies. 2. A surface-negative potential, N200, was evoked by faces but not by the other categories of stimuli. N200 was recorded only from small regions of the left and right fusiform and inferior temporal gyri. Electrical stimulation of the same region frequently produced a temporary inability to name familiar faces. 3. The results suggest that discrete regions of inferior extrastriate visual cortex, varying in location between individuals, are specialized for the recognition of faces. These "face modules" appear to be intercalated among other functionally specific small regions.},
	number = {2},
	urldate = {2019-05-03},
	journal = {Journal of Neurophysiology},
	author = {Allison, T. and Ginter, H. and McCarthy, G. and Nobre, A. C. and Puce, A. and Luby, M. and Spencer, D. D.},
	month = feb,
	year = {1994},
	pages = {821--825},
	file = {Snapshot:/Users/wjmn/Zotero/storage/VJQQW9S3/jn.1994.71.2.html:text/html}
}

@article{lewis_restoration_2015,
	title = {Restoration of vision in blind individuals using bionic devices: {A} review with a focus on cortical visual prostheses},
	volume = {1595},
	issn = {0006-8993},
	shorttitle = {Restoration of vision in blind individuals using bionic devices},
	url = {http://www.sciencedirect.com/science/article/pii/S0006899314015674},
	doi = {10.1016/j.brainres.2014.11.020},
	abstract = {The field of neurobionics offers hope to patients with sensory and motor impairment. Blindness is a common cause of major sensory loss, with an estimated 39 million people worldwide suffering from total blindness in 2010. Potential treatment options include bionic devices employing electrical stimulation of the visual pathways. Retinal stimulation can restore limited visual perception to patients with retinitis pigmentosa, however loss of retinal ganglion cells precludes this approach. The optic nerve, lateral geniculate nucleus and visual cortex provide alternative stimulation targets, with several research groups actively pursuing a cortically-based device capable of driving several hundred stimulating electrodes. While great progress has been made since the earliest works of Brindley and Dobelle in the 1960s and 1970s, significant clinical, surgical, psychophysical, neurophysiological, and engineering challenges remain to be overcome before a commercially-available cortical implant will be realized. Selection of candidate implant recipients will require assessment of their general, psychological and mental health, and likely responses to visual cortex stimulation. Implant functionality, longevity and safety may be enhanced by careful electrode insertion, optimization of electrical stimulation parameters and modification of immune responses to minimize or prevent the host response to the implanted electrodes. Psychophysical assessment will include mapping the positions of potentially several hundred phosphenes, which may require repetition if electrode performance deteriorates over time. Therefore, techniques for rapid psychophysical assessment are required, as are methods for objectively assessing the quality of life improvements obtained from the implant. These measures must take into account individual differences in image processing, phosphene distribution and rehabilitation programs that may be required to optimize implant functionality. In this review, we detail these and other challenges facing developers of cortical visual prostheses in addition to briefly outlining the epidemiology of blindness, and the history of cortical electrical stimulation in the context of visual prosthetics.},
	urldate = {2019-05-03},
	journal = {Brain Research},
	author = {Lewis, Philip M. and Ackland, Helen M. and Lowery, Arthur J. and Rosenfeld, Jeffrey V.},
	month = jan,
	year = {2015},
	keywords = {Blindness, Bionics, Bionic eye, Cortical implant, Vision},
	pages = {51--73},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/NUACUXUG/Lewis et al. - 2015 - Restoration of vision in blind individuals using b.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/X4KEI5ED/S0006899314015674.html:text/html}
}

@article{normann_toward_2009,
	title = {Toward the development of a cortically based visual neuroprosthesis},
	volume = {6},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2560%2F6%2F3%2F035001},
	doi = {10.1088/1741-2560/6/3/035001},
	abstract = {Motivated by the success of cochlear implants for deaf patients, we are now facing the goal of creating a visual neuroprosthesis designed to interface with the occipital cortex as a means through which a limited but useful sense of vision could be restored in profoundly blind patients. We review the most important challenges regarding this neuroprosthetic approach and emphasize the need for basic human psychophysical research on the best way of presenting complex stimulating patterns through multiple microelectrodes. Continued research will hopefully lead to the development of and design specifications for the first generation of a cortically based visual prosthesis system.},
	language = {en},
	number = {3},
	urldate = {2019-05-03},
	journal = {Journal of Neural Engineering},
	author = {Normann, Richard A. and Greger, Bradley A. and House, Paul and Romero, Samuel F. and Pelayo, Francisco and Fernandez, Eduardo},
	month = may,
	year = {2009},
	pages = {035001},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/EMUJS6KN/Normann et al. - 2009 - Toward the development of a cortically based visua.pdf:application/pdf}
}

@inproceedings{srivastava_estimating_2007,
	title = {Estimating {Phosphene} {Maps} for {Psychophysical} {Experiments} used in {Testing} a {Cortical} {Visual} {Prosthesis} {Device}},
	doi = {10.1109/CNE.2007.369629},
	abstract = {Visual prosthesis devices are being developed to restore vision for those with blindness. Researchers working in the field of visual prosthesis are taking different approaches to develop a practical device. Some are targeting the retina for stimulation, whereas at least one group is targeting the optical nerve, and our laboratory is developing a system for the visual cortex. To estimate the kind of response they might expect from a typical user, researchers are conducting psychophysical experiments on normally-sighted persons. The device being developed in our laboratory is a first generation visual prosthesis system, designed to test the limits of artificial visual pattern recognition. Targeting the visual cortex area with our first generation device has limitations including limitations in lateral cortical surface area for electrode implantation, surgical difficulties and the lack of understanding as to how to use an artificial interface for communication with the visual cortex. Here, we discuss the uncertainties related to visotopic mapping of the lateral surface of the occipital lobe in humans.},
	booktitle = {2007 3rd {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering}},
	author = {Srivastava, N. R. and Troyk, P. R. and Towle, V. L. and Curry, D. and Schmidt, E. and Kufta, C. and Dagnelie, G.},
	month = may,
	year = {2007},
	keywords = {Blindness, visual perception, visual cortex, Electrodes, Visual prosthesis, blindness, prosthetics, Retina, artificial interface, artificial visual pattern recognition, cortical visual prosthesis device testing, electrode implantation, handicapped aids, Intracortical, Laboratories, lateral cortical surface area, occipital lobe, Pattern recognition, phosphene map, phosphene map estimation, Psychology, psychophysical experiment, psychophysical experiments, sensory aids, Stimulated emission, surgical difficulty, System testing, Test pattern generators, vision restore, visotopic mapping, visual cortex communication, visual prosthesis, visual prosthesis system},
	pages = {130--133},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/X54P3Y4C/4227234.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/YXPMXERV/Srivastava et al. - 2007 - Estimating Phosphene Maps for Psychophysical Exper.pdf:application/pdf}
}

@incollection{stronks_phosphene_2011,
	address = {Boston, MA},
	title = {Phosphene {Mapping} {Techniques} for {Visual} {Prostheses}},
	isbn = {978-1-4419-0754-7},
	url = {https://doi.org/10.1007/978-1-4419-0754-7_19},
	abstract = {Mapping of the visual world onto the visual system occurs in a highly ordered manner, yet with substantial interindividual variability. Since the retinal map of the scene at the photoreceptor level is fully determined by the optical projection of the eye, it is likely that a proximal map generated by a retinal prosthesis closely adheres to the same geometric projection. Once the nerve signals enter the optic nerve, this orderly map is redistributed, and while maps at more proximal levels still follow general rules, special mapping techniques in individual LGN or cortical prosthesis recipients will be required to allow reconstruction of spatial ­relationships in the outside world by means of a disorderly array of phosphenes.This chapter provides an overview of mapping techniques that have been used in a number of laboratories; discuss the strengths and weaknesses of each; and suggest ways in which various techniques can be combined.},
	language = {en},
	urldate = {2019-05-03},
	booktitle = {Visual {Prosthetics}: {Physiology}, {Bioengineering}, {Rehabilitation}},
	publisher = {Springer US},
	author = {Stronks, H. Christiaan and Dagnelie, Gislin},
	editor = {Dagnelie, Gislin},
	year = {2011},
	doi = {10.1007/978-1-4419-0754-7_19},
	keywords = {Lower Visual Field, Sighted Subject, Touch Screen, Transcranial Magnetic Stimulation, Visual Field},
	pages = {367--383},
	file = {Springer Full Text PDF:/Users/wjmn/Zotero/storage/675GS23P/Stronks and Dagnelie - 2011 - Phosphene Mapping Techniques for Visual Prostheses.pdf:application/pdf}
}

@article{buffoni_image_2005,
	title = {Image {Processing} {Strategies} {Dedicated} to {Visual} {Cortical} {Stimulators}: {A} {Survey}},
	volume = {29},
	issn = {1525-1594},
	shorttitle = {Image {Processing} {Strategies} {Dedicated} to {Visual} {Cortical} {Stimulators}},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1525-1594.2005.29104.x},
	doi = {10.1111/j.1525-1594.2005.29104.x},
	abstract = {Abstract: Multi-electrode devices are constantly evolving toward a state where complexity and reliability are adequate for providing a breakthrough in visual cortical stimulation allowing the blind to recover partial vision. Yet few research teams have focused on the development of the front-end subsystem that transforms an input image from a camera into stimulation commands. This article collects state-of-the-art knowledge about the appearance and organization of phosphenes, and previous work in image processing dedicated to visual cortical stimulation. Observations and hypothesis about important issues are highlighted, and six image processing strategies that could be used in such a subsystem are presented, from the most optimistic that use brightness modulation to emulate grayscale to the most conservative that use only on/off phosphene evocation.},
	language = {en},
	number = {8},
	urldate = {2019-05-03},
	journal = {Artificial Organs},
	author = {Buffoni, Louis-Xavier and Coulombe, Jonathan and Sawan, Mohamad},
	year = {2005},
	keywords = {Image processing, Image segmentation, Intracortical microelectrodes, Phosphene, Phosphene pattern recognition, Resolution reduction, Scene representation, Visual cortical stimulation},
	pages = {658--664},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/ZNS3E3R6/Buffoni et al. - 2005 - Image Processing Strategies Dedicated to Visual Co.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/7C5G6I35/j.1525-1594.2005.29104.html:text/html}
}

@article{ghose_strong_2012,
	title = {A {Strong} {Constraint} to the {Joint} {Processing} of {Pairs} of {Cortical} {Signals}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/3215922-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/32/45/15922},
	doi = {10.1523/JNEUROSCI.2186-12.2012},
	abstract = {An important question in neuroscience is how the activity from spatially distributed cortical representations is integrated and processed together. In this study, we used a new approach to investigate the integration of distributed cortical activity. We used microstimulation to directly activate pairs of sites in primary visual cortex of rhesus monkeys. The sites were activated either singly or jointly, and the monkeys were trained to behaviorally report detection of the activation of either cortical site. We compared the detection performance with predictions from two different mathematical models of signal combination. Our data show that, at cortical separations {\textless}1 mm, signal integration is well described as a linear combination (d′ summation) of individual site activity. At larger separations, signal integration is better described as a maximum operation on the site signals. We compare our neurophysiological findings to existing psychophysical data and suggest the intriguing possibility that cortical activity originating at spatial separations greater than ∼1 mm is processed as if by parallel, independent circuits whose signals can be compared against each other but not summed. This in turn implies that there is a strong constraint to the kinds of computations the brain can perform with spatially distributed cortical activity.},
	language = {en},
	number = {45},
	urldate = {2019-05-03},
	journal = {Journal of Neuroscience},
	author = {Ghose, Kaushik and Maunsell, John H. R.},
	month = nov,
	year = {2012},
	pmid = {23136430},
	pages = {15922--15933},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/7FSFCMCH/Ghose and Maunsell - 2012 - A Strong Constraint to the Joint Processing of Pai.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/45TYU2Q9/15922.html:text/html}
}

@article{wandell_plasticity_2009,
	title = {Plasticity and stability of visual field maps in adult primary visual cortex},
	volume = {10},
	copyright = {2009 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn2741},
	doi = {10.1038/nrn2741},
	abstract = {It is important to understand the balance between cortical plasticity and stability in various systems and across spatial scales in the adult brain. Here we review studies of adult plasticity in primary visual cortex (V1), which has a key role in distributing visual information. There are claims of plasticity at multiple spatial scales in adult V1, but a number of inconsistencies in the supporting data raise questions about the extent and nature of such plasticity. Our understanding of the extent of plasticity in V1 is further limited by a lack of quantitative models to guide the interpretation of the data. These problems limit efforts to translate research findings about adult cortical plasticity into significant clinical, educational and policy applications.},
	language = {en},
	number = {12},
	urldate = {2019-05-03},
	journal = {Nature Reviews Neuroscience},
	author = {Wandell, Brian A. and Smirnakis, Stelios M.},
	month = dec,
	year = {2009},
	pages = {873--884},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/P5TZTSUY/Wandell and Smirnakis - 2009 - Plasticity and stability of visual field maps in a.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/BRJUGFZ2/nrn2741.html:text/html}
}

@article{born_cortical_2015,
	series = {Sight restoration: prosthetics, optogenetics and gene therapy},
	title = {Cortical magnification plus cortical plasticity equals vision?},
	volume = {111},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698914002351},
	doi = {10.1016/j.visres.2014.10.002},
	abstract = {Most approaches to visual prostheses have focused on the retina, and for good reasons. The earlier that one introduces signals into the visual system, the more one can take advantage of its prodigious computational abilities. For methods that make use of microelectrodes to introduce electrical signals, however, the limited density and volume occupying nature of the electrodes place severe limits on the image resolution that can be provided to the brain. In this regard, non-retinal areas in general, and the primary visual cortex in particular, possess one large advantage: “magnification factor” (MF)—a value that represents the distance across a sheet of neurons that represents a given angle of the visual field. In the foveal representation of primate primary visual cortex, the MF is enormous—on the order of 15–20mm/deg in monkeys and humans, whereas on the retina, the MF is limited by the optical design of the eye to around 0.3mm/deg. This means that, for an electrode array of a given density, a much higher-resolution image can be introduced into V1 than onto the retina (or any other visual structure). In addition to this tremendous advantage in resolution, visual cortex is plastic at many different levels ranging from a very local ability to learn to better detect electrical stimulation to higher levels of learning that permit human observers to adapt to radical changes to their visual inputs. We argue that the combination of the large magnification factor and the impressive ability of the cerebral cortex to learn to recognize arbitrary patterns, might outweigh the disadvantages of bypassing earlier processing stages and makes V1 a viable option for the restoration of vision.},
	urldate = {2019-05-03},
	journal = {Vision Research},
	author = {Born, Richard T. and Trott, Alexander R. and Hartmann, Till S.},
	month = jun,
	year = {2015},
	keywords = {Visual prosthesis, Magnification factor, Plasticity, Primary visual cortex, V1, Vision restoration},
	pages = {161--169},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/MML8M5DT/Born et al. - 2015 - Cortical magnification plus cortical plasticity eq.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/HXMYJ7C9/S0042698914002351.html:text/html}
}

@article{niketeghad_brain_2019,
	title = {Brain {Machine} {Interfaces} for {Vision} {Restoration}: {The} {Current} {State} of {Cortical} {Visual} {Prosthetics}},
	volume = {16},
	issn = {1878-7479},
	shorttitle = {Brain {Machine} {Interfaces} for {Vision} {Restoration}},
	url = {https://doi.org/10.1007/s13311-018-0660-1},
	doi = {10.1007/s13311-018-0660-1},
	abstract = {Loss of vision alters the day to day life of blind individuals and may impose a significant burden on their family and the economy. Cortical visual prosthetics have been shown to have the potential of restoring a useful degree of vision via stimulation of primary visual cortex. Due to current advances in electrode design and wireless power and data transmission, development of these prosthetics has gained momentum in the past few years and multiple sites around the world are currently developing and testing their designs. In this review, we briefly outline the visual prosthetic approaches and describe the history of cortical visual prosthetics. Next, we focus on the state of the art of cortical visual prosthesis by briefly explaining the design of current devices that are either under development or in the clinical testing phase. Lastly, we shed light on the challenges of each design and provide some potential solutions.},
	language = {en},
	number = {1},
	urldate = {2019-05-03},
	journal = {Neurotherapeutics},
	author = {Niketeghad, Soroush and Pouratian, Nader},
	month = jan,
	year = {2019},
	keywords = {Blindness, Brain computer interface, Electrode array, Stimulation, Visual cortex, Visual prosthetic},
	pages = {134--143},
	file = {Springer Full Text PDF:/Users/wjmn/Zotero/storage/L4M4DPTT/Niketeghad and Pouratian - 2019 - Brain Machine Interfaces for Vision Restoration T.pdf:application/pdf}
}

@article{lee_mapping_2000,
	title = {Mapping of functional organization in human visual cortex: {Electrical} cortical stimulation},
	volume = {54},
	issn = {0028-3878, 1526-632X},
	shorttitle = {Mapping of functional organization in human visual cortex},
	url = {http://www.neurology.org/cgi/doi/10.1212/WNL.54.4.849},
	doi = {10.1212/WNL.54.4.849},
	language = {en},
	number = {4},
	urldate = {2019-05-03},
	journal = {Neurology},
	author = {Lee, H. W. and Hong, S. B. and Seo, D. W. and Tae, W. S. and Hong, S. C.},
	month = feb,
	year = {2000},
	pages = {849--854},
	annote = {V1 (or areas close to calcarine fissure produce "simple forms"). Peristirate areas produce "intermediate forms". Temporal areas produce "complex forms". },
	file = {Lee et al. - 2000 - Mapping of functional organization in human visual.pdf:/Users/wjmn/Zotero/storage/UQWSNQ6N/Lee et al. - 2000 - Mapping of functional organization in human visual.pdf:application/pdf}
}

@article{cone_electrical_2018,
	title = {Electrical {Microstimulation} of {Visual} {Cerebral} {Cortex} {Elevates} {Psychophysical} {Detection} {Thresholds}},
	volume = {5},
	doi = {10.1523/ENEURO.0311-18.2018},
	abstract = {Sensory prostheses can restore aspects of natural sensation by delivering electrical current directly into sensory circuits. An effective sensory prosthetic should be capable of generating reliable real-time perceptual signals for hours each day over many years. However, we still know little regarding the stability of percepts produced by electrical microstimulation of cerebral sensory cortex when stimulation is delivered repeatedly over long periods. Developing methods that yield highly sensitive and reliable assessments of a subject's sensitivity to stimulation is important for developing prosthetic devices that can mimic the constant stream of information inherent in daily experience. Here, we trained rhesus monkeys to report electrical microstimulation of their primary visual cortex (V1) and measured how repeated stimulation affected the minimal electrical current needed to generate a percept (behavioral detection threshold). Using adaptive staircase procedures with a two-alternative forced-choice (2AFC) detection task, we obtained highly reliable detection threshold measures with as few as 100 trials. Using either chronically implanted or acutely inserted microelectrodes, we found that repeated electrical microstimulation elevated detection thresholds, with effects persisting between daily testing sessions. Our results demonstrate task designs that can support rapid and reliable measurements of detection thresholds, and point to the need for validation that detection thresholds in targeted structures will be sufficiently stable in the face of the amount of chronic stimulation that will be required for effective sensory prosthetics.},
	number = {5},
	journal = {eNeuro},
	author = {Cone, J.J. and Ni, A.M. and Ghose, K. and Maunsell, J.H.R.},
	year = {2018},
	keywords = {vision, microstimulation, perception, prosthesis, psychophysics},
	file = {Full Text:/Users/wjmn/Zotero/storage/KZIVRL6S/Cone et al. - 2018 - Electrical Microstimulation of Visual Cerebral Cor.pdf:application/pdf;SCOPUS Snapshot:/Users/wjmn/Zotero/storage/CFXBHMRL/display.html:text/html}
}

@article{collins_preserved_2019,
	title = {Preserved evoked conscious perception of phosphenes with direct stimulation of deafferented primary visual cortex},
	volume = {11},
	issn = {2213-3232},
	url = {http://www.sciencedirect.com/science/article/pii/S2213323218301270},
	doi = {10.1016/j.ebcr.2018.12.002},
	abstract = {The premise of neuro-rehabilitation after injury is to access the residual capacity of the nervous system to improve function. We describe a patient who developed a quadrantopsia and drug-resistant focal epilepsy after an arteriovenous malformation hemorrhage. Thirty years later, he underwent placement of subdural electrodes for seizure mapping. Phosphenes were elicited in the blind right visual field with stimulation of occipital cortex. This case demonstrates that visual cortex may retain functional organization after a partial subcortical visual pathway injury. This persistent conscious mapping suggests that disconnected visual cortex could serve as a region for interfacing with neural prosthetic devices for acquired blindness.},
	urldate = {2019-05-03},
	journal = {Epilepsy \& Behavior Case Reports},
	author = {Collins, Kelly L. and Sarma, Devapratim and Hakimian, Shahin and Tsai, Jeff J. and Ojemann, Jeffrey G.},
	month = jan,
	year = {2019},
	keywords = {Perception, Plasticity, Brain computer interface (BCI), Consciousness, Neural engineering, Neuroprosthesis},
	pages = {84--86},
	annote = {Basically just establishes that you can produce some visual percept in someone with a visual field defect. But I feel we knew that already.},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/MYG6SRG8/Collins et al. - 2019 - Preserved evoked conscious perception of phosphene.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/4E336VK9/S2213323218301270.html:text/html}
}

@article{kosta_electromagnetic_2018,
	title = {Electromagnetic {Safety} {Assessment} of a {Cortical} {Implant} for {Vision} {Restoration}},
	volume = {2},
	doi = {10.1109/JERM.2018.2812302},
	abstract = {A cortical visual prosthetic system bypasses the components of the visual pathway, which may be damaged due to injury or disease, by directly stimulating the visual cortex; therefore, cortical visual prostheses promise the capability of restoring a form of vision to patients who cannot benefit from other types of visual neural stimulators. A high data rate, multielectrode, implantable device, such as that utilized for a cortical visual prosthesis, requires continuous power provided by an external telemetry unit, which is nonnegligible, given the number of stimulating electrodes and the stimulation rate necessary to avoid flickering visual percepts. This aspect motivates the need to develop models and methods that aid the development of such devices by assessing their compliance with electromagnetic safety standards. In this paper, the electromagnetic safety assessment of a cortical visual prosthetic system is considered, and the solutions employed to numerically treat the computational complexities associated with it are discussed. The specifics of the implementation of an actual visual cortical implant are discussed, and the parameters of such an implant are used as a test case to determine whether IEEE and ICNIRP electromagnetic standards are met in what can be considered a typical embodiment of the prosthesis. Results show that, for the considered implant, such a system meets IEEE and ICNIRP safety standards, thus enabling further development of similar neurorehabilitative devices. © 2016 IEEE.},
	number = {1},
	journal = {IEEE Journal of Electromagnetics, RF and Microwaves in Medicine and Biology},
	author = {Kosta, P. and Paknahad, J. and Rodriguez, E.S.G. and Loizos, K. and Roy, A. and Talbot, N. and Seidman, S. and Datta, P. and Dai, R. and Pollack, B. and Greenberg, R. and Lazzi, G.},
	year = {2018},
	keywords = {visual prosthesis, Electromagnetics, finite difference methods, implantable biomedical devices, specific absorption rate},
	pages = {56--63},
	file = {SCOPUS Snapshot:/Users/wjmn/Zotero/storage/XAK2IMQ3/display.html:text/html}
}

@article{bosking_electrical_2017,
	title = {Electrical {Stimulation} of {Visual} {Cortex}: {Relevance} for the {Development} of {Visual} {Cortical} {Prosthetics}},
	volume = {3},
	issn = {2374-4642, 2374-4650},
	shorttitle = {Electrical {Stimulation} of {Visual} {Cortex}},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-vision-111815-114525},
	doi = {10.1146/annurev-vision-111815-114525},
	abstract = {Electrical stimulation of the cerebral cortex is a powerful tool for exploring cortical function. Stimulation of early visual cortical areas is easily detected by subjects and produces simple visual percepts known as phosphenes. A device implanted in visual cortex that generates patterns of phosphenes could be used as a substitute for natural vision in blind patients. We review the possibilities and limitations of such a device, termed a visual cortical prosthetic. Currently, we can predict the location and size of phosphenes produced by stimulation of single electrodes. A functional prosthetic, however, must produce spatial temporal patterns of activity that will result in the perception of complex visual objects. Although stimulation of later visual cortical areas alone usually does not lead to a visual percept, it can alter visual perception and the performance of visual behaviors, and training subjects to use signals injected into these areas may be possible.},
	language = {en},
	number = {1},
	urldate = {2019-05-03},
	journal = {Annual Review of Vision Science},
	author = {Bosking, William H. and Beauchamp, Michael S. and Yoshor, Daniel},
	month = sep,
	year = {2017},
	pages = {141--166},
	file = {Bosking et al. - 2017 - Electrical Stimulation of Visual Cortex Relevance.pdf:/Users/wjmn/Zotero/storage/MC7ZDHXQ/Bosking et al. - 2017 - Electrical Stimulation of Visual Cortex Relevance.pdf:application/pdf}
}

@article{martinez-alvarez_automatic_2016,
	title = {Automatic {Tuning} of a {Retina} {Model} for a {Cortical} {Visual} {Neuroprosthesis} {Using} a {Multi}-{Objective} {Optimization} {Genetic} {Algorithm}},
	volume = {26},
	doi = {10.1142/S0129065716500210},
	abstract = {The retina is a very complex neural structure, which contains many different types of neurons interconnected with great precision, enabling sophisticated conditioning and coding of the visual information before it is passed via the optic nerve to higher visual centers. The encoding of visual information is one of the basic questions in visual and computational neuroscience and is also of seminal importance in the field of visual prostheses. In this framework, it is essential to have artificial retina systems to be able to function in a way as similar as possible to the biological retinas. This paper proposes an automatic evolutionary multi-objective strategy based on the NSGA-II algorithm for tuning retina models. Four metrics were adopted for guiding the algorithm in the search of those parameters that best approximate a synthetic retinal model output with real electrophysiological recordings. Results show that this procedure exhibits a high flexibility when different trade-offs has to be considered during the design of customized neuro prostheses. © 2016 World Scientific Publishing Company.},
	number = {7},
	journal = {International Journal of Neural Systems},
	author = {Martínez-Álvarez, A. and Crespo-Cano, R. and Díaz-Tahoces, A. and Cuenca-Asensi, S. and Ferrández Vicente, J.M. and Fernández, E.},
	year = {2016},
	keywords = {evolutionary search, multi-objective optimization, NSGA-II, Retinal modeling, visual neuroprostheses},
	annote = {Cited By :10},
	file = {SCOPUS Snapshot:/Users/wjmn/Zotero/storage/HYBA6NL9/display.html:text/html;Submitted Version:/Users/wjmn/Zotero/storage/3DM6IY4B/Martínez-Álvarez et al. - 2016 - Automatic Tuning of a Retina Model for a Cortical .pdf:application/pdf}
}

@article{fine_pulse_2015,
	title = {Pulse trains to percepts: {The} challenge of creating a perceptually intelligible world with sight recovery technologies},
	volume = {370},
	shorttitle = {Pulse trains to percepts},
	doi = {10.1098/rstb.2014.0208},
	abstract = {An extraordinary variety of sight recovery therapies are either about to begin clinical trials, have begun clinical trials, or are currently being implanted in patients. However, as yet we have little insight into the perceptual experience likely to be produced by these implants. This review focuses on methodologies, such as optogenetics, small molecule photoswitches and electrical prostheses, which use artificial stimulation of the retina to elicit percepts. For each of these technologies, the interplay between the stimulating technology and the underlying neurophysiology is likely to result in distortions of the perceptual experience. Here, we describe some of these potential distortions and discuss how they might be minimized either through changes in the encoding model or through cortical plasticity. © 2015 The Author(s) Published by the Royal Society. All rights reserved.},
	number = {1677},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Fine, I. and Boynton, G.M.},
	year = {2015},
	keywords = {Vision restoration, Macular degeneration, Neural coding, Neural prosthetic, Optogenetic, Retinal degeneration},
	annote = {Cited By :12},
	file = {Full Text:/Users/wjmn/Zotero/storage/6VBTZIWT/Fine and Boynton - 2015 - Pulse trains to percepts The challenge of creatin.pdf:application/pdf;SCOPUS Snapshot:/Users/wjmn/Zotero/storage/CH4SLGM3/display.html:text/html}
}

@inproceedings{sharmili_comparative_2017,
	title = {Comparative analysis of image processing algorithms for visual prosthesis},
	doi = {10.1109/ICCSP.2017.8286551},
	abstract = {Visual prosthesis is one of the emerging technology in biomedical implants which helps to restore useful sight for visually impaired people with retinal degenerative diseases. The visual prosthesis consists of two parts. One is external and the other is internal (surgically implanted). The external part includes a camera, image processor and a transmitter. The image processor captures the video using a camera, encodes the captured video to bit frames that can be recognized by surgically placed retinal stimulator and transmits the coded data through transmitter. The internal implanted part includes a receiver and electrode array. The receiver encodes the received serial bits into electrical signals and stimulates the survival parts of the retina using electrical signals applied through the electrode array. The survival parts then sends a signal to the brain where it is interpreted as image/video. The researchers suggested that an array of 600-1000 electrodes are required to do some basic forms of vision such as reading large letters, recognizing faces. etc. The image processor is the crucial one of visual prosthesis where it captures high resolution image from camera, and resizes it into 1024 resolution image. To extract 1024 pixel vital information, the related image processing algorithms include RGB to Gray conversion, Gamma encoding, Edge Detection and down sampling are described here. The comparative analysis of image processing algorithms provided in this paper will drive an image processing strategy with less computational complexity of achieving better performance that is suitable to implement on MIPS based microcontroller.},
	booktitle = {2017 {International} {Conference} on {Communication} and {Signal} {Processing} ({ICCSP})},
	author = {Sharmili, N. and Swapna, N. and Ramakrishna, G.},
	month = apr,
	year = {2017},
	keywords = {biomedical electrodes, Electrodes, prosthetics, biomedical electronics, eye, Implants, medical image processing, Retina, vision, handicapped aids, visual prosthesis, bioelectric potentials, biomedical implants, biomedical optical imaging, camera, Cameras, captured video, diseases, DVP, edge detection, Edge Detection, electrical signals, electrode array, Epiretinal prosthesis, gamma encoding, high resolution image, Image color analysis, image colour analysis, Image edge detection, Image Processing, image processing algorithms, image processing strategy, image processor, image sensors, medical disorders, patient treatment, retinal degenerative diseases, RIRS, surgically placed retinal stimulator, Vision prosthesis, visually impaired people},
	pages = {1120--1124},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/GUNVUHKQ/8286551.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/EZDQMR66/Sharmili et al. - 2017 - Comparative analysis of image processing algorithm.pdf:application/pdf}
}

@article{foroushani_cortical_2018,
	title = {Cortical visual prostheses: from microstimulation to functional percept},
	volume = {15},
	issn = {1741-2552},
	shorttitle = {Cortical visual prostheses},
	url = {https://doi.org/10.1088%2F1741-2552%2Faaa904},
	doi = {10.1088/1741-2552/aaa904},
	abstract = {Cortical visual prostheses are intended to restore vision by targeted electrical stimulation of the visual cortex. The perception of spots of light, called phosphenes, resulting from microstimulation of the visual pathway, suggests the possibility of creating meaningful percept made of phosphenes. However, to date electrical stimulation of V1 has still not resulted in perception of phosphenated images that goes beyond punctate spots of light. In this review, we summarize the clinical and experimental progress that has been made in generating phosphenes and modulating their associated perceptual characteristics in human and macaque primary visual cortex (V1). We focus specifically on the effects of different microstimulation parameters on perception and we analyse key challenges facing the generation of meaningful artificial percepts. Finally, we propose solutions to these challenges based on the application of supervised learning of population codes for spatial stimulation of visual cortex.},
	language = {en},
	number = {2},
	urldate = {2019-05-03},
	journal = {Journal of Neural Engineering},
	author = {Foroushani, Armin Najarpour and Pack, Christopher C. and Sawan, Mohamad},
	month = feb,
	year = {2018},
	pages = {021005},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/5MXQTA4B/Foroushani et al. - 2018 - Cortical visual prostheses from microstimulation .pdf:application/pdf}
}

@article{wong_cmos_2019,
	title = {{CMOS} stimulating chips capable of wirelessly driving 473 electrodes for a cortical vision prosthesis},
	volume = {16},
	issn = {1741-2552},
	doi = {10.1088/1741-2552/ab021b},
	abstract = {OBJECTIVE: Implantable neural stimulating and recording devices have the potential to restore capabilities such as vision or motor control to disabled patients, improving quality of life. Implants with a large number of stimulating electrodes typically utilize implanted batteries and/or subcutaneous wiring to deal with their high-power consumption and high data throughput needed to address all electrodes with low latency. The use of batteries places severe limitations on the implant's size, usable duty cycle, device longevity while subcutaneous wiring increases the risk of infection and mechanical damage due to device movement.
APPROACH: To overcome these limitations, we have designed and implemented a system that supports up to 473 implanted stimulating microelectrodes, all wirelessly powered and individually controlled by micropower application specific integrated circuits (ASICs).
MAIN RESULTS: Each ASIC controls 43 electrodes and draws 3.18 mW of power when stimulating through 24 channels. We measured the linearity of the digital-to-analog convertors (DACs) to be 0.21 LSB (integrated non-linearity) and the variability in timing of stimulation pulses across ASICs to be 172 ns.
SIGNIFICANCE: This work demonstrates the feasibility of a new low power ASIC designed to be implanted in the visual cortex of humans. The fully implantable device will greatly reduce the risks of infection and damage due to mechanical issues.},
	language = {eng},
	number = {2},
	journal = {Journal of Neural Engineering},
	author = {Wong, Yan T. and Feleppa, Timothy and Mohan, Anand and Browne, Damien and Szlawski, Julian and Rosenfeld, Jeffrey V. and Lowery, Arthur},
	month = apr,
	year = {2019},
	pmid = {30690434},
	pages = {026025}
}

@article{panetsos_consistent_2011,
	title = {Consistent {Phosphenes} {Generated} by {Electrical} {Microstimulation} of the {Visual} {Thalamus}. {An} {Experimental} {Approach} for {Thalamic} {Visual} {Neuroprostheses}},
	volume = {5},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2011.00084/full},
	doi = {10.3389/fnins.2011.00084},
	abstract = {Most work on visual prostheses has centred on developing retinal or cortical devices. However, when retinal implants are not feasible, neuroprostheses could be implanted in the lateral geniculate nucleus of the thalamus (LGN), the intermediate relay station of visual information from the retina to the visual cortex (V1). The objective of the present study was to determine the types of artificial stimuli that when delivered to the visual thalamus can generate reliable responses of the cortical neurons similar to those obtained when the eye perceives a visual image. Visual stimuli \{Si\} were presented to one eye of an experimental animal and both, the thalamic \{RThi\} and cortical responses \{RV1i\} to such stimuli were recorded. Electrical patterns \{RThi*\} resembling \{RThi\} were then injected into the visual thalamus to obtain cortical responses \{RV1i*\} similar to \{RV1i\}. Visually- and electrically-generated V1 responses were compared. Results: During the course of this work we: (i) characterised the response of V1 neurons to visual stimuli according to response magnitude, duration, spiking rate and the distribution of interspike intervals; (ii) experimentally tested the dependence of V1 responses on stimulation parameters such as intensity, frequency, duration, etc. and determined the ranges of these parameters generating the desired cortical activity; (iii) identified similarities between responses of V1 useful to compare the naturally and artificially generated neuronal activity of V1; and (iv) by modifying the stimulation parameters, we generated artificial V1 responses similar to those elicited by visual stimuli. Generation of predictable and consistent phosphenes by means of artificial stimulation of the LGN is important for the feasibility of visual prostheses. Here we proved that electrical stimuli to the LGN can generate V1 neural responses that resemble those elicited by natural visual stimuli.},
	language = {English},
	urldate = {2019-05-03},
	journal = {Frontiers in Neuroscience},
	author = {Panetsos, Fivos and Sanchez-Jimenez, Abel and Diaz-de Cerio, Elena R. and Diaz-Guemes, Idoia and Sanchez, Francisco M.},
	year = {2011},
	keywords = {phosphene, V1, BMI, Implant, LGN, visual percept},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/CBKZ2EME/Panetsos et al. - 2011 - Consistent Phosphenes Generated by Electrical Micr.pdf:application/pdf}
}

@article{humayun_visual_1996,
	title = {Visual perception elicited by electrical stimulation of retina in blind humans},
	volume = {114},
	issn = {0003-9950},
	abstract = {OBJECTIVE: To evaluate the feasibility of bypassing damaged photoreceptors and electrically stimulating the remaining viable retinal layers to provide limited visual input to patients who are blind because of severe photoreceptor degeneration.
METHODS: In the operating room with the patient under local anesthesia, focal electrical stimulation of the retinal surface with brief biphasic pulses was performed using small probes inserted through the sclera. The procedure was performed in five subjects who had little or no light perception. Three subjects had retinitis pigmentosa, one had age-related macular degeneration, and one had unspecified retinal degeneration from birth.
RESULTS: Stimulation elicited visual perception of a spot of light (phosphene). Subjects who previously had useful vision accurately localized the phosphenes according to the retinal area stimulated. Two subjects could track the movement of the stimulating electrode by reporting movement of the elicited phosphene, and could perceive two simultaneous phosphenes on independent stimulation with two electrodes. In a resolution test, one of the subjects with no light perception in his left eye resolved phosphenes at 1.75 degrees center-to-center distance (ie, 4/200 OS visual acuity).
CONCLUSIONS: Local electrical stimulation of the retinal surface in patients blind from outer retinal disease results in focal light perception that seems to arise from the stimulated area. Such findings in an acute experiment warrant further research into the possibility of prolonged retinal stimulation, improved resolution, and ultimately, an intraocular visual prosthesis.},
	language = {eng},
	number = {1},
	journal = {Archives of Ophthalmology (Chicago, Ill.: 1960)},
	author = {Humayun, M. S. and de Juan, E. and Dagnelie, G. and Greenberg, R. J. and Propst, R. H. and Phillips, D. H.},
	month = jan,
	year = {1996},
	pmid = {8540849},
	keywords = {Blindness, Electric Stimulation, Humans, Adult, Male, Middle Aged, Microelectrodes, Prostheses and Implants, Retina, Aged, Aged, 80 and over, Feasibility Studies, Retinal Degeneration, Visual Perception},
	pages = {40--46}
}

@article{veraart_visual_1998,
	title = {Visual sensations produced by optic nerve stimulation using an implanted self-sizing spiral cuff electrode},
	volume = {813},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/S0006899398009779},
	doi = {10.1016/S0006-8993(98)00977-9},
	abstract = {A blind volunteer with retinitis pigmentosa was chronically implanted with a self-sizing spiral cuff electrode around an optic nerve. Electrical stimuli applied to the nerve produced localized visual sensations that were broadly distributed throughout the visual field and could be varied by changing the stimulating conditions. These results demonstrate the potential for constructing a visual prosthesis, based on electrical stimulation of the optic nerve, for blind subjects who have intact retinal ganglion cells.},
	number = {1},
	urldate = {2019-05-03},
	journal = {Brain Research},
	author = {Veraart, Claude and Raftopoulos, Christian and Mortimer, J. Thomas and Delbeke, Jean and Pins, Delphine and Michaux, Géraldine and Vanlierde, Annick and Parrini, Simone and Wanet-Defalque, Marie-Chantal},
	month = nov,
	year = {1998},
	keywords = {Visual prosthesis, Optic nerve stimulation, Retinitis pigmentosa, Self-sizing spiral cuff electrode},
	pages = {181--186},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/WV3HCQDW/S0006899398009779.html:text/html}
}

@article{ray_magnetic_1998,
	title = {Magnetic stimulation of visual cortex: factors influencing the perception of phosphenes},
	volume = {15},
	issn = {0736-0258},
	shorttitle = {Magnetic stimulation of visual cortex},
	abstract = {Using transcranial magnetic stimulation of occipital cortex, the authors studied the stimulus parameters that generate phosphenes in healthy volunteers. Single pulses or trains of stimuli readily elicited phosphenes in all subjects. The threshold current needed to elicit perception of phosphenes was essentially the same for stimulus trains from 250 msec to 2000 msec in length, but increased dramatically for trains of shorter duration. The effect of stimulus frequency was variable, with each subject having a distinctive "frequency tuning curve," but overall, the threshold current necessary to produce phosphenes decreased as frequency of stimulation increased. Using paired pulses, the perceptual threshold was flat for interstimulus intervals between 2 msec and 100 msec, but increased rapidly as the interstimulus interval was increased above 100 msec. Stimulation of sites lateral to the midline elicited phosphenes in the contralateral visual field. Phosphenes were dominant in the lower and peripheral aspects of the visual fields. The findings are discussed in relation to similar studies of electrical stimulation of somatosensory cortex.},
	language = {eng},
	number = {4},
	journal = {Journal of Clinical Neurophysiology: Official Publication of the American Electroencephalographic Society},
	author = {Ray, P. G. and Meador, K. J. and Epstein, C. M. and Loring, D. W. and Day, L. J.},
	month = jul,
	year = {1998},
	pmid = {9736469},
	keywords = {Humans, Phosphenes, Visual Cortex, Adult, Evoked Potentials, Visual, Female, Male, Middle Aged, Visual Fields, Analysis of Variance, Electromagnetic Fields, Physical Stimulation, Psychophysics, Sensory Thresholds, Time Factors},
	pages = {351--357}
}

@article{beyeler_learning_2017,
	title = {Learning to see again: biological constraints on cortical plasticity and the implications for sight restoration technologies},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {Learning to see again},
	url = {https://www.biorxiv.org/content/10.1101/115188v1},
	doi = {10.1101/115188},
	abstract = {1.{\textless}h3{\textgreater}ABSTRACT{\textless}/h3{\textgreater} {\textless}p{\textgreater}The bionic eye – so long a dream of the future – is finally becoming a reality with retinal prostheses available to patients in the US and Europe. However, clinical experience with these implants has made it apparent that the vision restored by these devices differs substantially from normal sight. Consequently, the ability to learn to make use of this abnormal retinal input plays a critical role in whether or not some functional vision is successfully restored. The goal of the present review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of sight recovery. We begin with formal definitions of cortical plasticity and perceptual learning. We then describe what is known, and what is unknown, about visual plasticity across the hierarchy of brain regions involved in visual processing, and across different stages of life. We close by discussing what is known about brain plasticity in sight restoration patients and discuss biological mechanisms that could be harnessed in future technologies to improve visual learning in these patients.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-03},
	journal = {bioRxiv},
	author = {Beyeler, Michael and Rokem, Ariel and Boynton, Geoffrey M. and Fine, Ione},
	month = mar,
	year = {2017},
	pages = {115188},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/JPY3N29K/Beyeler et al. - 2017 - Learning to see again biological constraints on c.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/HI8MU5I4/115188v1.html:text/html}
}

@article{merabet_`who_2007,
	title = {`{Who} is the ideal candidate?': decisions and issues relating to visual neuroprosthesis development, patient testing and neuroplasticity},
	volume = {4},
	issn = {1741-2552},
	shorttitle = {`{Who} is the ideal candidate?},
	url = {https://doi.org/10.1088%2F1741-2560%2F4%2F1%2Fs15},
	doi = {10.1088/1741-2560/4/1/S15},
	abstract = {Appropriate delivery of electrical stimulation to intact visual structures can evoke patterned sensations of light in individuals who have been blind for many years. This pivotal finding has lent credibility to the concept of restoring functional vision by artificial means. As numerous groups worldwide pursue human clinical testing with visual prosthetic devices, it is becoming increasingly clear that there remains a considerable gap between the challenges of prosthetic device development and the rehabilitative strategies needed to implement this new technology in patients. An important area of future work will be the development of appropriate pre- and post-implantation measures of performance and establishing candidate selection criteria in order to quantify technical advances, guide future device design and optimize therapeutic success. We propose that the selection of an ‘ideal’ candidate should also be considered within the context of the variable neuroplastic changes that follow vision loss. Specifically, an understanding of the adaptive and compensatory changes that occur within the brain could assist in guiding the development of post-implantation rehabilitative strategies and optimize behavioral outcomes.},
	language = {en},
	number = {1},
	urldate = {2019-05-03},
	journal = {Journal of Neural Engineering},
	author = {Merabet, Lotfi B. and Rizzo, Joseph F. and Pascual-Leone, Alvaro and Fernandez, Eduardo},
	month = feb,
	year = {2007},
	pages = {S130--S135},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/FP7HFZRN/Merabet et al. - 2007 - `Who is the ideal candidate' decisions and issue.pdf:application/pdf}
}

@article{ge_spiking_2017,
	title = {A spiking neural network model for obstacle avoidance in simulated prosthetic vision},
	volume = {399},
	issn = {0020-0255},
	url = {http://www.sciencedirect.com/science/article/pii/S0020025517305819},
	doi = {10.1016/j.ins.2017.03.006},
	abstract = {Limited by visual percepts elicited by existing visual prosthesis, it’s necessary to enhance its functionality to fulfill some challenging tasks for the blind such as obstacle avoidance. This paper argues that spiking neural networks (SNN) are effective techniques for object recognition and introduces for the first time a SNN model for obstacle recognition to assist blind people wearing prosthetic vision devices by modelling and classifying spatio-temporal (ST) video data. The proposed methodology is based on a novel spiking neural network architecture, called NeuCube as a general framework for video data modelling in simulated prosthetic vision. As an integrated environment including spiking trains encoding, input variable mapping, unsupervised reservoir training and supervised classifier training, the NeuCube consists of a spiking neural network reservoir (SNNr) and a dynamic evolving spiking neural network classifier (deSNN). First, input data is captured by visual prosthesis, then ST feature extraction is utilized in the low-resolution prosthetic vision generated by prostheses. Finally such ST features are fed to the NeuCube to output classification result of obstacle analysis for an early warning system to be activated. Experiments on collected video data and comparison with other computational intelligence methods indicate promising results. This makes it possible to directly utilize available neuromorphic hardware chips, embedded in visual prostheses, to enhance significantly their functionality. The proposed NeuCube-based obstacle avoidance methodology provides useful guidance to the blind, thus offering a significant improvement of current prostheses and potentially benefiting future prosthesis wearers.},
	urldate = {2019-05-04},
	journal = {Information Sciences},
	author = {Ge, Chenjie and Kasabov, Nikola and Liu, Zhi and Yang, Jie},
	month = aug,
	year = {2017},
	keywords = {NeuCube, Obstacle avoidance, Simulated prosthetic vision, Spiking neural networks, Visual prothesis},
	pages = {30--42},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/5HU5JY9U/Ge et al. - 2017 - A spiking neural network model for obstacle avoida.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/7VS565AQ/S0020025517305819.html:text/html}
}

@article{lewis_electrical_2016,
	title = {Electrical stimulation of the brain and the development of cortical visual prostheses: {An} historical perspective},
	volume = {1630},
	issn = {00068993},
	shorttitle = {Electrical stimulation of the brain and the development of cortical visual prostheses},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0006899315006897},
	doi = {10.1016/j.brainres.2015.08.038},
	abstract = {Rapid advances are occurring in neural engineering, bionics and the brain–computer interface. These milestones have been underpinned by staggering advances in microelectronics, computing, and wireless technology in the last three decades. Several cortically-based visual prosthetic devices are currently being developed, but pioneering advances with early implants were achieved by Brindley followed by Dobelle in the 1960s and 1970s. We have reviewed these discoveries within the historical context of the medical uses of electricity including attempts to cure blindness, the discovery of the visual cortex, and opportunities for cortex stimulation experiments during neurosurgery. Further advances were made possible with improvements in electrode design, greater understanding of cortical electrophysiology and miniaturisation of electronic components. Human trials of a new generation of prototype cortical visual prostheses for the blind are imminent.},
	language = {en},
	urldate = {2019-05-04},
	journal = {Brain Research},
	author = {Lewis, Philip M. and Rosenfeld, Jeffrey V.},
	month = jan,
	year = {2016},
	pages = {208--224},
	file = {Lewis and Rosenfeld - 2016 - Electrical stimulation of the brain and the develo.pdf:/Users/wjmn/Zotero/storage/DN7PRAE4/Lewis and Rosenfeld - 2016 - Electrical stimulation of the brain and the develo.pdf:application/pdf}
}

@article{zhao_chinese_2011,
	title = {Chinese {Character} {Recognition} {Using} {Simulated} {Phosphene} {Maps}},
	volume = {52},
	issn = {1552-5783},
	url = {http://iovs.arvojournals.org/article.aspx?doi=10.1167/iovs.09-4234},
	doi = {10.1167/iovs.09-4234},
	abstract = {PURPOSE. A visual prosthetic device may produce phosphene maps in which individual phosphene characteristics can be altered. This study was an investigation of the ability of normally sighted subjects to recognize Chinese characters (CCs) after altering simulated phosphene maps.
METHODS. Thirty volunteers with normal or corrected visual acuity of 20/20 were recruited. CC recognition accuracy and response time were investigated while one parameter was changed (distortion, pixel dropout percentage, pixel size variability, or pixel gray level) or different combinations of three parameters were used. Five hundred CCs consisting of 1 to 16 strokes were used for the character sets.
RESULTS. CC recognition accuracy and response times respectively decreased and increased when distortion, dropout, and pixel size variability increased. Gray levels did not signiﬁcantly affect the results, except when eight levels were used. To maintain an 80\% accuracy rate, there should be a distortion index (k) of no more than 0.2 (irregularity), a pixel dropout of 20\%, and a pixel size range of 1 to 16 mm (7–112 min arc). Only a combination of a k ϭ 0.1 distortion index, a dropout of 10\%, and a pixel size range of 1.33 to 12 mm (9.3– 84 min arc) achieved a goal of Ն80\% accuracy.
CONCLUSIONS. Distortion, dropout percentage, and pixel size variability have a signiﬁcant impact on pixelated CC recognition. Although at present the visual ability of prosthesis users is limited, it should be possible to extend this to CC recognition and reading in the future. The results will help visual prosthesis researchers determine the effects of altering phosphene maps},
	language = {en},
	number = {6},
	urldate = {2019-05-04},
	journal = {Investigative Opthalmology \& Visual Science},
	author = {Zhao, Ying and Lu, Yanyu and Zhou, Chuanqing and Chen, Yao and Ren, Qiushi and Chai, Xinyu},
	month = may,
	year = {2011},
	pages = {3404},
	file = {Zhao et al. - 2011 - Chinese Character Recognition Using Simulated Phos.pdf:/Users/wjmn/Zotero/storage/FAXAWLTI/Zhao et al. - 2011 - Chinese Character Recognition Using Simulated Phos.pdf:application/pdf}
}

@article{wang_face_2014,
	title = {Face recognition in simulated prosthetic vision: face detection-based image processing strategies},
	volume = {11},
	issn = {1741-2552},
	shorttitle = {Face recognition in simulated prosthetic vision},
	url = {https://doi.org/10.1088%2F1741-2560%2F11%2F4%2F046009},
	doi = {10.1088/1741-2560/11/4/046009},
	abstract = {Objective. Given the limited visual percepts elicited by current prosthetic devices, it is essential to optimize image content in order to assist implant wearers to achieve better performance of visual tasks. This study focuses on recognition of familiar faces using simulated prosthetic vision. Approach. Combined with region-of-interest (ROI) magnification, three face extraction strategies based on a face detection technique were used: the Viola–Jones face region, the statistical face region (SFR) and the matting face region. Main results. These strategies significantly enhanced recognition performance compared to directly lowering resolution (DLR) with Gaussian dots. The inclusion of certain external features, such as hairstyle, was beneficial for face recognition. Given the high recognition accuracy achieved and applicable processing speed, SFR-ROI was the preferred strategy. DLR processing resulted in significant face gender recognition differences (i.e. females were more easily recognized than males), but these differences were not apparent with other strategies. Significance. Face detection-based image processing strategies improved visual perception by highlighting useful information. Their use is advisable for face recognition when using low-resolution prosthetic vision. These results provide information for the continued design of image processing modules for use in visual prosthetics, thus maximizing the benefits for future prosthesis wearers.},
	language = {en},
	number = {4},
	urldate = {2019-05-04},
	journal = {Journal of Neural Engineering},
	author = {Wang, Jing and Wu, Xiaobei and Lu, Yanyu and Wu, Hao and Kan, Han and Chai, Xinyu},
	month = jun,
	year = {2014},
	pages = {046009},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/J36D34DB/Wang et al. - 2014 - Face recognition in simulated prosthetic vision f.pdf:application/pdf}
}

@article{li_image_2018,
	title = {Image processing strategies based on saliency segmentation for object recognition under simulated prosthetic vision},
	volume = {84},
	issn = {0933-3657},
	url = {http://www.sciencedirect.com/science/article/pii/S0933365716304195},
	doi = {10.1016/j.artmed.2017.11.001},
	abstract = {Background and objective
Current retinal prostheses can only generate low-resolution visual percepts constituted of limited phosphenes which are elicited by an electrode array and with uncontrollable color and restricted grayscale. Under this visual perception, prosthetic recipients can just complete some simple visual tasks, but more complex tasks like face identification/object recognition are extremely difficult. Therefore, it is necessary to investigate and apply image processing strategies for optimizing the visual perception of the recipients. This study focuses on recognition of the object of interest employing simulated prosthetic vision.
Method
We used a saliency segmentation method based on a biologically plausible graph-based visual saliency model and a grabCut-based self-adaptive-iterative optimization framework to automatically extract foreground objects. Based on this, two image processing strategies, Addition of Separate Pixelization and Background Pixel Shrink, were further utilized to enhance the extracted foreground objects.
Results
i) The results showed by verification of psychophysical experiments that under simulated prosthetic vision, both strategies had marked advantages over Direct Pixelization in terms of recognition accuracy and efficiency. ii) We also found that recognition performance under two strategies was tied to the segmentation results and was affected positively by the paired-interrelated objects in the scene.
Conclusion
The use of the saliency segmentation method and image processing strategies can automatically extract and enhance foreground objects, and significantly improve object recognition performance towards recipients implanted a high-density implant.},
	urldate = {2019-05-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Li, Heng and Su, Xiaofan and Wang, Jing and Kan, Han and Han, Tingting and Zeng, Yajie and Chai, Xinyu},
	month = jan,
	year = {2018},
	keywords = {Visual prosthesis, Simulated prosthetic vision, Image processing strategy, Objects recognition, Saliency segmentation},
	pages = {64--78},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/NK35WBT3/Li et al. - 2018 - Image processing strategies based on saliency segm.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/W4792H7I/S0933365716304195.html:text/html}
}

@inproceedings{han_object_2015,
	title = {Object recognition based on a foreground extraction method under simulated prosthetic vision},
	doi = {10.1109/ISBB.2015.7344951},
	abstract = {At present, retinal prostheses only generate low-resolution visual percepts because of a limited number of implantable electrodes. Prosthetic recipients are able to perform some simple visual tasks, but more complex tasks like object recognition are difficult. Therefore, image processing strategies to optimize the visual percepts of recipients were investigated. This study focused on object recognition under simulated prosthetic vision. A foreground extraction method based on a saliency model was proposed to obtain foreground object. Based on this, an image enhancement strategy combining edge information with foreground object was presented to obtain the pixelized image. Results showed that foreground extraction method achieved superior effects in foreground extraction. Psychophysical experiments verified that under simulated prosthetic vision, our method had prominent advantages in comparison with direct pixelization in terms of recognition accuracy and efficiency.},
	booktitle = {2015 {International} {Symposium} on {Bioelectronics} and {Bioinformatics} ({ISBB})},
	author = {Han, T. and Li, H. and Lyu, Q. and Zeng, Y. and Chai, X.},
	month = oct,
	year = {2015},
	keywords = {visual perception, biomedical electrodes, Visualization, prosthetics, eye, medical image processing, Retina, psychophysical experiments, biomedical optical imaging, edge detection, Image edge detection, Simulated prosthetic vision, Objects recognition, edge information, feature extraction, foreground extraction method, image enhancement, image enhancement strategy, image processing strategies, Image processing strategies, implantable electrodes, low-resolution visual perception, object recognition, Object recognition, pixelized image, prosthetic recipients, Prosthetics, retinal prostheses, Retinal prostheses, saliency model, simple visual tasks, simulated prosthetic vision, Visual perception},
	pages = {172--175},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/7VPG93EL/7344951.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/SRXA6I4U/Han et al. - 2015 - Object recognition based on a foreground extractio.pdf:application/pdf}
}

@article{fornos_simulation_2005,
	title = {Simulation of {Artificial} {Vision}, {III}: {Do} the {Spatial} or {Temporal} {Characteristics} of {Stimulus} {Pixelization} {Really} {Matter}?},
	volume = {46},
	issn = {1552-5783},
	shorttitle = {Simulation of {Artificial} {Vision}, {III}},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2181720},
	doi = {10.1167/iovs.04-1173},
	language = {en},
	number = {10},
	urldate = {2019-05-04},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Fornos, Angélica Pérez and Sommerhalder, Jörg and Rappaz, Benjamin and Safran, Avinoam B. and Pelizzone, Marco},
	month = oct,
	year = {2005},
	pages = {3906--3912},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/G4UG55RR/Fornos et al. - 2005 - Simulation of Artificial Vision, III Do the Spati.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/WAGW76X6/article.html:text/html}
}

@article{perez_fornos_simulation_2008,
	title = {Simulation of artificial vision: {IV}. {Visual} information required to achieve simple pointing and manipulation tasks},
	volume = {48},
	issn = {0042-6989},
	shorttitle = {Simulation of artificial vision},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698908002368},
	doi = {10.1016/j.visres.2008.04.027},
	abstract = {Retinal prostheses attempt to restore some amount of vision to totally blind patients. Vision evoked this way will be however severely constrained because of several factors (e.g., size of the implanted device, number of stimulating contacts, etc.). We used simulations of artificial vision to study how such restrictions of the amount of visual information provided would affect performance on simple pointing and manipulation tasks. Five normal subjects participated in the study. Two tasks were used: pointing on random targets (LEDs task) and arranging wooden chips according to a given model (CHIPs task). Both tasks had to be completed while the amount of visual information was limited by reducing the resolution (number of pixels) and modifying the size of the effective field of view. All images were projected on a 10°×7° viewing area, stabilised at a given position on the retina. In central vision, the time required to accomplish the tasks remained systematically slower than with normal vision. Accuracy was close to normal at high image resolutions and decreased at 500 pixels or below, depending on the field of view used. Subjects adapted quite rapidly (in less than 15 sessions) to performing both tasks in eccentric vision (15° in the lower visual field), achieving after adaptation performances close to those observed in central vision. These results demonstrate that, if vision is restricted to a small visual area stabilised on the retina (as would be the case in a retinal prosthesis), the perception of several hundreds of retinotopically arranged phosphenes is still needed to restore accurate but slow performance on pointing and manipulation tasks. Considering that present prototypes afford less than 100 stimulation contacts and that our simulations represent the most favourable visual input conditions that the user might experience, further development is required to achieve optimal rehabilitation prospects.},
	number = {16},
	urldate = {2019-05-04},
	journal = {Vision Research},
	author = {Pérez Fornos, Angélica and Sommerhalder, Jörg and Pittard, Alexandre and Safran, Avinoam B. and Pelizzone, Marco},
	month = jul,
	year = {2008},
	keywords = {Blindness, Retinal prosthesis, Shape recognition, Target localization, Visuomotor performance},
	pages = {1705--1718},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/THAS6CKZ/Pérez Fornos et al. - 2008 - Simulation of artificial vision IV. Visual inform.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/GABGJDBS/S0042698908002368.html:text/html}
}

@article{barnes_role_2012,
	series = {Special {Section}: {Opinion} {Papers}},
	title = {The role of computer vision in prosthetic vision},
	volume = {30},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885612000832},
	doi = {10.1016/j.imavis.2012.05.007},
	abstract = {The cost of vision loss worldwide has been estimated at nearly \$3 trillion (http://www.amdalliance.org/cost-of-blindness.html). Non-preventable diseases cause a significant proportion of blindness in developed nations and will become more prevalent as people live longer. Prosthetic vision technologies including retinal implants will play an important therapeutic role. Retinal implants convert an input image stream to visual percepts via stimulation of the retina. This paper highlights some barriers to restoring functional human vision for current generation visual prosthetic devices that computer vision can help overcome. Such computer vision is interactive, aiming to restore function including visuo-motor tasks and recognition.},
	number = {8},
	urldate = {2019-05-04},
	journal = {Image and Vision Computing},
	author = {Barnes, Nick},
	month = aug,
	year = {2012},
	keywords = {Bionic eye, Computer vision, Face recognition, Orientation and mobility, Prosthetic vision, Retinal implants},
	pages = {478--479},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/UVD5MSDN/Barnes - 2012 - The role of computer vision in prosthetic vision.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/W4JAG23Q/S0262885612000832.html:text/html}
}

@inproceedings{srivastava_proposed_2005,
	title = {A proposed intracortical visual prosthesis image processing system},
	doi = {10.1109/IEMBS.2005.1615667},
	abstract = {It has been a goal of neuroprosthesis researchers to develop a system, which could provide artificial vision to a large population of individuals with blindness. It has been demonstrated by earlier researches that stimulating the visual cortex area electrically can evoke spatial visual percepts, i.e. phosphenes. The goal of visual cortex prosthesis is to stimulate the visual cortex area and generate a visual perception in real time to restore vision. Even though the normal working of the visual system is not been completely understood, the existing knowledge has inspired research groups to develop strategies to develop visual cortex prosthesis which can help blind patients in their daily activities. A major limitation in this work is the development of an image processing system for converting an electronic image, as captured by a camera, into a real-time data stream for stimulation of the implanted electrodes. This paper proposes a system, which will capture the image using a camera and use a dedicated hardware real time image processor to deliver electrical pulses to intracortical electrodes. This system has to be flexible enough to adapt to individual patients and to various strategies of image reconstruction. Here we consider a preliminary architecture for this system},
	booktitle = {2005 {IEEE} {Engineering} in {Medicine} and {Biology} 27th {Annual} {Conference}},
	author = {Srivastava, N. R. and Troyk, P. R.},
	month = jan,
	year = {2005},
	keywords = {Blindness, visual perception, electrical stimulation, visual cortex, bioelectric phenomena, biomedical electrodes, Electrodes, neurophysiology, Visual prosthesis, blindness, intracortical visual prosthesis, prosthetics, vision defects, Image processing, medical image processing, Intracortical, visual prosthesis, biomedical optical imaging, Cameras, Prosthetics, Visual perception, artificial vision, electrical pulses, electronic image, image processing, image processing system, image reconstruction, Image restoration, implanted electrodes, intracortical electrodes, neuroprosthesis, phosphenes, Real time systems, spatial visual percepts, Visual system},
	pages = {5264--5267},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/CJBJUFR7/1615667.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/JM4XD2UJ/Srivastava and Troyk - 2005 - A proposed intracortical visual prosthesis image p.pdf:application/pdf}
}

@article{abraham_active_2019,
	title = {Active photonic sensing for super-resolved reading performance in simulated prosthetic vision},
	volume = {10},
	issn = {2156-7085, 2156-7085},
	url = {https://www.osapublishing.org/abstract.cfm?URI=boe-10-3-1081},
	doi = {10.1364/BOE.10.001081},
	abstract = {In this work, we study the enhancement of simulated prosthetic reading performance through “active photonic sensing” in normally sighted subjects. Three sensing paradigms were implemented: active sensing, in which the subject actively scanned the presented words using the computer mouse, with an option to control text size; passive scanning produced by software-initiated horizontal movements of words; and no scanning. Our findings reveal a 30\% increase in word recognition rate with active scanning as compared to no or passive scanning and up to 14-fold increase with zooming. These results highlight the importance of a patient interactive interface and shed light on techniques that can greatly enhance prosthetic vision quality.},
	language = {en},
	number = {3},
	urldate = {2019-05-04},
	journal = {Biomedical Optics Express},
	author = {Abraham, Chen and Farah, Nairouz and Gerbi-Zarfati, Liron and Harpaz, Yuval and Zalvesky, Zeev and Mandel, Yossi},
	month = mar,
	year = {2019},
	pages = {1081},
	file = {Abraham et al. - 2019 - Active photonic sensing for super-resolved reading.pdf:/Users/wjmn/Zotero/storage/K9GIIHGC/Abraham et al. - 2019 - Active photonic sensing for super-resolved reading.pdf:application/pdf}
}

@article{ahad_advancements_2018,
	title = {Advancements of {Image} {Processing} and {Vision} in {Healthcare}},
	volume = {2018},
	issn = {2040-2295, 2040-2309},
	url = {https://www.hindawi.com/journals/jhe/2018/8458024/},
	doi = {10.1155/2018/8458024},
	language = {en},
	urldate = {2019-05-04},
	journal = {Journal of Healthcare Engineering},
	author = {Ahad, Md Atiqur Rahman and Kobashi, Syoji and Tavares, João Manuel R. S.},
	year = {2018},
	pages = {1--3},
	file = {Ahad et al. - 2018 - Advancements of Image Processing and Vision in Hea.pdf:/Users/wjmn/Zotero/storage/9THXGIIL/Ahad et al. - 2018 - Advancements of Image Processing and Vision in Hea.pdf:application/pdf}
}

@article{atickt_could_nodate,
	title = {Could information theory provide an ecological theory of sensory processing?},
	language = {en},
	author = {Atickt, Joseph J},
	pages = {39},
	file = {Atickt - Could information theory provide an ecological the.pdf:/Users/wjmn/Zotero/storage/9Y9QTIHA/Atickt - Could information theory provide an ecological the.pdf:application/pdf}
}

@inproceedings{brady_visual_2013,
	address = {Paris, France},
	title = {Visual challenges in the everyday lives of blind people},
	isbn = {978-1-4503-1899-0},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2481291},
	doi = {10.1145/2470654.2481291},
	abstract = {The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the ﬁndings of a large-scale study of the visual questions that blind people would like to have answered. As part of this yearlong study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Brady, Erin and Morris, Meredith Ringel and Zhong, Yu and White, Samuel and Bigham, Jeffrey P.},
	year = {2013},
	pages = {2117},
	file = {Brady et al. - 2013 - Visual challenges in the everyday lives of blind p.pdf:/Users/wjmn/Zotero/storage/5VQ75RG6/Brady et al. - 2013 - Visual challenges in the everyday lives of blind p.pdf:application/pdf}
}

@article{guymer_progress_2016,
	title = {Progress in the clinical development and utilization of vision prostheses: an update},
	issn = {1179-2744},
	shorttitle = {Progress in the clinical development and utilization of vision prostheses},
	url = {https://www.dovepress.com/progress-in-the-clinical-development-and-utilization-of-vision-prosthe-peer-reviewed-article-EB},
	doi = {10.2147/EB.S70822},
	abstract = {Vision prostheses, or “bionic eyes”, are implantable medical bionic devices with the potential to restore rudimentary sight to people with profound vision loss or blindness. In the past two decades, this field has rapidly progressed, and there are now two commercially available retinal prostheses in the US and Europe, and a number of next-generation devices in development. This review provides an update on the development of these devices and a discussion on the future directions for the field.},
	language = {en},
	urldate = {2019-05-04},
	journal = {Eye and Brain},
	author = {Guymer, Robyn and Brandli, Alice and Luu, Chi and Ayton, Lauren},
	month = may,
	year = {2016},
	pages = {15},
	file = {Guymer et al. - 2016 - Progress in the clinical development and utilizati.pdf:/Users/wjmn/Zotero/storage/UQ8WDNS2/Guymer et al. - 2016 - Progress in the clinical development and utilizati.pdf:application/pdf}
}

@incollection{canny_readings_1987,
	title = {Readings in computer vision},
	abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to- a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge. This detection scheme uses several elongated operators at each point, and the directional operator outputs are integrated with the gradient maximum detector.},
	language = {en},
	booktitle = {A {Computational} {Approach} to {Edge} {Detection}},
	publisher = {Morgan Kaufmann},
	author = {Canny, John},
	year = {1987},
	pages = {184--203},
	file = {Canny - A Computational Approach to Edge Detection.pdf:/Users/wjmn/Zotero/storage/KQ7TQBF2/Canny - A Computational Approach to Edge Detection.pdf:application/pdf}
}

@article{caspi_assessing_2015,
	title = {Assessing the utility of visual acuity measures in visual prostheses},
	volume = {108},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698915000218},
	doi = {10.1016/j.visres.2015.01.006},
	abstract = {There are presently several ongoing clinical trials to provide usable sight to profoundly visually impaired patients by means of electrical stimulation of the retina. Some of the blind patients implanted with retinal prosthesis reported un-patterned perception and yet beneﬁt from the device in many activities of daily living, seemingly because they adopt active scanning strategies.},
	language = {en},
	urldate = {2019-05-04},
	journal = {Vision Research},
	author = {Caspi, Avi and Zivotofsky, Ari Z.},
	month = mar,
	year = {2015},
	pages = {77--84},
	file = {Caspi and Zivotofsky - 2015 - Assessing the utility of visual acuity measures in.pdf:/Users/wjmn/Zotero/storage/EL5VZEME/Caspi and Zivotofsky - 2015 - Assessing the utility of visual acuity measures in.pdf:application/pdf}
}

@article{chang_facial_2012,
	title = {Facial identification in very low-resolution images simulating prosthetic vision},
	volume = {9},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/9/i=4/a=046012?key=crossref.82f47f235753f422323435341cb2f4b0},
	doi = {10.1088/1741-2560/9/4/046012},
	abstract = {Familiar facial identiﬁcation is important to blind or visually impaired patients and can be achieved using a retinal prosthesis. Nevertheless, there are limitations in delivering the facial images with a resolution sufﬁcient to distinguish facial features, such as eyes and nose, through multichannel electrode arrays used in current visual prostheses. This study veriﬁes the feasibility of familiar facial identiﬁcation under low-resolution prosthetic vision and proposes an edge-enhancement method to deliver more visual information that is of higher quality. We ﬁrst generated a contrast-enhanced image and an edge image by applying the Sobel edge detector and blocked each of them by averaging. Then, we subtracted the blocked edge image from the blocked contrast-enhanced image and produced a pixelized image imitating an array of phosphenes. Before subtraction, every gray value of the edge images was weighted as 50\% (mode 2), 75\% (mode 3) and 100\% (mode 4). In mode 1, the facial image was blocked and pixelized with no further processing. The most successful identiﬁcation was achieved with mode 3 at every resolution in terms of identiﬁcation index, which covers both accuracy and correct response time. We also found that the subjects recognized a distinctive face especially more accurately and faster than the other given facial images even under low-resolution prosthetic vision. Every subject could identify familiar faces even in very low-resolution images. And the proposed edge-enhancement method seemed to contribute to intermediate-stage visual prostheses.},
	language = {en},
	number = {4},
	urldate = {2019-05-04},
	journal = {Journal of Neural Engineering},
	author = {Chang, M H and Kim, H S and Shin, J H and Park, K S},
	month = aug,
	year = {2012},
	pages = {046012},
	file = {Chang et al. - 2012 - Facial identification in very low-resolution image.pdf:/Users/wjmn/Zotero/storage/XQKZTP2S/Chang et al. - 2012 - Facial identification in very low-resolution image.pdf:application/pdf}
}

@article{chen_simulating_2009,
	title = {Simulating prosthetic vision: {II}. {Measuring} functional capacity},
	volume = {49},
	issn = {00426989},
	shorttitle = {Simulating prosthetic vision},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698909003253},
	doi = {10.1016/j.visres.2009.07.003},
	abstract = {Investigators of microelectronic visual prosthesis devices have found that some aspects of vision can be restored in the form of spots of light in the visual ﬁeld, so-called ‘‘phosphenes”, from which more rich and complex scenes may be composed. However, questions still surround the capabilities of how such a form of vision can allow its recipients to ‘‘see” and to carry out everyday activities. Through simulations of prosthetic vision, researchers can experience ﬁrst-hand many performance and behavioral aspects of prosthetic vision, and studies conducted on a larger population can inform the performance and behavioral preferences in general and in individual cases. This review examines the ﬁndings from the various investigations of the functional capacity of prosthetic vision conducted through simulations, especially on the topics of letter acuity, reading, navigation, learning and visual scanning adaptation. Central to the review, letter acuity is posited as a reference measurement so that results and performance trends across the various simulation models and functional assessment tasks can be more readily compared and generalized. Future directions for simulation based research are discussed with respect to designing a functional visual prosthesis, improving functional vision in near-term low-phosphene-count devices, and pursuing image processing strategies to impart the most comprehensible prosthetic vision.},
	language = {en},
	number = {19},
	urldate = {2019-05-04},
	journal = {Vision Research},
	author = {Chen, Spencer C. and Suaning, Gregg J. and Morley, John W. and Lovell, Nigel H.},
	month = sep,
	year = {2009},
	pages = {2329--2343},
	file = {Chen et al. - 2009 - Simulating prosthetic vision II. Measuring functi.pdf:/Users/wjmn/Zotero/storage/4H3A3A7W/Chen et al. - 2009 - Simulating prosthetic vision II. Measuring functi.pdf:application/pdf}
}

@article{chichilnisky_eduardo-jose_smart_2018,
	title = {{SMART} {PROSTHESIS} {FOR} {FACILITATING} {ARTIFICIAL} {VISION} {USING} {SCENE} {ABSTRACTION}},
	language = {en},
	author = {Chichilnisky, Eduardo-Jose and Greschner, Martin and Jepson, Lauren},
	year = {2018},
	pages = {27},
	file = {Greschner and Jepson - (72) Inventors Eduardo-Jose Chichilnisky, Palo Al.pdf:/Users/wjmn/Zotero/storage/TBVK9S36/Greschner and Jepson - (72) Inventors Eduardo-Jose Chichilnisky, Palo Al.pdf:application/pdf}
}

@article{fink_artificial_2014,
	title = {Artificial vision support system ({AVS} $^{\textrm{2}}$ ) for improved prosthetic vision},
	volume = {38},
	issn = {0309-1902, 1464-522X},
	url = {http://www.tandfonline.com/doi/full/10.3109/03091902.2014.957869},
	doi = {10.3109/03091902.2014.957869},
	abstract = {State-of-the-art and upcoming camera-driven, implanted artificial vision systems provide only tens to hundreds of electrodes, affording only limited visual perception for blind subjects. Therefore, real time image processing is crucial to enhance and optimize this limited perception. Since tens or hundreds of pixels/electrodes allow only for a very crude approximation of the typically megapixel optical resolution of the external camera image feed, the preservation and enhancement of contrast differences and transitions, such as edges, are especially important compared to picture details such as object texture. An Artificial Vision Support System (AVS2) is devised that displays the captured video stream in a pixelation conforming to the dimension of the epi-retinal implant electrode array. AVS2, using efficient image processing modules, modifies the captured video stream in real time, enhancing ‘present but hidden’ objects to overcome inadequacies or extremes in the camera imagery. As a result, visual prosthesis carriers may now be able to discern such objects in their ‘field-of-view’, thus enabling mobility in environments that would otherwise be too hazardous to navigate. The image processing modules can be engaged repeatedly in a user-defined order, which is a unique capability. AVS2 is directly applicable to any artificial vision system that is based on an imaging modality (video, infrared, sound, ultrasound, microwave, radar, etc.) as the first step in the stimulation/processing cascade, such as: retinal implants (i.e. epi-retinal, sub-retinal, suprachoroidal), optic nerve implants, cortical implants, electric tongue stimulators, or tactile stimulators.},
	language = {en},
	number = {8},
	urldate = {2019-05-04},
	journal = {Journal of Medical Engineering \& Technology},
	author = {Fink, Wolfgang and Tarbell, Mark A.},
	month = nov,
	year = {2014},
	pages = {385--395},
	file = {Fink and Tarbell - 2014 - Artificial vision support system (AVS sup2sup.pdf:/Users/wjmn/Zotero/storage/9CV5SULZ/Fink and Tarbell - 2014 - Artificial vision support system (AVS sup2sup.pdf:application/pdf}
}

@incollection{helal_blind_2008,
	address = {Hoboken, NJ, USA},
	title = {Blind {Navigation} and the {Role} of {Technology}},
	isbn = {978-0-470-37942-4 978-0-471-71155-1},
	url = {http://doi.wiley.com/10.1002/9780470379424.ch25},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {The {Engineering} {Handbook} of {Smart} {Technology} for {Aging}, {Disability}, and {Independence}},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Giudice, Nicholas A. and Legge, Gordon E.},
	editor = {Helal, Abdelsalam Sumi and Mokhtari, Mounir and Abdulrazak, Bessam},
	month = jan,
	year = {2008},
	doi = {10.1002/9780470379424.ch25},
	pages = {479--500},
	file = {Giudice and Legge - 2008 - Blind Navigation and the Role of Technology.pdf:/Users/wjmn/Zotero/storage/C8MB7CTZ/Giudice and Legge - 2008 - Blind Navigation and the Role of Technology.pdf:application/pdf}
}

@article{goetz_holographic_2013,
	title = {Holographic display system for restoration of sight to the blind},
	volume = {10},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/10/i=5/a=056021?key=crossref.785fe88ea3b6ae8b832730ed1a8bc78a},
	doi = {10.1088/1741-2560/10/5/056021},
	abstract = {Objective. We present a holographic near-the-eye display system enabling optical approaches for sight restoration to the blind, such as photovoltaic retinal prosthesis, optogenetic and other photoactivation techniques. We compare it with conventional liquid crystal displays (LCD) or digital light processing (DLP)-based displays in terms of image quality, ﬁeld of view, optical efﬁciency and safety. Approach. We detail the optical conﬁguration of the holographic display system and its characterization using a phase-only spatial light modulator. Main results. We describe approaches to controlling the zero diffraction order and speckle related issues in holographic display systems and assess the image quality of such systems. We show that holographic techniques offer signiﬁcant advantages in terms of peak irradiance and power efﬁciency, and enable designs that are inherently safer than LCD or DLP-based systems. We demonstrate the performance of our holographic display system in the assessment of cortical response to alternating gratings projected onto the retinas of rats. Signiﬁcance. We address the issues associated with the design of high brightness, near-the-eye display systems and propose solutions to the efﬁciency and safety challenges with an optical design which could be miniaturized and mounted onto goggles.},
	language = {en},
	number = {5},
	urldate = {2019-05-04},
	journal = {Journal of Neural Engineering},
	author = {Goetz, G A and Mandel, Y and Manivanh, R and Palanker, D V and Čižmár, T},
	month = oct,
	year = {2013},
	pages = {056021},
	file = {Goetz et al. - 2013 - Holographic display system for restoration of sigh.pdf:/Users/wjmn/Zotero/storage/TTTQV5YN/Goetz et al. - 2013 - Holographic display system for restoration of sigh.pdf:application/pdf}
}

@article{guo_decoding_2015,
	title = {Decoding brain responses to pixelized images in the primary visual cortex: implications for visual cortical prostheses},
	volume = {10},
	issn = {1673-5374},
	shorttitle = {Decoding brain responses to pixelized images in the primary visual cortex},
	url = {http://www.nrronline.org/text.asp?2015/10/10/1622/167761},
	doi = {10.4103/1673-5374.167761},
	abstract = {Visual cortical prostheses have the potential to restore partial vision. Still limited by the low-resolution visual percepts provided by visual cortical prostheses, implant wearers can currently only “see” pixelized images, and how to obtain the specific brain responses to different pixelized images in the primary visual cortex (the implant area) is still unknown. We conducted a functional magnetic resonance imaging experiment on normal human participants to investigate the brain activation patterns in response to 18 different pixelized images. There were 100 voxels in the brain activation pattern that were selected from the primary visual cortex, and voxel size was 4 mm × 4 mm × 4 mm. Multi-voxel pattern analysis was used to test if these 18 different brain activation patterns were specific. We chose a Linear Support Vector Machine (LSVM) as the classifier in this study. The results showed that the classification accuracies of different brain activation patterns were significantly above chance level, which suggests that the classifier can successfully distinguish the brain activation patterns. Our results suggest that the specific brain activation patterns to different pixelized images can be obtained in the primary visual cortex using a 4 mm × 4 mm × 4 mm voxel size and a 100-voxel pattern.},
	language = {en},
	number = {10},
	urldate = {2019-05-04},
	journal = {Neural Regeneration Research},
	author = {Guo, Bing-bing and Zheng, Xiao-lin and Lu, Zhen-gang and Wang, Xing and Yin, Zheng-qin and Hou, Wen-sheng and Meng, Ming},
	year = {2015},
	pages = {1622},
	file = {Guo et al. - 2015 - Decoding brain responses to pixelized images in th.pdf:/Users/wjmn/Zotero/storage/BCB27PLI/Guo et al. - 2015 - Decoding brain responses to pixelized images in th.pdf:application/pdf}
}

@article{guo_optimization_2018,
	title = {Optimization of {Visual} {Information} {Presentation} for {Visual} {Prosthesis}},
	volume = {2018},
	issn = {1687-4188, 1687-4196},
	url = {https://www.hindawi.com/journals/ijbi/2018/3198342/},
	doi = {10.1155/2018/3198342},
	abstract = {Visual prosthesis applying electrical stimulation to restore visual function for the blind has promising prospects. However, due to the low resolution, limited visual field, and the low dynamic range of the visual perception, huge loss of information occurred when presenting daily scenes. The ability of object recognition in real-life scenarios is severely restricted for prosthetic users. To overcome the limitations, optimizing the visual information in the simulated prosthetic vision has been the focus of research. This paper proposes two image processing strategies based on a salient object detection technique. The two processing strategies enable the prosthetic implants to focus on the object of interest and suppress the background clutter. Psychophysical experiments show that techniques such as foreground zooming with background clutter removal and foreground edge detection with background reduction have positive impacts on the task of object recognition in simulated prosthetic vision. By using edge detection and zooming technique, the two processing strategies significantly improve the recognition accuracy of objects. We can conclude that the visual prosthesis using our proposed strategy can assist the blind to improve their ability to recognize objects. The results will provide effective solutions for the further development of visual prosthesis.},
	language = {en},
	urldate = {2019-05-04},
	journal = {International Journal of Biomedical Imaging},
	author = {Guo, Fei and Yang, Yuan and Gao, Yong},
	year = {2018},
	pages = {1--12},
	file = {Guo et al. - 2018 - Optimization of Visual Information Presentation fo.pdf:/Users/wjmn/Zotero/storage/8EB7IH6U/Guo et al. - 2018 - Optimization of Visual Information Presentation fo.pdf:application/pdf}
}

@article{irons_new_2014,
	title = {A new theoretical approach to improving face recognition in disorders of central vision: {Face} caricaturing},
	volume = {14},
	issn = {1534-7362},
	shorttitle = {A new theoretical approach to improving face recognition in disorders of central vision},
	url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/14.2.12},
	doi = {10.1167/14.2.12},
	language = {en},
	number = {2},
	urldate = {2019-05-04},
	journal = {Journal of Vision},
	author = {Irons, J. and McKone, E. and Dumbleton, R. and Barnes, N. and He, X. and Provis, J. and Ivanovici, C. and Kwa, A.},
	month = feb,
	year = {2014},
	pages = {12--12},
	file = {Irons et al. - 2014 - A new theoretical approach to improving face recog.pdf:/Users/wjmn/Zotero/storage/39I5E4ZI/Irons et al. - 2014 - A new theoretical approach to improving face recog.pdf:application/pdf}
}

@inproceedings{noauthor_mobile_2012,
	address = {Vilamoura, Algarve, Portugal},
	title = {{MOBILE}, {REAL}-{TIME} {SIMULATOR} {FOR} {A} {CORTICAL} {VISUAL} {PROSTHESIS}:},
	isbn = {978-989-8425-91-1},
	shorttitle = {{MOBILE}, {REAL}-{TIME} {SIMULATOR} {FOR} {A} {CORTICAL} {VISUAL} {PROSTHESIS}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0003773300370046},
	doi = {10.5220/0003773300370046},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {Proceedings of the {International} {Conference} on {Biomedical} {Electronics} and {Devices}},
	publisher = {SciTePress - Science and and Technology Publications},
	year = {2012},
	pages = {37--46},
	file = {2012 - MOBILE, REAL-TIME SIMULATOR FOR A CORTICAL VISUAL .pdf:/Users/wjmn/Zotero/storage/H2CJKIBG/2012 - MOBILE, REAL-TIME SIMULATOR FOR A CORTICAL VISUAL .pdf:application/pdf}
}

@inproceedings{josh_psychophysics_2013,
	address = {Melbourne, Australia},
	title = {Psychophysics testing of bionic vision image processing algorithms using an {FPGA} {Hatpack}},
	isbn = {978-1-4799-2341-0},
	url = {http://ieeexplore.ieee.org/document/6738319/},
	doi = {10.1109/ICIP.2013.6738319},
	abstract = {Different image processing approaches are presented that are candidates for the Monash Vision Group prosthetic vision device. As described in a companion paper [6], the Monash Vision Group is developing a bionic eye based on the implantation of 7-11 stimulation tiles on the primary visual cortex of the brain. In the lead up to an expected 2014 first in-human trial of this device, potential image processing techniques and intuitive user interfaces need to be developed and evaluated. An FPGA Hatpack has been developed to give normally sighted people a similar binary limited resolution visual experience expected of a Bionic Eye recipient. The Hatpack has been used to generate new psychophysics results to evaluate and improve the performance and practicality of three different methods of luminance threshold selection. The results show an interesting difference in terms of performance and highlight areas of possible improvement for the algorithms used.},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {2013 {IEEE} {International} {Conference} on {Image} {Processing}},
	publisher = {IEEE},
	author = {Josh, Horace and Mann, Collette and Kleeman, Lindsay and Lui, Wen Lik Dennis},
	month = sep,
	year = {2013},
	pages = {1550--1554},
	file = {Josh et al. - 2013 - Psychophysics testing of bionic vision image proce.pdf:/Users/wjmn/Zotero/storage/BMKRQWZX/Josh et al. - 2013 - Psychophysics testing of bionic vision image proce.pdf:application/pdf}
}

@article{liu_augmented_2018,
	title = {Augmented reality powers a cognitive assistant for the blind},
	volume = {7},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/37841},
	doi = {10.7554/eLife.37841},
	abstract = {To restore vision for the blind, several prosthetic approaches have been explored that convey raw images to the brain. So far, these schemes all suffer from a lack of bandwidth. An alternate approach would restore vision at the cognitive level, bypassing the need to convey sensory data. A wearable computer captures video and other data, extracts important scene knowledge, and conveys that to the user in compact form. Here, we implement an intuitive user interface for such a device using augmented reality: each object in the environment has a voice and communicates with the user on command. With minimal training, this system supports many aspects of visual cognition: obstacle avoidance, scene understanding, formation and recall of spatial memories, navigation. Blind subjects can traverse an unfamiliar multi-story building on their first attempt. To spur further development in this domain, we developed an open-source environment for standardized benchmarking of visual assistive devices.},
	language = {en},
	urldate = {2019-05-04},
	journal = {eLife},
	author = {Liu, Yang and Stiles, Noelle RB and Meister, Markus},
	month = nov,
	year = {2018},
	pages = {e37841},
	file = {Liu et al. - 2018 - Augmented reality powers a cognitive assistant for.pdf:/Users/wjmn/Zotero/storage/ZVJB4C5W/Liu et al. - 2018 - Augmented reality powers a cognitive assistant for.pdf:application/pdf}
}

@inproceedings{lui_transformative_2012,
	address = {San Diego, CA},
	title = {Transformative {Reality}: {Improving} bionic vision with robotic sensing},
	isbn = {978-1-4577-1787-1 978-1-4244-4119-8},
	shorttitle = {Transformative {Reality}},
	url = {http://ieeexplore.ieee.org/document/6345929/},
	doi = {10.1109/EMBC.2012.6345929},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {2012 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	publisher = {IEEE},
	author = {Lui, W. L. D. and Browne, D. and Kleeman, L. and Drummond, T. and {Wai Ho Li}},
	month = aug,
	year = {2012},
	pages = {304--307},
	file = {Lui et al. - 2012 - Transformative Reality Improving bionic vision wi.pdf:/Users/wjmn/Zotero/storage/4X5IHJ6N/Lui et al. - 2012 - Transformative Reality Improving bionic vision wi.pdf:application/pdf}
}

@article{mace_simulated_2015,
	title = {Simulated {Prosthetic} {Vision}: {The} {Benefits} of {Computer}-{Based} {Object} {Recognition} and {Localization}: {Computer} {Vision} for {Low} {Resolution} {Visual} {Implants}},
	volume = {39},
	issn = {0160564X},
	shorttitle = {Simulated {Prosthetic} {Vision}},
	url = {http://doi.wiley.com/10.1111/aor.12476},
	doi = {10.1111/aor.12476},
	language = {en},
	number = {7},
	urldate = {2019-05-04},
	journal = {Artificial Organs},
	author = {Macé, Marc J.-M. and Guivarch, Valérian and Denis, Grégoire and Jouffrais, Christophe},
	month = jul,
	year = {2015},
	pages = {E102--E113},
	file = {Macé et al. - 2015 - Simulated Prosthetic Vision The Benefits of Compu.pdf:/Users/wjmn/Zotero/storage/G7W5U3HR/Macé et al. - 2015 - Simulated Prosthetic Vision The Benefits of Compu.pdf:application/pdf}
}

@article{markowitz_rehabilitation_2018,
	title = {Rehabilitation of lost functional vision with the {Argus} {II} retinal prosthesis},
	volume = {53},
	issn = {00084182},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0008418217309729},
	doi = {10.1016/j.jcjo.2017.12.001},
	abstract = {RÉSUMÉ The Argus II retinal prosthesis is the first commercially available device for restoration of vision in patients with Retinitis Pigmentosa or with similar retinal pathology who still have minimal residual native vision. The technology is able to restore vision with production of artificial visual percepts which usually are given adequate useful interpretation by the visual system in most implanted patients. The technology usually produces visual perception at the level of shape identification or better in some cases enabling in many less dependence on vision substitution devices and skills. There is no consensus among vision rehabilitation practitioners on single methods for assessments, outcome measures and training, yet there is constant progress in these areas of concern. Hence the current vision rehabilitation practice related to the implantation of the Argus II retinal prosthesis is a work in progress with many learning opportunities for all involved. All agree that implementation of this technology in clinical practice requires the combined work of a multi-disciplinary team which includes a specialized surgical team as well as a specialized rehabilitation team in order to obtain optimal results. Our own experience is presented in this paper and indicates so far that the Argus II technology is beneficial to patients and that it could be successfully managed within the Canadian heath care system.},
	language = {en},
	number = {1},
	urldate = {2019-05-04},
	journal = {Canadian Journal of Ophthalmology},
	author = {Markowitz, Michelle and Rankin, Mark and Mongy, Mohamed and Patino, Beatrice E. and Manusow, Joshua and Devenyi, Robert G. and Markowitz, Samuel N.},
	month = feb,
	year = {2018},
	pages = {14--22},
	file = {Markowitz et al. - 2018 - Rehabilitation of lost functional vision with the .pdf:/Users/wjmn/Zotero/storage/LHPQVAUI/Markowitz et al. - 2018 - Rehabilitation of lost functional vision with the .pdf:application/pdf}
}

@techreport{mccartney_towards_2019,
	type = {preprint},
	title = {Towards a real-world brain-computer interface for image retrieval},
	url = {http://biorxiv.org/lookup/doi/10.1101/576983},
	abstract = {Brain decoding — the process of inferring a person’s momentary cognitive state from their brain activity — has enormous potential in the field of human-computer interaction. In this study we propose a zero-shot EEG-to-image brain decoding approach which makes use of state-of-the-art EEG preprocessing and feature selection methods, and which maps EEG activity to biologically inspired computer vision and linguistic models. We apply this approach to solve the problem of identifying viewed images from recorded brain activity in a reliable and scalable way. We demonstrate competitive decoding accuracies across two EEG datasets, using a zero-shot learning framework more applicable to real-world image retrieval than traditional classification techniques.},
	language = {en},
	urldate = {2019-05-04},
	institution = {Neuroscience},
	author = {McCartney, Ben and Martinez-del-Rincon, Jesus and Devereux, Barry and Murphy, Brian},
	month = mar,
	year = {2019},
	doi = {10.1101/576983},
	file = {McCartney et al. - 2019 - Towards a real-world brain-computer interface for .pdf:/Users/wjmn/Zotero/storage/XJ37A24T/McCartney et al. - 2019 - Towards a real-world brain-computer interface for .pdf:application/pdf}
}

@article{mohammadi_image_2012,
	title = {An {Image} {Processing} {Approach} for {Blind} {Mobility} {Facilitated} {Through} {Visual} {Intracortical} {Stimulation}: {IMAGE} {PROCESSING} {APPROACH} {FOR} {BLIND} {MOBILITY}},
	volume = {36},
	issn = {0160564X},
	shorttitle = {An {Image} {Processing} {Approach} for {Blind} {Mobility} {Facilitated} {Through} {Visual} {Intracortical} {Stimulation}},
	url = {http://doi.wiley.com/10.1111/j.1525-1594.2011.01421.x},
	doi = {10.1111/j.1525-1594.2011.01421.x},
	abstract = {This article presents an image processing approach dedicated for a blind mobility aid facilitated through visual intracortical electrical stimulation. The method examines a display framework based on the distances related to a scene. The distances of objects to the walker are measured using a size perspective method which uses only one camera without any occlusion effect. The method extracts the information of the closest object to the camera and transfers a sense of distance to a blind walker.},
	language = {en},
	number = {7},
	urldate = {2019-05-04},
	journal = {Artificial Organs},
	author = {Mohammadi, Hossein Mahvash and Ghafar-Zadeh, Ebrahim and Sawan, Mohamad},
	month = jul,
	year = {2012},
	pages = {616--628},
	file = {Mohammadi et al. - 2012 - An Image Processing Approach for Blind Mobility Fa.pdf:/Users/wjmn/Zotero/storage/4IXV9JEP/Mohammadi et al. - 2012 - An Image Processing Approach for Blind Mobility Fa.pdf:application/pdf}
}

@article{paradiso_54_2019,
	title = {(54) {INTELLIGENT} {VISUAL} {PROSTHESIS}},
	abstract = {A visual prosthetic system includes a computer system , and a wearable spectacle, the wearable spectacle linked to the computer system and comprising a pair of headphones , a microphone, a depth camera , a sensor, a fish -eye camera and 3D spectacle frame, the computer system configured to receive outputs from the depth camera , the sensor and the fish -eye camera to track a user's hand and a target object simultaneously.},
	language = {en},
	author = {Paradiso, Michael},
	year = {2019},
	pages = {6},
	file = {Paradiso - 2019 - (54) INTELLIGENT VISUAL PROSTHESIS.pdf:/Users/wjmn/Zotero/storage/245N6TWZ/Paradiso - 2019 - (54) INTELLIGENT VISUAL PROSTHESIS.pdf:application/pdf}
}

@inproceedings{perez-yus_depth_2017,
	address = {Venice},
	title = {Depth and {Motion} {Cues} with {Phosphene} {Patterns} for {Prosthetic} {Vision}},
	isbn = {978-1-5386-1034-3},
	url = {http://ieeexplore.ieee.org/document/8265389/},
	doi = {10.1109/ICCVW.2017.179},
	abstract = {Recent research demonstrates that visual prostheses are able to provide visual perception to people with some kind of blindness. In visual prostheses, image information from the scene is transformed to a phosphene pattern to be sent to the implant. This is a complex problem where the main challenge is the very limited spatial and intensity resolution. Moreover, depth perception, which is relevant to perform agile navigation, is lost and codifying the semantic information to phosphene patterns remains an open problem. In this work, we consider the framework of perception for navigation where aspects such as obstacle avoidance are critical. We propose using a head-mounted RGB-D camera to detect free-space, obstacles and scene direction in front of the user. The main contribution is a new approach to represent depth information and provide motion cues by using particular phosphene patterns. The effectiveness of this approach is tested in simulation with real data from indoor environments.},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCVW})},
	publisher = {IEEE},
	author = {Perez-Yus, Alejandro and Bermudez-Cameo, Jesus and Guerrero, Jose J. and Lopez-Nicolas, Gonzalo},
	month = oct,
	year = {2017},
	pages = {1516--1525},
	file = {Perez-Yus et al. - 2017 - Depth and Motion Cues with Phosphene Patterns for .pdf:/Users/wjmn/Zotero/storage/2SWJXCZP/Perez-Yus et al. - 2017 - Depth and Motion Cues with Phosphene Patterns for .pdf:application/pdf}
}

@incollection{chaaraoui_computer_2016,
	title = {Computer vision for active and assisted living},
	isbn = {978-1-84919-987-2 978-1-84919-988-9},
	url = {https://digital-library.theiet.org/content/books/10.1049/pbhe006e_ch4},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {Active and {Assisted} {Living}: {Technologies} and {Applications}},
	publisher = {Institution of Engineering and Technology},
	author = {{Florez-Revuelta} and {Planinc} and {Kampel} and {Chaaraoui}},
	editor = {{Chaaraoui} and {Florez-Revuelta}},
	month = aug,
	year = {2016},
	doi = {10.1049/PBHE006E_ch4},
	pages = {57--79},
	file = {Florez-Revuelta et al. - 2016 - Computer vision for active and assisted living.pdf:/Users/wjmn/Zotero/storage/R9MBQV2B/Florez-Revuelta et al. - 2016 - Computer vision for active and assisted living.pdf:application/pdf}
}

@incollection{bryant_information_2006,
	address = {Southampton UK},
	edition = {1},
	title = {Information theory and sensory perception},
	volume = {1},
	isbn = {978-1-85312-853-0},
	url = {https://www.witpress.com/elibrary/wit-transactions-on-state-of-the-art-in-science-and-engineering/27/18518},
	abstract = {In this chapter, we explore Shannon’s information theory and what it may tell us about the biological processes of sensory perception. We begin by discussing some historical theories of sensory perception, including concepts of objects and invariances as well as principles from Gestalt psychology. We consider the ecological principle that perception should be useful for an organism, and introduce information theory as a possible way to measure this usefulness. After introducing some of the key concepts from information theory, such as entropy, information, redundancy and factorial coding, we draw parallels between communication in engineering systems and sensory perception. We discuss Attneave’s early proposal that perception should create an economical description of sensory inputs, as measured by information theory, and Barlow’s suggestion of lateral inhibition as a possible mechanism to achieve this. We discuss the important role played by noise in an information processing system, and its importance when determining how to optimise the communication of information. This leads to the concept of information-optimal ﬁlters which change their characteristics at different signal-to-noise levels, a feature exhibited by ﬂy and human visual systems. For information processed across topographic maps, optimal information processing leads to a principle of uniform information density, whereby a larger area in the cortex allows higher information density, and hence higher accuracy or sensitivity, at the corresponding sensors. We also discuss some recent investigations of information theory applied to spiking neural systems, and the concept of economy of impulses. Finally, we discuss some related concepts such as structure in a perceptual stimulus and implications for Gibson’s ideas about perceptual systems, and we speculate about the possible importance of attention and active perception for efﬁcient information processing in a sensory system.},
	language = {en},
	urldate = {2019-05-04},
	booktitle = {{WIT} {Transactions} on {State}-of-the-art in {Science} and {Engineering}},
	publisher = {WIT Press},
	author = {Plumbley, M.D. and Abdallah, S.A.},
	editor = {Bryant, J. A. and Atherton, M. A. and Collins, M. W.},
	month = oct,
	year = {2006},
	doi = {10.2495/978-1-85312-853-0/07},
	pages = {205--233},
	file = {Plumbley and Abdallah - 2006 - Information theory and sensory perception.pdf:/Users/wjmn/Zotero/storage/LAX59YE4/Plumbley and Abdallah - 2006 - Information theory and sensory perception.pdf:application/pdf}
}

@article{rao_towards_2019,
	title = {Towards neural co-processors for the brain: combining decoding and encoding in brain–computer interfaces},
	volume = {55},
	issn = {09594388},
	shorttitle = {Towards neural co-processors for the brain},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818301843},
	doi = {10.1016/j.conb.2019.03.008},
	abstract = {The field of brain-computer interfaces is poised to advance from the traditional goal of controlling prosthetic devices using brain signals to combining neural decoding and encoding within a single neuroprosthetic device. Such a device acts as a “co-processor” for the brain, with applications ranging from inducing Hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. We review recent progress in simultaneous decoding and encoding for closed-loop control and plasticity induction. To address the challenge of multi-channel decoding and encoding, we introduce a unifying framework for developing brain co-processors based on artificial neural networks and deep learning. These “neural co-processors” can be used to jointly optimize cost functions with the nervous system to achieve desired behaviors ranging from targeted neuro-rehabilitation to augmentation of brain function.},
	language = {en},
	urldate = {2019-05-04},
	journal = {Current Opinion in Neurobiology},
	author = {Rao, Rajesh PN},
	month = apr,
	year = {2019},
	pages = {142--151},
	file = {Rao - 2019 - Towards neural co-processors for the brain combin.pdf:/Users/wjmn/Zotero/storage/KLI52H55/Rao - 2019 - Towards neural co-processors for the brain combin.pdf:application/pdf}
}

@article{rassia_improvement_2018,
	title = {Improvement in reading performance through training with simulated thalamic visual prostheses},
	volume = {8},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-018-31435-0},
	doi = {10.1038/s41598-018-31435-0},
	language = {en},
	number = {1},
	urldate = {2019-05-04},
	journal = {Scientific Reports},
	author = {Rassia, Katerina Eleonora K. and Pezaris, John S.},
	month = dec,
	year = {2018},
	pages = {16310},
	file = {Rassia and Pezaris - 2018 - Improvement in reading performance through trainin.pdf:/Users/wjmn/Zotero/storage/3AHMQDF6/Rassia and Pezaris - 2018 - Improvement in reading performance through trainin.pdf:application/pdf}
}

@article{van_rheede_simulating_2010,
	title = {Simulating prosthetic vision: {Optimizing} the information content of a limited visual display},
	volume = {10},
	issn = {1534-7362},
	shorttitle = {Simulating prosthetic vision},
	url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/10.14.32},
	doi = {10.1167/10.14.32},
	abstract = {Visual prostheses for the restoration of functional vision are currently under development. To guide prosthesis research and allow for an accurate prognosis of functional gain, simulating the experience of a retinal prosthesis in healthy individuals is desirable. Current simulation paradigms lack crucial aspects of the prosthetic experience such as realistic head- and eyeposition-dependent image presentation. We developed a simulation paradigm that used a head-mounted camera and eye tracker to lock the simulation to the point of ﬁxation. We evaluated visual acuity, object recognition and manipulation, and wayﬁnding under simulated prosthetic vision. We explored three ways of optimizing the information content of the prosthetic visual image: Full-Field representation (wide visual angle, low sampling frequency), Region of Interest (ROI; narrow visible angle, high sampling frequency), and Fisheye (high sampling frequency in the center, progressively lower resolution toward the edges). Full-Field representation facilitated visual search and navigation, whereas ROI improved visual acuity. The Fisheye representation, designed to incorporate the beneﬁts of both Full-Field representation and ROI, performed similarly to ROI with subjects unable to capitalize on the peripheral data. The observation that different image representation conditions prove advantageous for different tasks should be taken into account in the process of designing and testing new visual prosthesis prototypes.},
	language = {en},
	number = {14},
	urldate = {2019-05-04},
	journal = {Journal of Vision},
	author = {van Rheede, J. J. and Kennard, C. and Hicks, S. L.},
	month = dec,
	year = {2010},
	pages = {32--32},
	file = {van Rheede et al. - 2010 - Simulating prosthetic vision Optimizing the infor.pdf:/Users/wjmn/Zotero/storage/VTQ8NMKL/van Rheede et al. - 2010 - Simulating prosthetic vision Optimizing the infor.pdf:application/pdf}
}

@article{sanchez-garcia_structural_2018,
	title = {Structural and object detection for phosphene images},
	url = {http://arxiv.org/abs/1809.09607},
	abstract = {Prosthetic vision based on phosphenes is a promising way to provide visual perception to some blind people. However, phosphenic images are very limited in terms of spatial resolution (e.g.: 32 x 32 phosphene array) and luminance levels (e.g.: 8 gray levels), which results in the subject receiving very limited information about the scene. This requires using high-level processing to extract more information from the scene and present it to the subject with the phosphenes limitations. In this work, we study the recognition of indoor environments under simulated prosthetic vision. Most research in simulated prosthetic vision is performed based on static images, while very few researchers have addressed the problem of scene recognition through video sequences. We propose a new approach to build a schematic representation of indoor environments for phosphene images. Our schematic representation relies on two parallel CNNs for the extraction of structural informative edges of the room and the relevant object silhouettes based on mask segmentation. We have performed a study with twelve normally sighted subjects to evaluate how they were able to recognize the rooms by presenting phosphenic images and videos with our method. We show how our method is able to increase the recognition ability of the user from ∼ 75\% using alternative methods to 90\% using our approach.},
	language = {en},
	urldate = {2019-05-04},
	journal = {arXiv:1809.09607 [cs]},
	author = {Sanchez-Garcia, Melani and Martinez-Cantin, Ruben and Guerrero, Jose J.},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.09607},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Sanchez-Garcia et al. - 2018 - Structural and object detection for phosphene imag.pdf:/Users/wjmn/Zotero/storage/BR97ZNCE/Sanchez-Garcia et al. - 2018 - Structural and object detection for phosphene imag.pdf:application/pdf}
}

@article{massiceti_stereosonic_2018,
	title = {Stereosonic vision: {Exploring} visual-to-auditory sensory substitution mappings in an immersive virtual reality navigation paradigm},
	volume = {13},
	issn = {1932-6203},
	shorttitle = {Stereosonic vision},
	url = {https://dx.plos.org/10.1371/journal.pone.0199389},
	doi = {10.1371/journal.pone.0199389},
	language = {en},
	number = {7},
	urldate = {2019-05-04},
	journal = {PLOS ONE},
	author = {Massiceti, Daniela and Hicks, Stephen Lloyd and van Rheede, Joram Jacob},
	editor = {Sathian, Krish},
	month = jul,
	year = {2018},
	pages = {e0199389},
	file = {Massiceti et al. - 2018 - Stereosonic vision Exploring visual-to-auditory s.pdf:/Users/wjmn/Zotero/storage/CFYB7ATY/Massiceti et al. - 2018 - Stereosonic vision Exploring visual-to-auditory s.pdf:application/pdf}
}

@article{szegedy_deep_nodate,
	title = {Deep {Neural} {Networks} for {Object} {Detection}},
	abstract = {Deep Neural Networks (DNNs) have recently shown outstanding performance on image classiﬁcation tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We deﬁne a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications. State-of-the-art performance of the approach is shown on Pascal VOC.},
	language = {en},
	author = {Szegedy, Christian and Toshev, Alexander and Erhan, Dumitru},
	pages = {9},
	file = {Szegedy et al. - Deep Neural Networks for Object Detection.pdf:/Users/wjmn/Zotero/storage/WV34QWLA/Szegedy et al. - Deep Neural Networks for Object Detection.pdf:application/pdf}
}

@article{troy_visual_2015,
	title = {Visual {Prostheses}: {Technological} and {Socioeconomic} {Challenges}},
	volume = {1},
	issn = {20958099},
	shorttitle = {Visual {Prostheses}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2095809916300066},
	doi = {10.15302/J-ENG-2015080},
	abstract = {Visual prostheses are now entering the clinical marketplace. Such prostheses were originally targeted for patients suﬀering from blindness through retinitis pigmentosa (RP). However, in late July of this year, for the first time a patient was given a retinal implant in order to treat dry agerelated macular degeneration. Retinal implants are suitable solutions for diseases that attack photoreceptors but spare most of the remaining retinal neurons. For eye diseases that result in loss of retinal output, implants that interface with more central structures in the visual system are needed. The standard site for central visual prostheses under development is the visual cortex. This perspective discusses the technical and socioeconomic challenges faced by visual prostheses.},
	language = {en},
	number = {3},
	urldate = {2019-05-04},
	journal = {Engineering},
	author = {Troy, John B.},
	month = sep,
	year = {2015},
	pages = {288--291},
	file = {Troy - 2015 - Visual Prostheses Technological and Socioeconomic.pdf:/Users/wjmn/Zotero/storage/53M5CTQ7/Troy - 2015 - Visual Prostheses Technological and Socioeconomic.pdf:application/pdf}
}

@article{vergnieux_simplification_2017,
	title = {Simplification of {Visual} {Rendering} in {Simulated} {Prosthetic} {Vision} {Facilitates} {Navigation}: {SIMPLIFICATION} {OF} {VISUAL} {RENDERING}},
	volume = {41},
	issn = {0160564X},
	shorttitle = {Simplification of {Visual} {Rendering} in {Simulated} {Prosthetic} {Vision} {Facilitates} {Navigation}},
	url = {http://doi.wiley.com/10.1111/aor.12868},
	doi = {10.1111/aor.12868},
	language = {en},
	number = {9},
	urldate = {2019-05-04},
	journal = {Artificial Organs},
	author = {Vergnieux, Victor and Macé, Marc J.-M. and Jouffrais, Christophe},
	month = sep,
	year = {2017},
	pages = {852--861},
	file = {Vergnieux et al. - 2017 - Simplification of Visual Rendering in Simulated Pr.pdf:/Users/wjmn/Zotero/storage/V5P7LK8W/Vergnieux et al. - 2017 - Simplification of Visual Rendering in Simulated Pr.pdf:application/pdf}
}

@article{wang_image_2004,
	title = {Image {Quality} {Assessment}: {From} {Error} {Measurement} to {Structural} {Similarity}},
	volume = {13},
	abstract = {Objective methods for assessing perceptual image quality traditionally attempt to quantify the visibility of errors (diﬀerences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a speciﬁc example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000. A MatLab implementation of the proposed algorithm is available online at http://www.cns.nyu.edu/{\textasciitilde}lcv/ssim/.},
	language = {en},
	journal = {IEEE TRANSACTIONS ON IMAGE PROCESSING},
	author = {Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
	year = {2004},
	pages = {14},
	file = {Wang et al. - 2004 - Image Quality Assessment From Error Measurement t.pdf-:/Users/wjmn/Zotero/storage/NMBNSMW2/Wang et al. - 2004 - Image Quality Assessment From Error Measurement t.pdf-:application/pdf}
}

@article{weeraratne_challenges_2012,
	title = {Challenges faced by visually disabled people in use of medicines, self-adopted coping strategies and medicine-related mishaps},
	volume = {1},
	issn = {2224-3151},
	url = {http://www.who-seajph.org/text.asp?2012/1/3/256/207022},
	doi = {10.4103/2224-3151.207022},
	abstract = {Background: Difficulties faced by visually disabled people when using medicines, self-adopted coping strategies, and medicine-related mishaps have been under-explored locally and internationally. The objective of this study was to gain insight regarding this long-neglected issue.
Methods: A descriptive cross-sectional study, using an interviewer administered questionnaire on 63 visually disabled adults was carried out at a vocational training centre and a school for visually disabled students in Sri Lanka.
Results: Among 63 participants, 71\% wanted to be independent in medicine use and 79\% in spite of difficulties had self-administered medicines. They had difficulty in locating medicines (25.39\%), identifying medicines and medicine containers (17.46\%), and administering liquid medications (25.39\%). These difficulties led to inaccurate dosing (14.28\%), missed doses (39.68\%), and discontinuation of treatment prematurely (28.57\%). Self-adopted coping strategies to overcome these difficulties included using different sized and shaped containers, tying medicines to the attire, and dipping their finger into a measuring cup while measuring liquid medicines. Mishaps related to medicines such as taking vinegar instead of gripe mixture and, putting ear drops into eyes were disclosed.
Conclusions: There were many challenges for visually disabled people in taking medicines and some self-adopted coping strategies were inadequate to overcome these.},
	language = {en},
	number = {3},
	urldate = {2019-05-04},
	journal = {WHO South-East Asia Journal of Public Health},
	author = {Weeraratne, ChamariL and Opatha, SharmikaT and Rosa, ChamithT},
	year = {2012},
	pages = {256},
	file = {Weeraratne et al. - 2012 - Challenges faced by visually disabled people in us.pdf:/Users/wjmn/Zotero/storage/WZKRWF8S/Weeraratne et al. - 2012 - Challenges faced by visually disabled people in us.pdf:application/pdf}
}

@article{zhao_object_2018,
	title = {Object {Detection} with {Deep} {Learning}: {A} {Review}},
	shorttitle = {Object {Detection} with {Deep} {Learning}},
	url = {http://arxiv.org/abs/1807.05511},
	abstract = {Due to object detection’s close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classiﬁers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modiﬁcations and useful tricks to improve detection performance further. As distinct speciﬁc detection tasks exhibit different characteristics, we also brieﬂy survey several speciﬁc tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.},
	language = {en},
	urldate = {2019-05-04},
	journal = {arXiv:1807.05511 [cs]},
	author = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.05511},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhao et al. - 2018 - Object Detection with Deep Learning A Review.pdf:/Users/wjmn/Zotero/storage/LVFHZECN/Zhao et al. - 2018 - Object Detection with Deep Learning A Review.pdf:application/pdf}
}

@patent{dialameh_augmented_2013,
	title = {Augmented reality panorama supporting visually impaired individuals},
	url = {https://patents.google.com/patent/EP2539883A1/en},
	abstract = {There is presented a system and method for providing real-time object recognition to a remote user. The system comprises a portable communication device including a camera, at least one client-server host device remote from and accessible by the portable communication device over a network, and a recognition database accessible by the client-server host device or devices. A recognition application residing on the client-server host device or devices is capable of utilizing the recognition database to provide real-time object recognition of visual imagery captured using the portable communication device to the remote user of the portable communication device. In one embodiment, a sighted assistant shares an augmented reality panorama with a visually impaired user of the portable communication device where the panorama is constructed from sensor data from the device},
	nationality = {EP},
	assignee = {Nant Vision Inc},
	number = {EP2539883A1},
	urldate = {2019-05-05},
	author = {Dialameh, Orang and Miller, Douglas and Blanchard, Charles and Dorcey, Timothy C. and Sudol, Jeremi M.},
	month = jan,
	year = {2013},
	keywords = {augmented reality, data, device, engine, panorama},
	annote = {Classifications
G09B21/005: Details of specially-adapted software to access information, e.g. to browse through hyperlinked information
A61F9/08: Devices or methods enabling eye-patients to replace direct visual perception by another kind of perception
A61H3/061: Walking aids for blind persons with electronic detecting or guiding means
G06F16/583: Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
G06F16/955: Retrieval from the web using information identifiers, e.g. uniform resource locators [URL]
G06K9/00664: Recognising scenes such as could be captured by a camera operated by a pedestrian or robot, including objects at substantially different ranges from the camera
G06K9/00671: Recognising scenes such as could be captured by a camera operated by a pedestrian or robot, including objects at substantially different ranges from the camera for providing information about objects in the scene to a user, e.g. as in augmented reality applications
G06K9/22: Image acquisition using hand-held instruments
G09B21/008: Teaching or communicating with blind persons using visual presentation of the information for the partially sighted
G09B5/125: Electrically-operated educational appliances providing for individual presentation of information to a plurality of student stations different stations being capable of presenting different information simultaneously the stations being mobile
H04M1/72594: Portable communication terminals with improved user interface to control a main telephone operation mode or to indicate the communication status specially adapted for disabled people for a visually impaired user
A61H2201/0157: Constructive details portable
A61H2201/501: Control means thereof computer controlled connected to external computer devices or networks
A61H2201/5048: Audio interfaces, e.g. voice or music controlled
A61H2201/5092: Optical sensor}
}

@patent{li_image_2017,
	title = {Image processing method and system for irregular output patterns},
	url = {https://patents.google.com/patent/EP3122235A1/en},
	abstract = {A visual image processing method is based on received spatial field information (302) from a spatial field sensor (116). A data store (804) is accessed, which contains a sensor map data structure (206) comprising a set of predefined regions (208) within a spatial field corresponding with the information received via the sensor input. Each predefined region is associated in the data structure with one or more of a set of stimuli (204) applicable to a biological visual system, and each stimulus corresponds with a visual percept (210). The spatial field information associated with each region is processed to generate stimulus control information which is applied to select, from within the sensor map data structure, stimuli from the set of stimuli for application to the biological visual system. Output stimulus signals (310) are generated, which are suitable for application to the biological visual system based upon the selected stimuli. Flexible mappings are thus provided between visual percepts, stimuli which may be applied (e.g. via a prosthetic implant) in order to generate the percepts, and associations between those stimuli and regions of the spatial field corresponding with the visual percepts.},
	nationality = {EP},
	language = {en},
	assignee = {Monash University},
	number = {EP3122235A1},
	urldate = {2019-05-05},
	author = {LI, Wai Ho},
	month = feb,
	year = {2017},
	keywords = {region, sensor, stimuli, system, visual},
	annote = {Classifications
A61F2/14: Eye parts, e.g. lenses, corneal implants; Implanting instruments specially adapted therefor; Artificial eyes
A61N1/36046: Applying electric currents by contact electrodes alternating or intermittent currents for stimulation of the eye
G06T11/00: 2D [Two Dimensional] image generation
G06T11/60: Editing figures and text; Combining figures or text
G06K9/00671: Recognising scenes such as could be captured by a camera operated by a pedestrian or robot, including objects at substantially different ranges from the camera for providing information about objects in the scene to a user, e.g. as in augmented reality applications}
}

@article{elmannai_sensor-based_2017,
	title = {Sensor-{Based} {Assistive} {Devices} for {Visually}-{Impaired} {People}: {Current} {Status}, {Challenges}, and {Future} {Directions}},
	volume = {17},
	issn = {1424-8220},
	shorttitle = {Sensor-{Based} {Assistive} {Devices} for {Visually}-{Impaired} {People}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5375851/},
	doi = {10.3390/s17030565},
	abstract = {The World Health Organization (WHO) reported that there are 285 million visually-impaired people worldwide. Among these individuals, there are 39 million who are totally blind. There have been several systems designed to support visually-impaired people and to improve the quality of their lives. Unfortunately, most of these systems are limited in their capabilities. In this paper, we present a comparative survey of the wearable and portable assistive devices for visually-impaired people in order to show the progress in assistive technology for this group of people. Thus, the contribution of this literature survey is to discuss in detail the most significant devices that are presented in the literature to assist this population and highlight the improvements, advantages, disadvantages, and accuracy. Our aim is to address and present most of the issues of these systems to pave the way for other researchers to design devices that ensure safety and independent mobility to visually-impaired people.},
	number = {3},
	urldate = {2019-05-05},
	journal = {Sensors (Basel, Switzerland)},
	author = {Elmannai, Wafa and Elleithy, Khaled},
	month = mar,
	year = {2017},
	pmid = {28287451},
	pmcid = {PMC5375851},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/US9HEUEC/Elmannai and Elleithy - 2017 - Sensor-Based Assistive Devices for Visually-Impair.pdf:application/pdf}
}

@article{josh_real-time_2011,
	title = {A {Real}-time {FPGA}-based {Vision} {System} for a {Bionic} {Eye}},
	abstract = {Visual prosthesis simulators aim to provide a means of demonstrating, evaluating and improving the results of artificial vision devices. They transform the normal view of a camera scene into a form that represents the visual perceptions that would be caused by applying electrical stimulation to a part of the human visual pathway. These perceptions are called phosphenes and, in a cortical visual prosthesis, can be elicited through stimulation of the neurons in the visual cortex. This paper presents an FPGA implementation of a real-time vision system that simulates this phenomenon. The system is low-cost, mobile and consists of a CMOS camera, FPGA development board, and a head-mounted display. The methods of implementation discussed in this paper are applicable to other intelligent mobile sensor and machine vision applications where speed, low latency and low power consumption are important factors.},
	language = {en},
	author = {Josh, Horace and Yong, Benedict and Kleeman, Lindsay and Road, Wellington},
	year = {2011},
	pages = {8},
	file = {Josh et al. - 2011 - A Real-time FPGA-based Vision System for a Bionic .pdf:/Users/wjmn/Zotero/storage/6MQKNZQN/Josh et al. - 2011 - A Real-time FPGA-based Vision System for a Bionic .pdf:application/pdf}
}

@article{polimeni_multi-area_2006,
	title = {Multi-area visuotopic map complexes in macaque striate and extra-striate cortex},
	volume = {46},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698906001428},
	doi = {10.1016/j.visres.2006.03.006},
	abstract = {We propose that a simple, closed-form mathematical expression—the Wedge–Dipole mapping—provides a concise approximation to the full-field, two-dimensional topographic structure of macaque V1, V2, and V3. A single map function, which we term a map complex, acts as a simultaneous descriptor of all three areas. Quantitative estimation of the Wedge–Dipole parameters is provided via 2DG data of central-field V1 topography and a publicly available data set of full-field macaque V1 and V2 topography. Good quantitative agreement is obtained between the data and the model presented here. The increasing importance of fMRI-based brain imaging motivates the development of more sophisticated two-dimensional models of cortical visuotopy, in contrast to the one-dimensional approximations that have been in common use. One reason is that topography has traditionally supplied an important aspect of “ground truth,” or validation, for brain imaging, suggesting that further development of high-resolution fMRI will be facilitated by this data analysis. In addition, several important insights into the nature of cortical topography follow from this work. The presence of anisotropy in cortical magnification factor is shown to follow mathematically from the shared boundary conditions at the V1–V2 and V2–V3 borders, and therefore may not causally follow from the existence of columnar systems in these areas, as is widely assumed. An application of the Wedge–Dipole model to localizing aspects of visual processing to specific cortical areas—extending previous work in correlating V1 cortical magnification factor to retinal anatomy or visual psychophysics data—is briefly discussed.},
	number = {20},
	urldate = {2019-05-05},
	journal = {Vision Research},
	author = {Polimeni, J. R. and Balasubramanian, M. and Schwartz, E. L.},
	month = oct,
	year = {2006},
	keywords = {Visual cortex, Quasiconformal mapping, Retinotopic, Topographic map complex, Topographic modeling},
	pages = {3336--3359},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/A2NBB53W/Polimeni et al. - 2006 - Multi-area visuotopic map complexes in macaque str.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/SJCYMWSY/S0042698906001428.html:text/html}
}

@article{cha_simulation_1992,
	title = {Simulation of a phosphene-based visual field: {Visual} acuity in a pixelized vision system},
	volume = {20},
	shorttitle = {Simulation of a phosphene-based visual field},
	doi = {10.1007/BF02368135},
	abstract = {A visual prosthesis for the blind using electrical stimulation of the visual cortex will require the development of an array of electrodes. Passage of current through these electrodes is expected to create a visual image made up of a matrix of discrete phosphenes. The quality of the visual sense thus provided will be a function of many parameters, particularly the number of electrodes and their spacing. We are conducting a series of psychophysical experiments with a portable "phosphene" simulator to obtain estimates of suitable values for electrode number and spacing. The simulator consists of a small video camera and monitor worn by a normally sighted human subject. To simulate a discrete phosphene field, the monitor is masked by an opaque perforated film. The visual angle subtended by images from the masked monitor is 1.7 degrees or less, depending on the mask, and falls within the fovea of the subject. In the study presented here, we measured visual acuity as a function of the number of pixels and their spacing in the mask. Visual acuity was inversely proportional to pixel density, and trained subjects could achieve about 20/26 visual acuity with a 1024 pixel image. We conclude that 625 electrodes implanted in a 1 cm by 1 cm area near the foveal representation of the visual cortex should produce a phosphene image with a visual acuity of approximately 20/30. Such an acuity could provide useful restoration of functional vision for the profoundly blind.},
	journal = {Annals of biomedical engineering},
	author = {Cha, Kichul and Horch, Kenneth and A. Normann, Richard},
	month = feb,
	year = {1992},
	pages = {439--49},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/H32D9SHX/Cha et al. - 1992 - Simulation of a phosphene-based visual field Visu.pdf:application/pdf}
}

@article{spencer_creating_2018,
	title = {Creating virtual electrodes with 2D current steering},
	volume = {15},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2552%2Faab1b8},
	doi = {10.1088/1741-2552/aab1b8},
	abstract = {Objective. Current steering techniques have shown promise in retinal prostheses as a way to increase the number of distinct percepts elicitable without increasing the number of implanted electrodes. Previously, it has been shown that ‘virtual’ electrodes can be created between simultaneously stimulated electrode pairs, producing unique cortical response patterns. This study investigated whether virtual electrodes could be created using 2D current steering, and whether these virtual electrodes can produce cortical responses with predictable spatial characteristics. Approach. Normally-sighted eyes of seven adult anaesthetised cats were implanted with a 42-channel electrode array in the suprachoroidal space and multi-unit neural activity was recorded from the visual cortex. Stimuli were delivered to individual physical electrodes, or electrodes grouped into triangular, rectangular, and hexagonal arrangements. Varying proportions of charge were applied to each electrode in a group to ‘steer’ current and create virtual electrodes. The centroids of cortical responses to stimulation of virtual electrodes were compared to those evoked by stimulation of single physical electrodes. Main results. Responses to stimulation of groups of up to six electrodes with equal ratios of charge on each electrode resulted in cortical activation patterns that were similar to those elicited by the central physical electrode (centroids: RM ANOVA on ranks, p {\textgreater} 0.05; neural spread: one-way ANOVA on Ranks, p {\textgreater} 0.05). We were also able to steer the centroid of activation towards the direction of any of the electrodes of the group by applying a greater charge to that electrode, but the movement in the centroid was not found to be significant. Significance. The results suggest that current steering is possible in two dimensions between up to at least six electrodes, indicating it may be possible to increase the number of percepts in patients without increasing the number of physical electrodes. Being able to reproduce spatial characteristics of responses to individual physical electrodes suggests that this technique could also be used to compensate for faulty electrodes.},
	language = {en},
	number = {3},
	urldate = {2019-05-05},
	journal = {Journal of Neural Engineering},
	author = {Spencer, Thomas C. and Fallon, James B. and Shivdasani, Mohit N.},
	month = mar,
	year = {2018},
	pages = {035002},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/AF5ZVBBQ/Spencer et al. - 2018 - Creating virtual electrodes with 2D current steeri.pdf:application/pdf}
}

@article{mccarthy_mobility_2014,
	title = {Mobility and low contrast trip hazard avoidance using augmented depth},
	volume = {12},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2560%2F12%2F1%2F016003},
	doi = {10.1088/1741-2560/12/1/016003},
	abstract = {Objective. We evaluated a novel visual representation for current and near-term prosthetic vision. Augmented depth emphasizes ground obstacles and floor-wall boundaries in a depth-based visual representation. This is achieved by artificially increasing contrast between obstacles and the ground surface via a novel ground plane extraction algorithm specifically designed to preserve low-contrast ground-surface boundaries. Approach. The effectiveness of augmented depth was examined in human mobility trials compared against standard intensity-based (Intensity), depth-based (Depth) and random (Random) visual representations. Eight participants with normal vision used simulated prosthetic vision with 20 phosphenes and eight perceivable brightness levels to traverse a course with randomly placed small and low-contrast obstacles on the ground. Main results. The number of collisions was significantly reduced using augmented depth, compared with intensity, depth and random representations (48\%, 44\% and 72\% less collisions, respectively). Significance. These results indicate that augmented depth may enable safe mobility in the presence of low-contrast obstacles with current and near-term implants. This is the first demonstration that an augmentation of the scene ensuring key objects are visible may provide better outcomes for prosthetic vision.},
	language = {en},
	number = {1},
	urldate = {2019-05-05},
	journal = {Journal of Neural Engineering},
	author = {McCarthy, Chris and Walker, Janine G. and Lieby, Paulette and Scott, Adele and Barnes, Nick},
	month = nov,
	year = {2014},
	pages = {016003},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/JRQDRTGH/McCarthy et al. - 2014 - Mobility and low contrast trip hazard avoidance us.pdf:application/pdf}
}

@article{chen_quantitative_2007,
	title = {A quantitative analysis of head movement behaviour during visual acuity assessment under prosthetic vision simulation},
	volume = {4},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2560%2F4%2F1%2Fs13},
	doi = {10.1088/1741-2560/4/1/S13},
	abstract = {In most current vision prosthesis designs, head movement is the sole director of visual gaze and scanning due to the head-mounted nature of the camera. Study of this unnatural behaviour may provide insight into improved prosthesis designs and rehabilitation procedures. In this paper, we conducted a psychophysical study to investigate the characteristics of head movements of normally sighted subjects undergoing a visual acuity task in simulated prosthetic vision (SPV). In 12 naïve, untrained subjects, we recorded spontaneous changes in the amount of head movements during SPV sessions compared to control (normal vision) sessions. The observed behaviour continued to be refined until five or six sessions of practice. Increased head movement velocity was shown to be correlated to improved visual acuity performance, up to 0.3 logMAR, an equivalent of detecting details at half the physical size compared to complete deprivation of head movements. We postulate that visual scanning can as much as double the spatial frequency information in prosthetic vision. Increased head movement velocity observed when subjects were attempting smaller test items and for low-pass filtering schemes with higher cut-off frequencies may be further evidence that higher frequency content may be available through visual scanning, unconsciously driving subjects to increase head movement velocity.},
	language = {en},
	number = {1},
	urldate = {2019-05-05},
	journal = {Journal of Neural Engineering},
	author = {Chen, S. C. and Hallum, L. E. and Suaning, G. J. and Lovell, N. H.},
	month = feb,
	year = {2007},
	pages = {S108--S123},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/F9RGM38U/Chen et al. - 2007 - A quantitative analysis of head movement behaviour.pdf:application/pdf}
}

@inproceedings{chen_effect_2004,
	title = {Effect on prosthetic vision visual acuity by filtering schemes, filter cut-off frequency and phosphene matrix: a virtual reality simulation},
	volume = {2},
	shorttitle = {Effect on prosthetic vision visual acuity by filtering schemes, filter cut-off frequency and phosphene matrix},
	doi = {10.1109/IEMBS.2004.1404172},
	abstract = {Visual acuity of prosthetic vision was examined under virtual reality simulation. Prosthetic vision was simulated by first filtering an image using circular mean filters or Gaussian smoothing filters of different cut-off frequencies. Pixel values at 100 fixed sites of the filtered image were taken, sampling either with a regular rectangular or hexagonal matrix. Each pixel value was transformed into a Gaussian intensity profile centered at the corresponding position at which the sample was taken to simulate the evoked visual effect of an electric stimulation. Visual acuity scores of three subjects, each completing two sets of results, were recorded across different filtering schemes, cut-off frequencies and sampling matrices. The best mean score recorded was 1.55 logMAR, with the worst being 1.70 logMAR. The difference was mostly attributed to filter cut-off frequency. Differences between filtering schemes were insignificant. Results also showed emerging trends demonstrating differences between rectangular and hexagonal sampling matrices.},
	booktitle = {The 26th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Chen, S. C. and Lovell, N. H. and Suaning, G. J.},
	month = sep,
	year = {2004},
	keywords = {visual perception, phosphene, prosthetics, medical image processing, vision, Prosthetics, circular mean filters, Cutoff frequency, electric stimulation, evoked visual effect, filter cut-off frequency, Filtering, Filters, Gaussian processes, Gaussian smoothing filters, Image sampling, Pixel, prosthetic vision, prosthetic vision visual acuity, Sampling methods, smoothing methods, Smoothing methods, virtual reality, Virtual reality, virtual reality simulation, vision prosthesis, visual acuity, Visual effects},
	pages = {4201--4204},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/KE83F4WC/1404172.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/9FDJQVSA/Chen et al. - 2004 - Effect on prosthetic vision visual acuity by filte.pdf:application/pdf}
}

@article{vurro_simulation_2014,
	title = {Simulation of thalamic prosthetic vision: reading accuracy, speed, and acuity in sighted humans},
	volume = {8},
	issn = {1662-5161},
	shorttitle = {Simulation of thalamic prosthetic vision},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2014.00816/full},
	doi = {10.3389/fnhum.2014.00816},
	abstract = {The psychophysics of reading with artificial sight has received increasing attention as visual prostheses are becoming a real possibility to restore useful function to the blind through the coarse, pseudo-pixelized vision they generate. Studies to date have focused on simulating retinal prostheses; here we extend that work to report on thalamic designs. This study examined the reading performance of normally sighted human subjects using a simulation of three thalamic visual prostheses that varied in phosphene count, to help understand the level of functional ability afforded by thalamic designs in a task of daily living. Reading accuracy, reading speed, and reading acuity of 20 subjects were measured as a function of letter size, using a task based on the MNREAD chart. Results showed that fluid reading was available with appropriate combinations of letter size and phosphene count, and performance degraded smoothly as font size was decreased, with an approximate doubling of phosphene count resulting in an increase of 0.2 logMAR in acuity. Results here were consistent with previous results from our laboratory. Results were also consistent with those from the literature, despite using naive subjects who were not trained on the simulator, in contrast to other reports.},
	language = {English},
	urldate = {2019-05-05},
	journal = {Frontiers in Human Neuroscience},
	author = {Vurro, Milena and Crowell, Anne Marie and Pezaris, John S.},
	year = {2014},
	keywords = {artificial vision, Lateral Geniculate Nucleus, low vision, reading psychophysics, Visual Prosthesis},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/ZTGP885B/Vurro et al. - 2014 - Simulation of thalamic prosthetic vision reading .pdf:application/pdf}
}

@inproceedings{vergnieux_wayfinding_2014,
	title = {Wayfinding with simulated prosthetic vision: {Performance} comparison with regular and structure-enhanced renderings},
	shorttitle = {Wayfinding with simulated prosthetic vision},
	doi = {10.1109/EMBC.2014.6944151},
	abstract = {In this study, we used a simulation of upcoming low-resolution visual neuroprostheses to evaluate the benefit of embedded computer vision techniques in a wayfinding task. We showed that augmenting the classical phosphene rendering with the basic structure of the environment - displaying the ground plane with a different level of brightness - increased both wayfinding performance and cognitive mapping. In spite of the low resolution of current and upcoming visual implants, the improvement of these cognitive functions may already be possible with embedded artificial vision algorithms.},
	booktitle = {2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Vergnieux, V. and Macé, M. J.- and Jouffrais, C.},
	month = aug,
	year = {2014},
	keywords = {Humans, Phosphenes, Adult, Female, Male, Visualization, prosthetics, Implants, vision, Vision, Ocular, handicapped aids, Prosthetics, simulated prosthetic vision, Algorithms, cognitive functions, Computer Simulation, embedded artificial vision algorithms, embedded computer vision techniques, Eye, Artificial, Games, ground plane display, low resolution visual neuroprostheses, Models, Biological, Navigation, Performance analysis, phosphene rendering, regular rendering, Rendering (computer graphics), structure enhanced rendering, wayfinding task, Young Adult},
	pages = {2585--2588},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/GWCVYWEH/6944151.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/TT8EX3FV/Vergnieux et al. - 2014 - Wayfinding with simulated prosthetic vision Perfo.pdf:application/pdf}
}

@article{chen_simulating_2009-1,
	title = {Simulating prosthetic vision: {I}. {Visual} models of phosphenes},
	volume = {49},
	issn = {0042-6989},
	shorttitle = {Simulating prosthetic vision},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698909000467},
	doi = {10.1016/j.visres.2009.02.003},
	abstract = {With increasing research advances and clinical trials of visual prostheses, there is significant demand to better understand the perceptual and psychophysical aspects of prosthetic vision. In prosthetic vision a visual scene is composed of relatively large, isolated, spots of light so-called “phosphenes”, very much like a magnified pictorial print. The utility of prosthetic vision has been studied by investigators in the form of virtual–reality visual models (simulations) of prosthetic vision administered to normally sighted subjects. In this review, the simulations from these investigations are examined with respect to how they visually render the phosphenes and the virtual–reality apparatus involved. A comparison is made between these simulations and the actual descriptions of phosphenes reported from human trials of visual prosthesis devices. For the results from these simulation studies to be relevant to the experience of visual prosthesis recipients, it is important that, the simulated phosphenes must be consistent with the descriptions from human trials. A standardized simulation and reporting framework is proposed so that future simulations may be configured to be more realistic to the experience of implant recipients, and the simulation parameters from different investigators may be more readily extracted, and study results more fittingly compared.},
	number = {12},
	urldate = {2019-05-05},
	journal = {Vision Research},
	author = {Chen, Spencer C. and Suaning, Gregg J. and Morley, John W. and Lovell, Nigel H.},
	month = jun,
	year = {2009},
	keywords = {Phosphenes, Electrical stimulation, Visual prosthesis, Simulated prosthetic vision, Virtual–reality},
	pages = {1493--1506},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/8ZKICTEM/Chen et al. - 2009 - Simulating prosthetic vision I. Visual models of .pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/2B3H4S2Q/S0042698909000467.html:text/html}
}

@article{miyamoto_age-related_2017,
	title = {Age-related changes in the spatiotemporal responses to electrical stimulation in the visual cortex of rats with progressive vision loss},
	volume = {7},
	doi = {10.1038/s41598-017-14303-1},
	abstract = {The Royal College of Surgeons (RCS) rat gradually loses vision due to retinal degeneration. Previous physiological studies have depicted the progressive loss of optical responses in the visual pathway, including the primary visual cortex (V1), over the course of retinal degeneration in the RCS rat. However, little is known about how the excitability of the V1 circuit changes during over the course of the gradual loss of visual signal input from the retina. We elucidated the properties of responses to electrical stimulations directly applied to V1 at different stages of vision input loss in the RCS rat in reference to those of the Long-Evans (LE) rat, using in vivo voltage-sensitive dye imaging. The V1 neuronal network of the RCS rat exhibited an excitatory response comparable to the LE rat. The excitatory response was maintained even long after total loss of the visual signal input from the retina. However, the response time-course suggested that the suppressive response was somewhat debilitated in the RCS rat. This is the first experiment demonstrating the long-term effect of retinal degeneration on cortical activities. Our findings provide the physiological fundamentals to enhance the preclinical research of cortical prostheses with the use of the RCS rat. © 2017 The Author(s).},
	number = {1},
	journal = {Scientific Reports},
	author = {Miyamoto, S. and Suematsu, N. and Umehira, Y. and Hayashida, Y. and Yagi, T.},
	year = {2017},
	annote = {Cited By :2},
	file = {Full Text:/Users/wjmn/Zotero/storage/57PZMAZP/Miyamoto et al. - 2017 - Age-related changes in the spatiotemporal response.pdf:application/pdf;SCOPUS Snapshot:/Users/wjmn/Zotero/storage/T9WFMM99/display.html:text/html}
}

@article{thomson_cortical_2017,
	title = {Cortical neuroprosthesis merges visible and invisible light without impairing native sensory function},
	volume = {4},
	doi = {10.1523/ENEURO.0262-17.2017},
	abstract = {Adult rats equipped with a sensory prosthesis, which transduced infrared (IR) signals into electrical signals delivered to somatosensory cortex (S1), took approximately 4 d to learn a four-choice IR discrimination task. Here, we show that when such IR signals are projected to the primary visual cortex (V1), rats that are pretrained in a visual-discrimination task typically learn the same IR discrimination task on their first day of training. However, without prior training on a visual discrimination task, the learning rates for S1- and V1-implanted animals converged, suggesting there is no intrinsic difference in learning rate between the two areas. We also discovered that animals were able to integrate IR information into the ongoing visual processing stream in V1, performing a visual-IR integration task in which they had to combine IR and visual information. Furthermore, when the IR prosthesis was implanted in S1, rats showed no impairment in their ability to use their whiskers to perform a tactile discrimination task. Instead, in some rats, this ability was actually enhanced. Cumulatively, these findings suggest that cortical sensory neuroprostheses can rapidly augment the representational scope of primary sensory areas, integrating novel sources of information into ongoing processing while incurring minimal loss of native function. © 2017 Thomson et al.},
	number = {6},
	journal = {eNeuro},
	author = {Thomson, E.E. and Zea, I. and Windham, W. and Thenaisie, Y. and Walker, C. and Pedowitz, J. and França, W. and Graneiro, A.L. and Nicolelis, M.A.L.},
	year = {2017},
	keywords = {Plasticity, Neuroprosthesis, Behavior, Multisensory integration},
	file = {Full Text:/Users/wjmn/Zotero/storage/3WFJNQ6G/Thomson et al. - 2017 - Cortical neuroprosthesis merges visible and invisi.pdf:application/pdf;SCOPUS Snapshot:/Users/wjmn/Zotero/storage/JIDESYB5/display.html:text/html}
}

@article{dagnelie_psychophysical_2008,
	title = {Psychophysical {Evaluation} for {Visual} {Prosthesis}},
	volume = {10},
	url = {https://doi.org/10.1146/annurev.bioeng.10.061807.160529},
	doi = {10.1146/annurev.bioeng.10.061807.160529},
	abstract = {Vision restoration through retinal, optic nerve, and cortical implants is no longer just the stuff of fantasy. The design and development of visual prostheses rapidly move from the engineering phase toward preclinical and clinical trials, yet the benchmarks to determine their efficacy in blind research subjects have received very little attention, and likewise the selection criteria and preparation of early recipients of these devices. This article examines the aspects of vision for which prostheses may be of help, the selection of early prosthesis wearers, and the pre- and postimplant evaluations required to assess safety and efficacy. I concentrate on the functional assessment, and particularly on psychophysical methodology, but also address other measures of safety and efficacy, as well as approaches to vision rehabilitation with visual prostheses. Finally, I speculate what roles the first few generations of visual prostheses may play, and emphasize the importance of using simulations to support the development and rehabilitation process.},
	number = {1},
	urldate = {2019-05-05},
	journal = {Annual Review of Biomedical Engineering},
	author = {Dagnelie, Gislin},
	year = {2008},
	pmid = {18429703},
	pages = {339--368},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/TI46SK5C/Dagnelie - 2008 - Psychophysical Evaluation for Visual Prosthesis.pdf:application/pdf}
}

@inproceedings{ortmann_intracortical_2007,
	title = {Intracortical {Neural} {Interface} for {Prosthetic} {Applications}},
	doi = {10.1109/IEMBS.2007.4353813},
	abstract = {New design of intracortical penetrating electrodes with integrated electronic front end is presented. The main advantage of the presented manufacturing technology is a simple customization of the electrode lengths and arrangement, according to the brain geometry of the specific patient. The neural interface may be used for the stimulation of the inner cortical layers and for recording of evoked potentials. Experimental investigations on several cats have shown the higher effectiveness of the intracortical stimulation of the primary visual cortex in comparison to surface electrodes.},
	booktitle = {2007 29th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Ortmann, V. and Baziyan, B. K.},
	month = aug,
	year = {2007},
	keywords = {Electric Stimulation, Electrodes, Implanted, Visual Cortex, Evoked Potentials, Visual, Animals, biomedical electrodes, Electrodes, neurophysiology, Microelectrodes, primary visual cortex, prosthetics, Neural prosthesis, Implants, Prostheses and Implants, Retina, Behavior, Animal, biomedical measurement, Blood vessels, brain, Brain, Cats, Conditioning (Psychology), evoked potential recordings, Geometry, Glass, Gold, inner cortical layer stimulation, integrated electronic front end, intracortical neural interface, intracortical penetrating electrodes, Manufacturing, Materials Testing, patient's brain geometry, prosthetic applications, user interfaces, visual evoked potentials},
	pages = {6371--6374},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/JVDDQDNZ/4353813.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/THCIFDVK/Ortmann and Baziyan - 2007 - Intracortical Neural Interface for Prosthetic Appl.pdf:application/pdf}
}

@article{brunton_comparison_2012,
	title = {A comparison of microelectrodes for a visual cortical prosthesis using finite element analysis},
	volume = {5},
	issn = {1662-6443},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3460534/},
	doi = {10.3389/fneng.2012.00023},
	abstract = {Altering the geometry of microelectrodes for use in a cortical neural prosthesis modifies the electric field generated in tissue, thereby affecting electrode efficacy and tissue damage. Commonly, electrodes with an active region located at the tip (“conical” electrodes) are used for stimulation of cortex but there is argument to believe this geometry may not be the best. Here we use finite element analysis to compare the electric fields generated by three types of electrodes, a conical electrode with exposed active tip, an annular electrode with active area located up away from the tip, and a striped annular electrode where the active annular region has bands of insulation interrupting the full active region. The results indicate that the current density on the surface of the conical electrodes can be up to 10 times greater than the current density on the annular electrodes of the same height, which may increase the propensity for tissue damage. However choosing the most efficient electrode geometry in order to reduce power consumption is dependent on the distance of the electrode to the target neurons. If neurons are located within 10 μm of the electrode, then a small conical electrode would be more power efficient. On the other hand if the target neuron is greater than 500 μm away—as happens normally when insertion of an array of electrodes into cortex results in a “kill zone” around each electrode due to insertion damage and inflammatory responses—then a large annular electrode would be more efficient.},
	urldate = {2019-05-05},
	journal = {Frontiers in Neuroengineering},
	author = {Brunton, Emma and Lowery, Arthur J. and Rajan, Ramesh},
	month = sep,
	year = {2012},
	pmid = {23060789},
	pmcid = {PMC3460534},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/88BYDXTB/Brunton et al. - 2012 - A comparison of microelectrodes for a visual corti.pdf:application/pdf}
}

@inproceedings{fernandez_development_2015,
	title = {Development of a cortical visual neuroprosthesis for the blind: {Replacing} the role of the retina},
	shorttitle = {Development of a cortical visual neuroprosthesis for the blind},
	doi = {10.1109/NER.2015.7146609},
	abstract = {Cortical prostheses are a subgroup of visual neuroprosthesis capable of eliciting visual percepts in profoundly blind people through direct stimulation of the occipital cortex. This approach is the only treatment available for blindness caused by glaucoma, optic atrophy or by diseases of the central visual pathways such as brain injuries or stroke. If these higher visual centers could be stimulated with visual information in a format somewhat similar to the way they were stimulated before the onset of blindness, a blind individual could be able to use this stimulation to extract information about the physical world around him/her. Here we present an update of the strategies we are using to transmit visual information in a meaningful way to the brain.},
	booktitle = {2015 7th {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering} ({NER})},
	author = {Fernández, E. and Martínez-Álvarez, A. and Olmedo, A. and Romero, S. and Morillas, C. and Ferrandez, J. M. and Pelayo, F. and Normann, R. A.},
	month = apr,
	year = {2015},
	keywords = {Blindness, Electrodes, neurophysiology, Visualization, blindness, prosthetics, eye, Retina, retina, diseases, brain, visual evoked potentials, Arrays, Biological system modeling, brain injuries, central visual pathways, cortical visual neuroprosthesis, glaucoma, Neurons, occipital cortex, optic atrophy, stroke},
	pages = {260--263},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/TLIEMGBK/7146609.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/SMJZV7D7/Fernández et al. - 2015 - Development of a cortical visual neuroprosthesis f.pdf:application/pdf}
}

@inproceedings{sugiura_programmable_2016,
	title = {A programmable controller for spatio-temporal pattern stimulation of cortical visual prosthesis},
	doi = {10.1109/BioCAS.2016.7833824},
	abstract = {This paper proposes a programmable stimulation controller for cortical visual prosthesis to configure spatiotemporal parameters of stimulation. Since the relationship between stimulation to the visual cortex and responses in vision has not been clarified enough, both flexibility for stimulation strategies and timewise precision of stimulation are required for in-vivo experiments. In the proposed stimulation controller, a 16-bit microprocessor is utilized for various stimulation strategies, and dedicated control signal generator for electrodes runs in parallel with the microprocessor. The proposed stimulation controller generates stimulations in temporal resolution of 1 μs and spatio resolution up to 4 096 stimulation sites. Evaluation with an FPGA demonstrates the programmability of its implementation.},
	booktitle = {2016 {IEEE} {Biomedical} {Circuits} and {Systems} {Conference} ({BioCAS})},
	author = {Sugiura, T. and Khan, A. U. and Yu, J. and Takeuchi, Y. and Kameda, S. and Kamata, T. and Hayashida, Y. and Yagi, T. and Imai, M.},
	month = oct,
	year = {2016},
	keywords = {visual cortex, biomedical electrodes, Electrodes, neurophysiology, Visualization, prosthetics, biomedical electronics, vision, Wireless communication, cortical visual prosthesis, electrode, field programmable gate arrays, Field programmable gate arrays, FPGA, microprocessor, Microprocessors, programmable controllers, programmable stimulation controller, Registers, signal generator, Signal generators, spatiotemporal pattern stimulation, stimulation strategy flexibility},
	pages = {432--435},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/QRZ4LSF7/7833824.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/BSQYX3ZZ/Sugiura et al. - 2016 - A programmable controller for spatio-temporal patt.pdf:application/pdf}
}

@article{christie_approaches_2016,
	title = {Approaches to a cortical vision prosthesis: implications of electrode size and placement},
	volume = {13},
	issn = {1741-2552},
	shorttitle = {Approaches to a cortical vision prosthesis},
	url = {https://doi.org/10.1088%2F1741-2560%2F13%2F2%2F025003},
	doi = {10.1088/1741-2560/13/2/025003},
	abstract = {Objective. In order to move forward with the development of a cortical vision prosthesis, the critical issues in the field must be identified. Approach. To begin this process, we performed a brief review of several different cortical and retinal stimulation techniques that can be used to restore vision. Main results. Intracortical microelectrodes and epicortical macroelectrodes have been evaluated as the basis of a vision prosthesis. We concluded that an important knowledge gap necessitates an experimental in vivo performance evaluation of microelectrodes placed on the surface of the visual cortex. A comparison of the level of vision restored by intracortical versus epicortical microstimulation is necessary. Because foveal representation in the primary visual cortex involves more cortical columns per degree of visual field than does peripheral vision, restoration of foveal vision may require a large number of closely spaced microelectrodes. Based on previous studies of epicortical macrostimulation, it is possible that stimulation via surface microelectrodes could produce a lower spatial resolution, making them better suited for restoring peripheral vision. Significance. The validation of epicortical microstimulation in addition to the comparison of epicortical and intracortical approaches for vision restoration will fill an important knowledge gap and may have important implications for surgical strategies and device longevity. It is possible that the best approach to vision restoration will utilize both epicortical and intracortical microstimulation approaches, applying them appropriately to different visual representations in the primary visual cortex.},
	language = {en},
	number = {2},
	urldate = {2019-05-05},
	journal = {Journal of Neural Engineering},
	author = {Christie, Breanne P. and Ashmont, Kari R. and House, Paul A. and Greger, Bradley},
	month = feb,
	year = {2016},
	pages = {025003},
	file = {IOP Full Text PDF:/Users/wjmn/Zotero/storage/C5TXQ7AH/Christie et al. - 2016 - Approaches to a cortical vision prosthesis implic.pdf:application/pdf}
}

@inproceedings{mizuochi_real-time_2017,
	title = {Real-time cortical adaptation monitoring system for prosthetic rehabilitation based on functional near-infrared spectroscopy},
	doi = {10.1109/CBS.2017.8266082},
	abstract = {Prosthetics and rehabilitation for people with disabilities can benefit from new and reliable robotics technologies. This study investigates the reactions of the brain to adaptable robotics technologies for amputees by using adaptable computation of biological signals and robotic devices with large degrees of freedom. In the proposed system, the activity of the cortical region when using a prosthetic hand controlled by electro-myogram (EMG) is measured in real time by functional near-infrared spectroscopy (fNIRS). The prosthesis has a learning function that can recognize the EMG pattern. The key topic of this study is the mutual adaptation of a human and an adaptable robotic hand. This adaptation is analyzed with fNIRS to clarify the plasticity of the motor-sensory areas and frontal area of the cortex with a change in prosthesis under visual feedback. The experiment is designed as a pick-and-place task using an EMG prosthetic hand. The experimental results show that the plasticity of the brain promotes the effect of rehabilitation and helps the use of prosthetic devices.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Cyborg} and {Bionic} {Systems} ({CBS})},
	author = {Mizuochi, C. and Yabuki, Y. and Mouri, Y. and Togo, S. and Morishita, S. and Jiang, Y. and Kato, R. and Yokoi, H.},
	month = oct,
	year = {2017},
	keywords = {prosthetics, biomedical optical imaging, Prosthetics, EMG prosthetic hand, fNIRS, functional recovery, man-machine interface, mutual adaptation, real-time monitoring, sensory feedback system, brain, biological signals, cortical region, electro-myogram, electromyography, Electromyography, EMG pattern, functional near-infrared spectroscopy, medical robotics, medical signal processing, Monitoring, motor-sensory areas, patient monitoring, patient rehabilitation, prosthetic devices, prosthetic rehabilitation, real-time cortical adaptation monitoring system, Real-time systems, Robot sensing systems, robotic devices, robotic hand, robotics technologies, visual feedback},
	pages = {130--135},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/XFH6Z8NH/8266082.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/SIRGLHKU/Mizuochi et al. - 2017 - Real-time cortical adaptation monitoring system fo.pdf:application/pdf}
}

@article{lorach_neural_2013,
	series = {Special issue: {Neural} {Coding} and {Natural} {Image} {Statistics}},
	title = {Neural stimulation for visual rehabilitation: {Advances} and challenges},
	volume = {107},
	issn = {0928-4257},
	shorttitle = {Neural stimulation for visual rehabilitation},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425712000678},
	doi = {10.1016/j.jphysparis.2012.10.003},
	abstract = {Blindness affects tens of million people worldwide and its prevalence constantly increases along with population aging. In some pathologies leading to vision loss, prosthetic approaches are currently the only hope for the patient to recover some visual perception. Here, we review the latest advances in visual prosthetic strategies with their respective strength and weakness. The principle is to electrically stimulate neurons along the visual pathway. Ocular approaches target the remaining retinal cells whereas brain stimulation aims at stimulating higher visual structures directly. Even though ocular approaches are less invasive and easier to implement, brain stimulation can be applied to diseases where the connection between the retina and the brain is lost such as in glaucoma and could therefore benefit to patients with different pathologies. Today, numbers of groups are investigating these strategies and the first devices start being commercialized. However, critical bottlenecks still impair our scientific efforts towards efficient visual implants. These challenges include electrode miniaturization, material optimization, multiplexing of stimulation channels and encoding of visual information into electrical stimuli.},
	number = {5},
	urldate = {2019-05-05},
	journal = {Journal of Physiology-Paris},
	author = {Lorach, Henri and Marre, Olivier and Sahel, José-Alain and Benosman, Ryad and Picaud, Serge},
	month = nov,
	year = {2013},
	keywords = {Blindness, Implants, Prosthetics, Visual perception, Visual information coding},
	pages = {421--431},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/LYW6UF8T/Lorach et al. - 2013 - Neural stimulation for visual rehabilitation Adva.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/XPDXWVFP/S0928425712000678.html:text/html}
}

@article{hu_recognition_2014,
	title = {Recognition of {Similar} {Objects} {Using} {Simulated} {Prosthetic} {Vision}},
	volume = {38},
	copyright = {© 2013 Wiley Periodicals, Inc. and International Center for Artificial Organs and Transplantation},
	issn = {1525-1594},
	url = {http://www.onlinelibrary.wiley.com/doi/abs/10.1111/aor.12147},
	doi = {10.1111/aor.12147},
	abstract = {Due to the limitations of existing techniques, even the most advanced visual prostheses, using several hundred electrodes to transmit signals to the visual pathway, restrict sensory function and visual information. To identify the bottlenecks and guide prosthesis designing, psychophysics simulations of a visual prosthesis in normally sighted individuals are desirable. In this study, psychophysical experiments of discriminating objects with similar profiles were used to test the effects of phosphene array parameters (spatial resolution, gray scale, distortion, and dropout rate) on visual information using simulated prosthetic vision. The results showed that the increase in spatial resolution and number of gray levels and the decrease in phosphene distortion and dropout rate improved recognition performance, and the accuracy is 78.5\% under the optimum condition (resolution: 32 × 32, gray level: 8, distortion: k = 0, dropout: 0\%). In combined parameter tests, significant facial recognition accuracy was achieved for all the images with k = 0.1 distortion and 10\% dropout. Compared with other experiments, we find that different objects do not show specific sensitivity to the changes of parameters and visual information is not nearly enough even under the optimum condition. The results suggests that higher spatial resolution and more gray levels are required for visual prosthetic devices and further research on image processing strategies to improve prosthetic vision is necessary, especially when the wearers have to accomplish more than simple visual tasks.},
	language = {en},
	number = {2},
	urldate = {2019-05-05},
	journal = {Artificial Organs},
	author = {Hu, Jie and Xia, Peng and Gu, Chaochen and Qi, Jin and Li, Sheng and Peng, Yinghong},
	year = {2014},
	keywords = {Visual prosthesis, Psychophysics, Simulated prosthetic vision, Object recognition},
	pages = {159--167},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/XPGYEEIM/Hu et al. - 2014 - Recognition of Similar Objects Using Simulated Pro.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/H6P8KE4E/aor.html:text/html}
}

@inproceedings{ayton_image_2013,
	title = {Image processing for visual prostheses: {A} clinical perspective},
	shorttitle = {Image processing for visual prostheses},
	doi = {10.1109/ICIP.2013.6738317},
	abstract = {Recent advances in the field of visual prostheses or “bionic eyes” have shown that it is possible to use electrical stimulation to produce basic phosphenised vision to patients who are profoundly vision impaired or blind. In particular, retinal prostheses have been implanted in a number of clinical trials for a degenerative eye disease known as retinitis pigmentosa. To date, the visual improvements in these trials have been small and not easily quantified. The aim of this paper is to highlight the inherent complexities in the assessment of visual function in the profoundly vision impaired, and discuss the potential for improvement in outcomes using image processing technology.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Ayton, L. N. and Luu, C. D. and Bentley, S. A. and Allen, P. J. and Guymer, R. H.},
	month = sep,
	year = {2013},
	keywords = {electrical stimulation, prosthetics, eye, medical image processing, visual prosthesis, retinitis pigmentosa, diseases, retinal prostheses, blind patient, clinical assessment measures, clinical perspective, degenerative eye disease, functional vision outcomes, image processing technology, phosphenised vision, retinal recognition, vision impaired patient, visual function assessment, visual prostheses},
	pages = {1540--1544},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/NCTG8NX4/6738317.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/X9QCEUYC/Ayton et al. - 2013 - Image processing for visual prostheses A clinical.pdf:application/pdf}
}

@inproceedings{barriga-rivera_digital_2011,
	title = {Digital image processing for visual prosthesis: {Filtering} implications},
	shorttitle = {Digital image processing for visual prosthesis},
	doi = {10.1109/IEMBS.2011.6091204},
	abstract = {Investigators around the world are working on retinal neurostimulation as it may restore functional vision to the blind. The image is captured by a camera and after being processed, a series of electrical stimuli are applied to the surviving ganglion cells of the retina. This visual perception is expected to have low resolution. Therefore, there is a need of new algorithms that present the information contained in a visual scene understandable to humans. This study presents a novel multi-resolution algorithm based on wavelet analysis to extract the useful features of an image. Participants in this experiment were able to configure a filter bank to complete a set of everyday tasks. This study shows that wavelet-based algorithms may facilitate improved functional performance in prosthetic vision.},
	booktitle = {2011 {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	author = {Barriga-Rivera, A. and Suaning, G. J.},
	month = aug,
	year = {2011},
	keywords = {Electric Stimulation, Humans, visual perception, Visualization, Visual prosthesis, prosthetics, eye, medical image processing, Retina, Pattern recognition, visual prosthesis, camera, Visual Prosthesis, Algorithms, Algorithm design and analysis, blind, digital image processing, filtering, ganglion cells, Image resolution, multiresolution algorithm, retinal neurostimulation, wavelet analysis, wavelet transforms},
	pages = {4860--4863},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/XFE6N9XY/6091204.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/39FR6T36/Barriga-Rivera and Suaning - 2011 - Digital image processing for visual prosthesis Fi.pdf:application/pdf}
}

@article{thompson_facial_2003,
	title = {Facial {Recognition} {Using} {Simulated} {Prosthetic} {Pixelized} {Vision}},
	volume = {44},
	issn = {1552-5783},
	url = {https://iovs.arvojournals.org/article.aspx?articleid=2182149},
	doi = {10.1167/iovs.03-0341},
	language = {en},
	number = {11},
	urldate = {2019-05-05},
	journal = {Investigative Ophthalmology \& Visual Science},
	author = {Thompson, Robert W. and Barnett, G. David and Humayun, Mark S. and Dagnelie, Gislin},
	month = nov,
	year = {2003},
	pages = {5035--5042},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/TTNQ4ALS/Thompson et al. - 2003 - Facial Recognition Using Simulated Prosthetic Pixe.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/CU7S4JR9/article.html:text/html}
}

@article{chen_learning_2005,
	title = {Learning prosthetic vision: a virtual-reality study},
	volume = {13},
	issn = {1534-4320},
	shorttitle = {Learning prosthetic vision},
	doi = {10.1109/TNSRE.2005.851771},
	abstract = {Acceptance of prosthetic vision will be heavily dependent on the ability of recipients to form useful information from such vision. Training strategies to accelerate learning and maximize visual comprehension would need to be designed in the light of the factors affecting human learning under prosthetic vision. Some of these potential factors were examined in a visual acuity study using the Landolt C optotype under virtual-reality simulation of prosthetic vision. Fifteen normally sighted subjects were tested for 10-20 sessions. Potential learning factors were tested at p{\textless}0.05 with regression models. Learning was most evident across-sessions, though 17\% of sessions did express significant within-session trends. Learning was highly concentrated toward a critical range of optotype sizes, and subjects were less capable in identifying the closed optotype (a Landolt C with no gap, forming a closed annulus). Training for implant recipients should target these critical sizes and the closed optotype to extend the limit of visual comprehension. Although there was no evidence that image processing affected overall learning, subjects showed varying personal preferences.},
	number = {3},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Chen, S. C. and Hallum, L. E. and Lovell, N. H. and Suaning, G. J.},
	month = sep,
	year = {2005},
	keywords = {Humans, visual perception, Adult, Female, Male, neurophysiology, Biomedical engineering, prosthetics, Neural prosthesis, Prostheses and Implants, Visual Perception, Prosthetics, image processing, prosthetic vision, virtual reality, vision prosthesis, visual acuity, User-Computer Interface, Acceleration, Adolescent, Artificial Intelligence, Auditory system, Australia, Clinical trials, Cochlear implants, Computer Graphics, Data Display, human learning, Landolt C optotype, Learning, Prosthesis Fitting, regression analysis, regression models, Testing, virtual-reality, Vision Disorders, Vision Tests, Visual Acuity, visual comprehension},
	pages = {249--255},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/MLNJEAVI/1506811.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/TFXLJ89K/Chen et al. - 2005 - Learning prosthetic vision a virtual-reality stud.pdf:application/pdf}
}

@article{xia_adaptation_2015,
	title = {Adaptation to {Phosphene} {Parameters} {Based} on {Multi}-{Object} {Recognition} {Using} {Simulated} {Prosthetic} {Vision}},
	volume = {39},
	copyright = {Copyright © 2015 International Center for Artificial Organs and Transplantation and Wiley Periodicals, Inc.},
	issn = {1525-1594},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/aor.12504},
	doi = {10.1111/aor.12504},
	abstract = {Retinal prostheses for the restoration of functional vision are under development and visual prostheses targeting proximal stages of the visual pathway are also being explored. To investigate the experience with visual prostheses, psychophysical experiments using simulated prosthetic vision in normally sighted individuals are necessary. In this study, a helmet display with real-time images from a camera attached to the helmet provided the simulated vision, and experiments of recognition and discriminating multiple objects were used to evaluate visual performance under different parameters (gray scale, distortion, and dropout). The process of fitting and training with visual prostheses was simulated and estimated by adaptation to the parameters with time. The results showed that the increase in the number of gray scale and the decrease in phosphene distortion and dropout rate improved recognition performance significantly, and the recognition accuracy was 61.8 ± 7.6\% under the optimum condition (gray scale: 8, distortion: k = 0, dropout: 0\%). The adaption experiments indicated that the recognition performance was improved with time and the effect of adaptation to distortion was greater than dropout, which implies the difference of adaptation mechanism to the two parameters.},
	language = {en},
	number = {12},
	urldate = {2019-05-05},
	journal = {Artificial Organs},
	author = {Xia, Peng and Hu, Jie and Peng, Yinghong},
	year = {2015},
	keywords = {Psychophysics, Simulated prosthetic vision, Object recognition, Retinal prostheses, Neuroplasticity},
	pages = {1038--1045},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/J6GFIVB6/Xia et al. - 2015 - Adaptation to Phosphene Parameters Based on Multi-.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/2T4YYSUJ/aor.html:text/html}
}

@article{sommerhalder_simulation_2004,
	title = {Simulation of artificial vision: {II}. {Eccentric} reading of full-page text and the learning of this task},
	volume = {44},
	issn = {0042-6989},
	shorttitle = {Simulation of artificial vision},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698904000549},
	doi = {10.1016/j.visres.2004.01.017},
	abstract = {Reading of isolated words in conditions mimicking artificial vision has been found to be a difficult but feasible task. In particular at relatively high eccentricities, a significant adaptation process was required to reach optimal performances [Vision Res. 43 (2003) 269]. The present study addressed the task of full-page reading, including page navigation under control of subject's own eye movements. Conditions of artificial vision mimicking a retinal implant were simulated by projecting stimuli with reduced information content (lines of pixelised text) onto a restricted and eccentric area of the retina. Three subjects, naı̈ve to the task, were trained for almost two months (about 1 h/day) to read full-page texts. Subjects had to use their own eye movements to displace a 10°×7° viewing window, stabilised at 15° eccentricity in their lower visual field. Initial reading scores were very low for two subjects (about 13\% correctly read words), and astonishingly high for the third subject (86\% correctly read words). However, all of them significantly improved their performance with time, reaching close to perfect reading scores (ranging from 86\% to 98\% correct) at the end of the training process. Reading rates were as low as 1–5 words/min at the beginning of the experiment and increased significantly with time to 14–28 words/min. Qualitative text understanding was also estimated. We observed that reading scores of at least 85\% correct were necessary to achieve `good' text understanding. Gaze position recordings, made during the experimental sessions, demonstrated that the control of eye movements, especially the suppression of reflexive vertical saccades, constituted an important part of the overall adaptive learning process. Taken together, these results suggest that retinal implants might restore full-page text reading abilities to blind patients. About 600 stimulation contacts, distributed on an implant surface of 3×2 mm2, appear to be a minimum to allow for useful reading performance. A significant learning process will however be required to reach optimal performance with such devices, especially if they have to be placed outside the foveal area.},
	number = {14},
	urldate = {2019-05-05},
	journal = {Vision Research},
	author = {Sommerhalder, Jörg and Rappaz, Benjamin and de Haller, Raoul and Fornos, Angélica Pérez and Safran, Avinoam B. and Pelizzone, Marco},
	month = jun,
	year = {2004},
	keywords = {Learning, Eccentric reading, Reading performance, Simulation, Visual},
	pages = {1693--1706},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/PRQAHLPD/Sommerhalder et al. - 2004 - Simulation of artificial vision II. Eccentric rea.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/96CQFP86/S0042698904000549.html:text/html}
}

@article{sommerhalder_simulation_2003,
	title = {Simulation of artificial vision: {I}. {Eccentric} reading of isolated words, and perceptual learning},
	volume = {43},
	issn = {0042-6989},
	shorttitle = {Simulation of artificial vision},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698902004819},
	doi = {10.1016/S0042-6989(02)00481-9},
	abstract = {Simulations of artificial vision were performed to assess “minimum requirements for useful artificial vision”. Retinal prostheses will be implanted at a fixed (and probably eccentric) location of the retina. To mimic this condition on normal observers, we projected stimuli of various sizes and content on a defined stabilised area of the visual field. In experiment 1, we asked subjects to read isolated 4-letter words presented at various degrees of pixelisation and at various eccentricities. Reading performance dropped abruptly when the number of pixels was reduced below a certain threshold. For central reading, a viewing area containing about 300 pixels was necessary for close to perfect reading ({\textgreater}90\% correctly read words). At eccentricities beyond 10°, close to perfect reading was never achieved even if more than 300 pixels were used. A control experiment using isolated letter recognition in the same conditions suggested that lower reading performance at high eccentricity was in part due to the “crowding effect”. In experiment 2, we investigated whether the task of eccentric reading under such specific conditions could be improved by training. Two subjects, naive to this task, were trained to read pixelised 4-letter words presented at 15° eccentricity. Reading performance of both subjects increased impressively throughout the experiment. Low initial reading scores (range 6\%–23\% correct) improved impressively (range 64\%–85\% correct) after about one month of training (about 1 h/day). Control tests demonstrated that the learning process consisted essentially in an adaptation to use an eccentric area of the retina for reading. These results indicate that functional retinal implants consisting of more than 300 stimulation contacts will be needed. They might successfully restore some reading abilities in blind patients, even if they have to be placed outside the foveal area. Reaching optimal performance may, however, require a significant adaptation process.},
	number = {3},
	urldate = {2019-05-05},
	journal = {Vision Research},
	author = {Sommerhalder, Jörg and Oueghlani, Evelyne and Bagnoud, Marc and Leonards, Ute and Safran, Avinoam B and Pelizzone, Marco},
	month = feb,
	year = {2003},
	keywords = {Learning, Eccentric reading, Reading performance, Simulation, Visual},
	pages = {269--283},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/5QEZAJDW/Sommerhalder et al. - 2003 - Simulation of artificial vision I. Eccentric read.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/SEF2GRQA/S0042698902004819.html:text/html}
}

@inproceedings{oliveira_spatiotemporal_2018,
	title = {Spatiotemporal {Analysis} of {Simultaneous} {Repetitive} {Electrical} {Stimulation} with {Voltage} {Sensitive} {Dye}},
	doi = {10.1109/BIOCAS.2018.8584719},
	abstract = {In visual prostheses, resolution of restored image remain a matter of concern. The most common strategy is mainly focused on enhancing the hardware capabilities of the prosthetic devices, e.g., the density of stimulating electrodes. However, it is not yet well understood how electrical stimulations delivered from multiple electrodes interact spatially and temporally. We conducted intracortical microstimulation in mice using a pair of glass electrodes inserted in the primary visual cortex and recorded the cortical responses using voltage-sensitive dye imaging, which allowed us a fairly good spatial and temporal resolution. Response induced by simultaneous stimulation of both electrodes was compared to linear off-line summation of individual stimulation responses. We found an enhancing effect of simultaneous stimulation in a weak intensity range (≤ 10 μA) and a suppressive effect in a high intensity range, compared to the linear summation of responses. Also, cortical responses to simultaneous stimulation were found to merge in the first tens of milliseconds after simultaneous stimulation on-set and gradually regress back to the stimulation sites. The results obtained in the present study provide a physiological basis for controlling electrical activities to improve spatial resolution of restored image, such as it is done in current steering.},
	booktitle = {2018 {IEEE} {Biomedical} {Circuits} and {Systems} {Conference} ({BioCAS})},
	author = {Oliveira, L. de Levy and Suematsu, N. and Yagi, T.},
	month = oct,
	year = {2018},
	keywords = {biomedical electrodes, Electrical stimulation, Electrodes, neurophysiology, Visualization, primary visual cortex, prosthetics, bioelectric potentials, Image restoration, brain, cortical responses, current 10.0 muA, dyes, electrical stimulations, glass electrodes, image restoration, Imaging, in-vivo experiment, individual stimulation responses, intracortical microstimulation, linear off-line summation, multiple electrodes interact, neuromuscular stimulation, simultaneous repetitive electrical stimulation, simultaneous stimulation, spatial resolution, Spatial resolution, spatiotemporal phenomena, stimulating electrodes, stimulation sites, temporal resolution, Transient analysis, voltage sensitive dye, voltage-sensitive dye imaging},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/5ZBVKRJ4/8584719.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/GBEN6R3U/Oliveira et al. - 2018 - Spatiotemporal Analysis of Simultaneous Repetitive.pdf:application/pdf}
}

@inproceedings{guo_mimicking_2017,
	title = {Mimicking natural neural encoding through retinal electrostimulation},
	doi = {10.1109/NER.2017.8008346},
	abstract = {Retinal neuroprostheses or `bionic eyes', aim to restore patterned vision to those with vision loss by electrically stimulating the remaining neurons in the degenerate retina. Despite considerable progress over the last two decades, such devices generally stimulate indiscriminately both the `ON' and `OFF' visual pathways in the retina, conveying highly non-physiological signals to the brain. In this study, we used computational models to explore the ability of a new approach to retinal neurostimulation. To elicit neural responses more closely resembling those of natural vision, we demonstrate preferential excitation of the ON and OFF neurons by delivering spatiotemporally patterned stimuli with a multi-electrode array. In particular, the strategy relies on: (1) strategic placement of electrodes at key anatomical positions such as the RGC body and optic disc, and (2) using modulated stimulus waveforms, tailored to each stimulus electrode, to either initiate or suppress neural responses travelling to the cortex. By providing preferential activation of ON and OFF cells, and hence better device-to-biology integration, retinal implants would convey more physiologically-realistic spiking patterns to the visual processing centers in the brain, potentially improving the efficacy of next generation retinal implants.},
	booktitle = {2017 8th {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering} ({NER})},
	author = {Guo, T. and Barriga-Rivera, A. and Suaning, G. J. and Tsai, D. and Dokos, S. and Morley, J. W. and Lovell, N. H.},
	month = may,
	year = {2017},
	keywords = {biomedical electrodes, Electrodes, neurophysiology, Visualization, prosthetics, eye, Retina, patient treatment, brain, retinal neurostimulation, Axons, bionic eyes, Computational modeling, multielectrode array, neural encoding, optic discs, Physiology, retinal electrostimulation, retinal implants, retinal neuroprostheses, RGC body, visual processing},
	pages = {284--287},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/NNG36LKX/8008346.html:text/html;IEEE Xplore Full Text PDF:/Users/wjmn/Zotero/storage/358QYWJS/Guo et al. - 2017 - Mimicking natural neural encoding through retinal .pdf:application/pdf}
}

@article{freeman_encoding_2011,
	title = {Encoding {Visual} {Information} in {Retinal} {Ganglion} {Cells} with {Prosthetic} {Stimulation}},
	volume = {8},
	issn = {1741-2560},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3157751/},
	doi = {10.1088/1741-2560/8/3/035005},
	abstract = {Retinal prostheses aim to restore functional vision to those blinded by outer retinal diseases using electric stimulation of surviving retinal neurons. The ability to replicate the spatiotemporal pattern of ganglion cell spike trains present under normal viewing conditions is presumably an important factor for restoring high-quality vision. In order to replicate such activity with a retinal prosthesis, it is important to consider both how visual information is encoded in ganglion cell spike trains, and how retinal neurons respond to electric stimulation. The goal of the current review is to bring together these two concepts in order to guide the development of more effective stimulation strategies. We review the experiments to date that have studied how retinal neurons respond to electric stimulation and discuss these findings in the context of known retinal signaling strategies. The results from such in vitro studies reveal the advantages and disadvantages of activating the ganglion cell directly with the electric stimulus (direct activation) as compared to activation of neurons that are presynaptic to the ganglion cell (indirect activation). While direct activation allows high temporal but low spatial resolution, indirect activation yields improved spatial resolution but poor temporal resolution. Finally, we use knowledge gained from in vitro experiments to infer the patterns of elicited activity in ongoing human trials, providing insights into some of the factors limiting the quality of prosthetic vision.},
	number = {3},
	urldate = {2019-05-05},
	journal = {Journal of neural engineering},
	author = {Freeman, Daniel K and Rizzo, Joseph F and Fried, Shelley I},
	month = jun,
	year = {2011},
	pmid = {21593546},
	pmcid = {PMC3157751},
	pages = {035005},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/3YHJJ8Z5/Freeman et al. - 2011 - Encoding Visual Information in Retinal Ganglion Ce.pdf:application/pdf}
}

@techreport{golden_simulation_2017,
	type = {preprint},
	title = {Simulation of visual perception and learning with a retinal prosthesis},
	url = {http://biorxiv.org/lookup/doi/10.1101/206409},
	abstract = {The nature of artificial vision with a retinal prosthesis, and the degree to which the brain can adapt to the unnatural input from such a device, are poorly understood. Therefore, the development of current and future devices may be aided by theory and simulations that help to infer and understand what prosthesis patients see. A biologically-informed, extensible computational framework is presented here to predict visual perception and the potential effect of learning with a subretinal prosthesis. The framework relies on linear reconstruction of the stimulus from retinal responses to infer the visual information available to the patient. A simulation of the physiological optics of the eye and light responses of the major retinal neurons was used to calculate the optimal linear transformation for reconstructing natural images from retinal activity. The result was then used to reconstruct the visual stimulus during the artificial activation expected from a subretinal prosthesis in a degenerated retina, as a proxy for inferred visual perception. Several simple observations reveal the potential utility of such a simulation framework. The inferred perception obtained with prosthesis activation was substantially degraded compared to the inferred perception obtained with normal retinal responses, as expected given the limited resolution and lack of cell type specificity of the prosthesis. Consistent with clinical findings and the importance of cell type specificity, reconstruction using only ON cells, and not OFF cells, was substantially more accurate. Finally, when reconstruction was re-optimized for prosthesis stimulation, simulating idealized learning by the patient, the accuracy of inferred perception was much closer to that of healthy vision. The reconstruction approach thus provides a more complete method for exploring the potential for treating blindness with retinal prostheses than has been available previously. It may also be useful for interpreting patient data in clinical trials, and for improving prosthesis design.},
	language = {en},
	urldate = {2019-05-05},
	institution = {Neuroscience},
	author = {Golden, James R. and Erickson-Davis, Cordelia and Cottaris, Nicolas P. and Parthasarathy, Nikhil and Rieke, Fred and Brainard, David H. and Wandell, Brian A. and Chichilnisky, E. J.},
	month = oct,
	year = {2017},
	doi = {10.1101/206409},
	file = {Golden et al. - 2017 - Simulation of visual perception and learning with .pdf:/Users/wjmn/Zotero/storage/2LXQKBWZ/Golden et al. - 2017 - Simulation of visual perception and learning with .pdf:application/pdf}
}

@article{morillas_neuroengineering_2007,
	series = {Neural {Network} {Applications} in {Electrical} {Engineering}},
	title = {A neuroengineering suite of computational tools for visual prostheses},
	volume = {70},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231207001579},
	doi = {10.1016/j.neucom.2006.04.017},
	abstract = {The cooperation between neuroscience and biomedical engineering gave rise to a recent, but growing research field, known as neuroengineering. We follow its principles to have a system providing basic descriptions of the visual world to the brain's cortex. We describe a set of software and hardware tools to interface with neural tissue, in order to transmit visual information encoded into a bioinspired neural-like form. The set is composed of a retina-like encoder, and a platform to optimize electrical stimulation parameters for a multi-electrode implant. The main objective is to progress towards a functional visual neuroprosthesis for the blind.},
	number = {16},
	urldate = {2019-05-05},
	journal = {Neurocomputing},
	author = {Morillas, Christian and Romero, Samuel and Martínez, Antonio and Pelayo, Francisco and Reyneri, Leonardo and Bongard, Markus and Fernández, Eduardo},
	month = oct,
	year = {2007},
	keywords = {Artificial retinas, Electrical neurostimulation, Neural processing and coding, Spiking neurons, Visual neuroprostheses},
	pages = {2817--2827},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/WBSNZIE9/Morillas et al. - 2007 - A neuroengineering suite of computational tools fo.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/EA7BINDC/S0925231207001579.html:text/html}
}

@article{bourne_magnitude_2017,
	title = {Magnitude, temporal trends, and projections of the global prevalence of blindness and distance and near vision impairment: a systematic review and meta-analysis},
	volume = {5},
	issn = {2214-109X},
	shorttitle = {Magnitude, temporal trends, and projections of the global prevalence of blindness and distance and near vision impairment},
	url = {https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(17)30293-0/abstract},
	doi = {10.1016/S2214-109X(17)30293-0},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Global and regional prevalence estimates for blindness and vision impairment are important for the development of public health policies. We aimed to provide global estimates, trends, and projections of global blindness and vision impairment.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}We did a systematic review and meta-analysis of population-based datasets relevant to global vision impairment and blindness that were published between 1980 and 2015. We fitted hierarchical models to estimate the prevalence (by age, country, and sex), in 2015, of mild visual impairment (presenting visual acuity worse than 6/12 to 6/18 inclusive), moderate to severe visual impairment (presenting visual acuity worse than 6/18 to 3/60 inclusive), blindness (presenting visual acuity worse than 3/60), and functional presbyopia (defined as presenting near vision worse than N6 or N8 at 40 cm when best-corrected distance visual acuity was better than 6/12).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Findings{\textless}/h3{\textgreater}{\textless}p{\textgreater}Globally, of the 7·33 billion people alive in 2015, an estimated 36·0 million (80\% uncertainty interval [UI] 12·9–65·4) were blind (crude prevalence 0·48\%; 80\% UI 0·17–0·87; 56\% female), 216·6 million (80\% UI 98·5–359·1) people had moderate to severe visual impairment (2·95\%, 80\% UI 1·34–4·89; 55\% female), and 188·5 million (80\% UI 64·5–350·2) had mild visual impairment (2·57\%, 80\% UI 0·88–4·77; 54\% female). Functional presbyopia affected an estimated 1094·7 million (80\% UI 581·1–1686·5) people aged 35 years and older, with 666·7 million (80\% UI 364·9–997·6) being aged 50 years or older. The estimated number of blind people increased by 17·6\%, from 30·6 million (80\% UI 9·9–57·3) in 1990 to 36·0 million (80\% UI 12·9–65·4) in 2015. This change was attributable to three factors, namely an increase because of population growth (38·4\%), population ageing after accounting for population growth (34·6\%), and reduction in age-specific prevalence (−36·7\%). The number of people with moderate and severe visual impairment also increased, from 159·9 million (80\% UI 68·3–270·0) in 1990 to 216·6 million (80\% UI 98·5–359·1) in 2015.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interpretation{\textless}/h3{\textgreater}{\textless}p{\textgreater}There is an ongoing reduction in the age-standardised prevalence of blindness and visual impairment, yet the growth and ageing of the world's population is causing a substantial increase in number of people affected. These observations, plus a very large contribution from uncorrected presbyopia, highlight the need to scale up vision impairment alleviation efforts at all levels.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Funding{\textless}/h3{\textgreater}{\textless}p{\textgreater}Brien Holden Vision Institute.{\textless}/p{\textgreater}},
	language = {English},
	number = {9},
	urldate = {2019-05-05},
	journal = {The Lancet Global Health},
	author = {Bourne, Rupert R. A. and Flaxman, Seth R. and Braithwaite, Tasanee and Cicinelli, Maria V. and Das, Aditi and Jonas, Jost B. and Keeffe, Jill and Kempen, John H. and Leasher, Janet and Limburg, Hans and Naidoo, Kovin and Pesudovs, Konrad and Resnikoff, Serge and Silvester, Alex and Stevens, Gretchen A. and Tahhan, Nina and Wong, Tien Y. and Taylor, Hugh R. and Bourne, Rupert and Ackland, Peter and Arditi, Aries and Barkana, Yaniv and Bozkurt, Banu and Braithwaite, Tasanee and Bron, Alain and Budenz, Donald and Cai, Feng and Casson, Robert and Chakravarthy, Usha and Choi, Jaewan and Cicinelli, Maria Vittoria and Congdon, Nathan and Dana, Reza and Dandona, Rakhi and Dandona, Lalit and Das, Aditi and Dekaris, Iva and Monte, Monte Del and Deva, Jenny and Dreer, Laura and Ellwein, Leon and Frazier, Marcela and Frick, Kevin and Friedman, David and Furtado, Joao and Gao, Hua and Gazzard, Gus and George, Ronnie and Gichuhi, Stephen and Gonzalez, Victor and Hammond, Billy and Hartnett, Mary Elizabeth and He, Minguang and Hejtmancik, James and Hirai, Flavio and Huang, John and Ingram, April and Javitt, Jonathan and Jonas, Jost and Joslin, Charlotte and Keeffe, Jill and Kempen, John and Khairallah, Moncef and Khanna, Rohit and Kim, Judy and Lambrou, George and Lansingh, Van Charles and Lanzetta, Paolo and Leasher, Janet and Lim, Jennifer and Limburg, Hans and Mansouri, Kaweh and Mathew, Anu and Morse, Alan and Munoz, Beatriz and Musch, David and Naidoo, Kovin and Nangia, Vinay and Palaiou, Maria and Parodi, Maurizio Battaglia and Pena, Fernando Yaacov and Pesudovs, Konrad and Peto, Tunde and Quigley, Harry and Raju, Murugesan and Ramulu, Pradeep and Resnikoff, Serge and Robin, Alan and Rossetti, Luca and Saaddine, Jinan and Sandar, Mya and Serle, Janet and Shen, Tueng and Shetty, Rajesh and Sieving, Pamela and Silva, Juan Carlos and Silvester, Alex and Sitorus, Rita S. and Stambolian, Dwight and Stevens, Gretchen and Taylor, Hugh and Tejedor, Jaime and Tielsch, James and Tsilimbaris, Miltiadis and Meurs, Jan van and Varma, Rohit and Virgili, Gianni and Volmink, Jimmy and Wang, Ya Xing and Wang, Ning-Li and West, Sheila and Wiedemann, Peter and Wong, Tien and Wormald, Richard and Zheng, Yingfeng},
	month = sep,
	year = {2017},
	pmid = {28779882},
	pages = {e888--e897},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/JZW9CANQ/Bourne et al. - 2017 - Magnitude, temporal trends, and projections of the.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/QRYXQ9MG/fulltext.html:text/html}
}

@article{shatz_repair_1993,
	title = {Repair and {Replacement} to {Restore} {Sight}: {Report} {From} the {Panel} on {Ganglion} {Cell}/{Connectivity}},
	volume = {111},
	issn = {0003-9950},
	shorttitle = {Repair and {Replacement} to {Restore} {Sight}},
	url = {https://jamanetwork-com.ezproxy.lib.monash.edu.au/journals/jamaophthalmology/fullarticle/640158},
	doi = {10.1001/archopht.1993.01090040064031},
	abstract = {{\textless}p{\textgreater}A major goal of research on the visual system is to understand processes that promote repair and regeneration of central visual connections following disease or trauma. A number of distinct clinical conditions lead to the destruction or degeneration of retinal ganglion cells that, in turn, can result in permanent blindness. Among the major causes of ganglion cell loss are glaucoma, diabetic retinopathy, demyelinating diseases, tumors, optic neuropathy, ischemia, and traumatic injury. It is first desirable to prevent or retard the progress of neuronal injury and death in these diseases, but once connections to central visual targets are lost, the only way to restore sight is to promote the regeneration of ganglion cell connections. Recent advances have shown that this is an area of great promise for future treatment. It had long been thought that the regeneration of optic projections was not possible in the central nervous system (CNS), but findings{\textless}/p{\textgreater}},
	language = {en},
	number = {4},
	urldate = {2019-05-05},
	journal = {Archives of Ophthalmology},
	author = {Shatz, Carla J. and O'Leary, Dennis D. M.},
	month = apr,
	year = {1993},
	pages = {472--477},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/LZB4NZ49/Shatz and O'Leary - 1993 - Repair and Replacement to Restore Sight Report Fr.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/NYGHL93N/640158.html:text/html}
}

@article{khan_causes_nodate,
	title = {{CAUSES} {OF} {IRRIEVERSEBLE} {BLINDNESS}},
	abstract = {Objective: To find out the causes and risk factors of irreversible blindness in patients of different age groups and recommend strategies for its control. Design : It is a prospective study of one hundred consecutive blind cases, Place and Duration of Study: The study was conducted from January to June, 1999 at the Ophthalmology Department of Postgraduate Medical Institute, Peshawar. Subjects and Methods: A standard proforma was designed and entries were made regarding present, past and family history, thorough ocular examination of every patient was performed on slit-lamp with relevant biomicroscopic aids and posterior segment examination was conducted with direct as well as indirect ophthalmoscopes, biomicroscopy was performed as and when required. lntraocular pressure and ocular mobility were noted and relevant investigations were performed where needed.
Results: Of 100 patients 56\% were males and 44\% females. There were 3\% hypertensive patients and 35\% had diabetes mellitus. Etiologically40\% patients were blind due to glaucoma, 33\% had diabetic retinopathy, 8\% due to vitamin-A deficiency, 7\% experienced trauma, retinitis pigmentosa was the cause in 3\% patients, 3\% had retinoblastoma and 6\% were blind because of unknown or unidentified causes.
Conclusion: Irreversible blindness is more common in people above fifty years of age and mostly males are affected. Glaucoma was the commonest cause followed by diabetic retinopathy in this study.},
	language = {en},
	author = {Khan, Mohammad Daud},
	pages = {4},
	file = {Khan - CAUSES OF IRRIEVERSEBLE BLINDNESS.pdf:/Users/wjmn/Zotero/storage/WPFQRUBJ/Khan - CAUSES OF IRRIEVERSEBLE BLINDNESS.pdf:application/pdf}
}

@article{lee_glaucoma_2005,
	title = {Glaucoma and its treatment: {A} review},
	volume = {62},
	issn = {1079-2082},
	shorttitle = {Glaucoma and its treatment},
	url = {https://academic.oup.com/ajhp/article/62/7/691/5134357},
	doi = {10.1093/ajhp/62.7.691},
	abstract = {Abstract.  Purpose. A review of glaucoma and its treatment is presented.Summary. Glaucoma is a common eye disease that can cause irreversible blindness if left},
	language = {en},
	number = {7},
	urldate = {2019-05-05},
	journal = {American Journal of Health-System Pharmacy},
	author = {Lee, David A. and Higginbotham, Eve J.},
	month = apr,
	year = {2005},
	pages = {691--699},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/NEBWNVG5/Lee and Higginbotham - 2005 - Glaucoma and its treatment A review.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/K8EWV97J/5134357.html:text/html}
}

@article{zachariades_blindness_1996,
	title = {Blindness after facial trauma},
	volume = {81},
	issn = {1079-2104},
	url = {http://www.sciencedirect.com/science/article/pii/S1079210496801442},
	doi = {10.1016/S1079-2104(96)80144-2},
	abstract = {Blindness after facial fractures has been reported to occur with an incidence that ranges between 0.67\% and3\% depending on the reporting institution. To verify this finding we undertook a retrospective chart review of 5936 patients with facial fractures that occurred over a 12 1/2-year period. We found that vision in 19 eyes were lost in 18 patients. Vision loss was more frequently encountered in Le Fort III level fractures (2.2\%) followed distantly by Le Fort II level fractures (0.64\%), and zygomatic fractures (0.45\%). The cause of blindness was most frequently associated with motor vehicle accidents and gunshot injuries. Injuries of this type require immediate and prompt consultation by the ophthalmologic surgery service.},
	number = {1},
	urldate = {2019-05-05},
	journal = {Oral Surgery, Oral Medicine, Oral Pathology, Oral Radiology, and Endodontology},
	author = {Zachariades, Nicholas and Papavassiliou, Demetrius and Christopoulos, Panos},
	month = jan,
	year = {1996},
	pages = {34--37},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/9Z2J8WMM/S1079210496801442.html:text/html}
}

@article{flaxman_global_2017,
	title = {Global causes of blindness and distance vision impairment 1990–2020: a systematic review and meta-analysis},
	volume = {5},
	issn = {2214109X},
	shorttitle = {Global causes of blindness and distance vision impairment 1990–2020},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214109X17303935},
	doi = {10.1016/S2214-109X(17)30393-5},
	abstract = {Background Contemporary data for causes of vision impairment and blindness form an important basis of recommendations in public health policies. Refreshment of the Global Vision Database with recently published data sources permitted modelling of cause of vision loss data from 1990 to 2015, further disaggregation by cause, and forecasts to 2020.},
	language = {en},
	number = {12},
	urldate = {2019-05-05},
	journal = {The Lancet Global Health},
	author = {Flaxman, Seth R and Bourne, Rupert R A and Resnikoff, Serge and Ackland, Peter and Braithwaite, Tasanee and Cicinelli, Maria V and Das, Aditi and Jonas, Jost B and Keeffe, Jill and Kempen, John H and Leasher, Janet and Limburg, Hans and Naidoo, Kovin and Pesudovs, Konrad and Silvester, Alex and Stevens, Gretchen A and Tahhan, Nina and Wong, Tien Y and Taylor, Hugh R and Bourne, Rupert and Ackland, Peter and Arditi, Aries and Barkana, Yaniv and Bozkurt, Banu and Braithwaite, Tasanee and Bron, Alain and Budenz, Donald and Cai, Feng and Casson, Robert and Chakravarthy, Usha and Choi, Jaewan and Cicinelli, Maria Vittoria and Congdon, Nathan and Dana, Reza and Dandona, Rakhi and Dandona, Lalit and Das, Aditi and Dekaris, Iva and Del Monte, Monte and deva, Jenny and Dreer, Laura and Ellwein, Leon and Frazier, Marcela and Frick, Kevin and Friedman, David and Furtado, Joao and Gao, Hua and Gazzard, Gus and George, Ronnie and Gichuhi, Stephen and Gonzalez, Victor and Hammond, Billy and Hartnett, Mary Elizabeth and He, Minguang and Hejtmancik, James and Hirai, Flavio and Huang, John and Ingram, April and Javitt, Jonathan and Jonas, Jost and Joslin, Charlotte and Keeffe, Jill and Kempen, John and Khairallah, Moncef and Khanna, Rohit and Kim, Judy and Lambrou, George and Lansingh, Van Charles and Lanzetta, Paolo and Leasher, Janet and Lim, Jennifer and Limburg, Hans and Mansouri, Kaweh and Mathew, Anu and Morse, Alan and Munoz, Beatriz and Musch, David and Naidoo, Kovin and Nangia, Vinay and Palaiou, Maria and Parodi, Maurizio Battaglia and Pena, Fernando Yaacov and Pesudovs, Konrad and Peto, Tunde and Quigley, Harry and Raju, Murugesan and Ramulu, Pradeep and Rankin, Zane and Resnikoff, Serge and Reza, Dana and Robin, Alan and Rossetti, Luca and Saaddine, Jinan and Sandar, Mya and Serle, Janet and Shen, Tueng and Shetty, Rajesh and Sieving, Pamela and Silva, Juan Carlos and Silvester, Alex and Sitorus, Rita S. and Stambolian, Dwight and Stevens, Gretchen and Taylor, Hugh and Tejedor, Jaime and Tielsch, James and Tsilimbaris, Miltiadis and van Meurs, Jan and Varma, Rohit and Virgili, Gianni and Wang, Ya Xing and Wang, Ning-Li and West, Sheila and Wiedemann, Peter and Wong, Tien and Wormald, Richard and Zheng, Yingfeng},
	month = dec,
	year = {2017},
	pages = {e1221--e1234},
	file = {Flaxman et al. - 2017 - Global causes of blindness and distance vision imp.pdf:/Users/wjmn/Zotero/storage/ZN5EXUDI/Flaxman et al. - 2017 - Global causes of blindness and distance vision imp.pdf:application/pdf}
}

@article{redmon_you_2015,
	title = {You {Only} {Look} {Once}: {Unified}, {Real}-{Time} {Object} {Detection}},
	shorttitle = {You {Only} {Look} {Once}},
	url = {http://arxiv.org/abs/1506.02640},
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
	urldate = {2019-05-05},
	journal = {arXiv:1506.02640 [cs]},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02640},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1506.02640 PDF:/Users/wjmn/Zotero/storage/943LZ68Z/Redmon et al. - 2015 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf;arXiv.org Snapshot:/Users/wjmn/Zotero/storage/PWRJGA7R/1506.html:text/html}
}

@article{guo_deep_2016,
	series = {Recent {Developments} on {Deep} {Big} {Vision}},
	title = {Deep learning for visual understanding: {A} review},
	volume = {187},
	issn = {0925-2312},
	shorttitle = {Deep learning for visual understanding},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231215017634},
	doi = {10.1016/j.neucom.2015.09.116},
	abstract = {Deep learning algorithms are a subset of the machine learning algorithms, which aim at discovering multiple levels of distributed representations. Recently, numerous deep learning algorithms have been proposed to solve traditional artificial intelligence problems. This work aims to review the state-of-the-art in deep learning algorithms in computer vision by highlighting the contributions and challenges from over 210 recent research papers. It first gives an overview of various deep learning approaches and their recent developments, and then briefly describes their applications in diverse vision tasks, such as image classification, object detection, image retrieval, semantic segmentation and human pose estimation. Finally, the paper summarizes the future trends and challenges in designing and training deep neural networks.},
	urldate = {2019-05-05},
	journal = {Neurocomputing},
	author = {Guo, Yanming and Liu, Yu and Oerlemans, Ard and Lao, Songyang and Wu, Song and Lew, Michael S.},
	month = apr,
	year = {2016},
	keywords = {Computer vision, Applications, Challenges, Deep learning, Developments, Trends},
	pages = {27--48},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/MV2AZ2VX/S0925231215017634.html:text/html}
}

@article{moore_cramming_1998,
	title = {Cramming {More} {Components} {Onto} {Integrated} {Circuits}},
	volume = {86},
	issn = {0018-9219, 1558-2256},
	url = {http://ieeexplore.ieee.org/document/658762/},
	doi = {10.1109/JPROC.1998.658762},
	language = {en},
	number = {1},
	urldate = {2019-05-05},
	journal = {Proceedings of the IEEE},
	author = {Moore, G.E.},
	month = jan,
	year = {1998},
	pages = {82--85},
	file = {Moore - 1998 - Cramming More Components Onto Integrated Circuits.pdf:/Users/wjmn/Zotero/storage/L6GMQUX7/Moore - 1998 - Cramming More Components Onto Integrated Circuits.pdf:application/pdf}
}

@incollection{fernandez_cortivis_2017,
	address = {Cham},
	title = {{CORTIVIS} {Approach} for an {Intracortical} {Visual} {Prostheses}},
	isbn = {978-3-319-41876-6},
	url = {https://doi.org/10.1007/978-3-319-41876-6_15},
	abstract = {Cortical prostheses are a subgroup of visual neuroprostheses capable of evoking visual percepts in profoundly blind people through direct electrical stimulation of the occipital cortex. This approach may be the only treatment available for blindness caused by glaucoma, end-stage retinitis pigmentosa, optic atrophy, trauma to the retinas and/or optic nerves or by diseases of the central visual pathways such as brain injuries or stroke. However the selection of a specific person for a cortical implant is not straightforward and currently there are not strict standardized criteria for accepting or rejecting a candidate. We are now facing the challenge of creating such an intracortical visual neuroprosthesis designed to interface with the occipital visual cortex as a means through which a limited but useful visual sense could be restored to these blind patients.},
	language = {en},
	urldate = {2019-05-05},
	booktitle = {Artificial {Vision}: {A} {Clinical} {Guide}},
	publisher = {Springer International Publishing},
	author = {Fernández, Eduardo and Normann, Richard A.},
	editor = {Gabel, Veit Peter},
	year = {2017},
	doi = {10.1007/978-3-319-41876-6_15},
	keywords = {Phosphenes, Electrical stimulation, Artificial vision, Visual prosthesis, Plasticity, Electrode arrays, Human striate cortex, Surgical technique},
	pages = {191--201},
	file = {Springer Full Text PDF:/Users/wjmn/Zotero/storage/C2JM4BSN/Fernández and Normann - 2017 - CORTIVIS Approach for an Intracortical Visual Pros.pdf:application/pdf}
}

@incollection{troyk_intracortical_2017,
	address = {Cham},
	title = {The {Intracortical} {Visual} {Prosthesis} {Project}},
	isbn = {978-3-319-41876-6},
	url = {https://doi.org/10.1007/978-3-319-41876-6_16},
	abstract = {The possibility of engineering, testing, and deploying a cybernetic interface to the visual areas of the human brain has inspired scientists, biomedical engineers, clinicians, and science fiction writers. Implemented as a cortical visual prosthesis, visual perception might be provided to individuals with blindness. Based upon pioneering work in the late 1960’s, and the development of significant technology throughout the remainder of the twentieth century, the Intracortical Visual Prosthesis (ICVP) is being planned for clinical trial. Autonomous, wireless, 16-channel stimulator modules will be used to tile the dorsolateral surface of the human occipital lobe. Each module will contain 16 intracortical electrodes that penetrate the cortical surface and provide simulation currents to visual processing areas of the brain. Through the use of spatial and temporal integration, the expectation is that the brain will convert the artificial visual information into useful visual perceptions. While it is not expected that the ICVP will produce normal vision, prior work strongly suggests that the artificial visual perception may notably enhance the user’s ability to recognize objects and navigate, and improve overall quality of life.},
	language = {en},
	urldate = {2019-05-05},
	booktitle = {Artificial {Vision}: {A} {Clinical} {Guide}},
	publisher = {Springer International Publishing},
	author = {Troyk, Philip R.},
	editor = {Gabel, Veit Peter},
	year = {2017},
	doi = {10.1007/978-3-319-41876-6_16},
	keywords = {Visual prosthesis, Psychophysics, Cortical visual prosthesis, Intracortical electrodes, Intracortical Visual Prosthesis (ICVP), Wireless Floating Microelectrode Array (WFMA), Wireless implantable devices},
	pages = {203--214},
	file = {Springer Full Text PDF:/Users/wjmn/Zotero/storage/62S5FMGY/Troyk - 2017 - The Intracortical Visual Prosthesis Project.pdf:application/pdf}
}

@incollection{lowery_monash_2017,
	address = {Cham},
	title = {Monash {Vision} {Group}’s {Gennaris} {Cortical} {Implant} for {Vision} {Restoration}},
	isbn = {978-3-319-41876-6},
	url = {https://doi.org/10.1007/978-3-319-41876-6_17},
	abstract = {The Gennaris bionic vision system is a wireless device that has been designed to directly stimulate the primary visual cortex to restore useful vision to people with bilateral, irreversible blindness. Here, we describe the end-to-end system and the design of each component. The rationale for design decisions is provided, including the benefits of cortical stimulation, the need for wireless power and data transmission and the format of the autonomous implant tiles and penetrating micro-electrode arrays. We discuss the broad population of people for which this device may provide benefit, with reference to specific indications of blindness.Details of laboratory and preclinical tests that we have used to verify the electrical functionality of the device are described. A description of the surgical method that has been developed for implanting tiles in the visual cortex is provided, which will be used to demonstrate proof-of-concept of the system in first-in-human studies. Highlighted is the importance of post-surgical device calibration, psychophysics testing and training of recipients in using the system in both controlled and unsupervised environments. Signal processing algorithms that have been developed to enhance the user experience are described and details provided of how these have been tested to optimise their integration into the full system. Finally, we describe how the Gennaris technology can be applied to a broad spectrum of other technological and health-related challenges.},
	language = {en},
	urldate = {2019-05-05},
	booktitle = {Artificial {Vision}: {A} {Clinical} {Guide}},
	publisher = {Springer International Publishing},
	author = {Lowery, Arthur James and Rosenfeld, Jeffrey V. and Rosa, Marcello G. P. and Brunton, Emma and Rajan, Ramesh and Mann, Collette and Armstrong, Mark and Mohan, Anand and Josh, Horace and Kleeman, Lindsay and Li, Wai Ho and Pritchard, Jeanette},
	editor = {Gabel, Veit Peter},
	year = {2017},
	doi = {10.1007/978-3-319-41876-6_17},
	keywords = {Academic-industry partnership, Annulus, Bionic vision, Cortical stimulation, Hermetic, Implant tile, Neural plasticity, Neurosurgery, Penetrating electrodes, Wireless link},
	pages = {215--225}
}

@article{antolik_cortical_2019,
	title = {Cortical visual prosthesis: a detailed large-scale simulation study},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Cortical visual prosthesis},
	url = {https://www.biorxiv.org/content/10.1101/610378v1},
	doi = {10.1101/610378},
	abstract = {{\textless}p{\textgreater}Recent advances in applying optogenetics in primates initiated the development of light based prosthetic implants for sensory restoration. Thanks to being the most well explored cortical area that is readily accessible at the surface of the brain, vision restoration via direct optogenetic activation of primary visual cortex is one of the most promising early targets for a optogenetics based prosthetic program. However, two fundamental elements of the cortical optogenetic prosthesis remain unclear. First, the exact mechanisms of neural dynamics under direct cortical stimulation, especially in the context of living, active and functionally specific intra-cortical neural circuitry, is poorly understood. Second, we lack protocols for transformation of arbitrary visual stimuli into light activation patterns that would induce perception of the said stimulus by the subject. In this study we address these issues using a large-scale spiking neural network modeling strategy of high biological fidelity. We examine the relationship between specific spatial configuration of light delivered to cortex and the resulting spatio-temporal pattern of activity evoked in the simulated cortical circuitry. Using such virtual experiments, we design a protocol for translation of a specific set of stimuli to activation pattern of a matrix of light emitting elements and provide a detailed assessment of the resulting cortical activations with respect to the natural vision control condition. In this study we restrict our focus to the grating stimulus class, which are an ideal starting point for exploration due to their thoroughly characterized representation in V1 and well-defined information content. However, we also provide an outline of a straight-forward road-map for transforming this grating centric stimulation protocol towards general strategy capable of transforming arbitrary spatio-temporal visual stimulus to a spatio-temporal pattern of light, thus enabling vision restoration via optogenetic V1 activation.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-05},
	journal = {bioRxiv},
	author = {Antolik, Jan and Sabatier, Quentin and Galle, Charlie and Frègnac, Yves and Benosman, Ryad},
	month = apr,
	year = {2019},
	pages = {610378},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/56MJMJ5B/Antolik et al. - 2019 - Cortical visual prosthesis a detailed large-scale.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/LJKA295B/610378v1.html:text/html}
}

@article{fernandez_development_2018,
	title = {Development of visual {Neuroprostheses}: trends and challenges},
	volume = {4},
	issn = {2332-8886},
	shorttitle = {Development of visual {Neuroprostheses}},
	url = {https://doi.org/10.1186/s42234-018-0013-8},
	doi = {10.1186/s42234-018-0013-8},
	abstract = {Visual prostheses are implantable medical devices that are able to provide some degree of vision to individuals who are blind. This research field is a challenging subject in both ophthalmology and basic science that has progressed to a point where there are already several commercially available devices. However, at present, these devices are only able to restore a very limited vision, with relatively low spatial resolution. Furthermore, there are still many other open scientific and technical challenges that need to be solved to achieve the therapeutic benefits envisioned by these new technologies. This paper provides a brief overview of significant developments in this field and introduces some of the technical and biological challenges that still need to be overcome to optimize their therapeutic success, including long-term viability and biocompatibility of stimulating electrodes, the selection of appropriate patients for each artificial vision approach, a better understanding of brain plasticity and the development of rehabilitative strategies specifically tailored for each patient.},
	number = {1},
	urldate = {2019-05-05},
	journal = {Bioelectronic Medicine},
	author = {Fernandez, Eduardo},
	month = aug,
	year = {2018},
	pages = {12},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/J8X4JKY7/Fernandez - 2018 - Development of visual Neuroprostheses trends and .pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/XKKD86CD/s42234-018-0013-8.html:text/html}
}

@misc{noauthor_eyes-ex991_82.htm_nodate,
	title = {eyes-ex991\_82.htm},
	url = {https://www.sec.gov/Archives/edgar/data/1266806/000156459019011317/eyes-ex991_82.htm},
	urldate = {2019-05-05},
	file = {eyes-ex991_82.htm:/Users/wjmn/Zotero/storage/FIZI3HFC/eyes-ex991_82.html:text/html}
}

@article{luo_argus_2016,
	title = {The {Argus}® {II} {Retinal} {Prosthesis} {System}},
	volume = {50},
	issn = {1350-9462},
	url = {http://www.sciencedirect.com/science/article/pii/S1350946215000701},
	doi = {10.1016/j.preteyeres.2015.09.003},
	abstract = {The Argus® II Retinal Prosthesis System (Second Sight Medical Products) is the first prosthetic vision device to obtain regulatory approval in both Europe and the USA. As such it has entered the commercial market as a treatment for patients with profound vision loss from end-stage outer retinal disease, predominantly retinitis pigmentosa. To date, over 100 devices have been implanted worldwide, representing the largest group of patients currently treated with visual prostheses. The system works by direct stimulation of the relatively preserved inner retina via epiretinal microelectrodes, thereby replacing the function of the degenerated photoreceptors. Visual information from a glasses-mounted video camera is converted to a pixelated image by an external processor, before being transmitted to the microelectrode array at the macula. Elicited retinal responses are then relayed via the normal optic nerve to the cortex for interpretation. We reviewed the animal and human studies that led to the development of the Argus® II device. A sufficiently robust safety profile was demonstrated in the phase I/II clinical trial of 30 patients. Improvement of function in terms of orientation and mobility, target localisation, shape and object recognition, and reading of letters and short unrehearsed words have also been shown. There remains a wide variability in the functional outcomes amongst the patients and the factors contributing to these performance differences are still unclear. Future developments in terms of both software and hardware aimed at improving visual function have been proposed. Further experience in clinical outcomes is being acquired due to increasing implantation.},
	urldate = {2019-05-05},
	journal = {Progress in Retinal and Eye Research},
	author = {Luo, Yvonne Hsu-Lin and da Cruz, Lyndon},
	month = jan,
	year = {2016},
	keywords = {Retinal prosthesis, Visual prosthesis, Retinitis pigmentosa, Artificial retina, Retinal dystrophy},
	pages = {89--107},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/XSSMMP7Z/S1350946215000701.html:text/html}
}

@article{stingl_interim_2017,
	title = {Interim {Results} of a {Multicenter} {Trial} with the {New} {Electronic} {Subretinal} {Implant} {Alpha} {AMS} in 15 {Patients} {Blind} from {Inherited} {Retinal} {Degenerations}},
	volume = {11},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00445/full},
	doi = {10.3389/fnins.2017.00445},
	abstract = {Purpose: We assessed the safety and efficacy of a technically advanced subretinal electronic implant, RETINA IMPLANT Alpha AMS, in end stage retinal degeneration in an interim analysis of two ongoing prospective clinical trials. Methods: The subretinal visual prosthesis RETINA IMPLANT Alpha AMS (Retina Implant AG, Reutlingen, Germany) was implanted in 15 blind patients with hereditary retinal degenerations at four study sites with a follow-up period of 12 months (www.clinicaltrials.gov NCT01024803 and NCT02720640). Functional outcome measures included 1) screen-based standardized 2- or 4-alternative forced-choice tests of light perception, light localization, grating detection (basic grating acuity (BaGA) test) and Landolt C-rings; 2) grey level discrimination; 3) performance during activities of daily living (ADL-table tasks). Results: Implant-mediated light perception was observed in 13/15 patients. During the observation period implant mediated localization of visual targets was possible in 13/15 patients. Correct grating detection was achieved for spatial frequencies of 0.1 cpd (cycles per degree) in 4/15; 0.33 cpd in 3/15; 0.66 cpd in 2/15; 1.0 cpd in 2/15 and 3.3 cpd in 1/15 patients. In two patients visual acuity assessed with Landolt C- rings was 20/546 and 20/1111. Of 6 possible grey levels on average 4.6 +/-0.8 (mean +/- SD, n=10) were discerned. Improvements (power ON vs. OFF) of ADL table tasks were measured in 13/15 patients. Overall, results were stable during the observation period. Serious adverse events were reported in 4 patients: 2 movements of the implant, readjusted in a second surgery; 4 conjunctival erosion/dehiscence, successfully treated; 1 pain event around the coil, successfully treated; 1 partial reduction of silicone oil tamponade leading to distorted vision (silicon oil successfully refilled). The majority of adverse events were transient and mostly of mild to moderate intensity. Conclusions: Psychophysical and subjective data show that RETINA IMPLANT Alpha AMS is reliable, well tolerated and can restore limited visual functions in blind patients with degenerations of the outer retina. Compared with the previous implant Alpha IMS, longevity of the new implant Alpha AMS has been considerably improved. Alpha AMS has meanwhile been certified as a commercially available medical device, reimbursed in Germany by the public health system.},
	language = {English},
	urldate = {2019-05-05},
	journal = {Frontiers in Neuroscience},
	author = {Stingl, Katarina and Schippert, Ruth and Bartz-Schmidt, Karl U. and Besch, Dorothea and Cottriall, Charles L. and Edwards, Thomas L. and Gekeler, Florian and Greppmaier, Udo and Kiel, Katja and Koitschev, Assen and Kühlewein, Laura and MacLaren, Robert E. and Ramsden, James D. and Roider, Johann and Rothermel, Albrecht and Sachs, Helmut and Schröder, Greta S. and Tode, Jan and Troelenberg, Nicole and Zrenner, Eberhart},
	year = {2017},
	keywords = {artificial vision, Hereditary retinal disease, neuroprosthetics, photoreceptor degeneration, RETINA IMPLANT Alpha AMS, Retinitis Pigmentosa, Subretinal implant},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/G9FNDT8Z/Stingl et al. - 2017 - Interim Results of a Multicenter Trial with the Ne.pdf:application/pdf}
}

@article{lepore_brain_2010,
	title = {Brain {Structure} {Changes} {Visualized} in {Early}- and {Late}-{Onset} {Blind} {Subjects}},
	volume = {49},
	issn = {1053-8119},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2764825/},
	doi = {10.1016/j.neuroimage.2009.07.048},
	abstract = {We examine 3D patterns of volume differences in the brain associated with blindness, in subjects grouped according to early and late onset. Using tensor-based morphometry, we map volume reductions and gains in 16 early-onset (EB) and 16 late-onset (LB) blind adults (onset {\textless}5 and {\textgreater}14 years old, respectively) relative to 16 matched sighted controls. Each subject’s structural MRI was fluidly registered to a common template. Anatomical differences between groups were mapped based on statistical analysis of the resulting deformation fields revealing profound deficits in primary and secondary visual cortices for both blind groups. Regions outside the occipital lobe showed significant hypertrophy, suggesting widespread compensatory adaptations. EBs but not LBs showed deficits in the splenium and hypertrophy in the isthmus. Gains in the isthmus and non-occipital white matter were more widespread in the EBs. These differences may reflect regional alterations in late neurodevelopmental processes, such as myelination, that continue into adulthood.},
	number = {1},
	urldate = {2019-05-05},
	journal = {NeuroImage},
	author = {Leporé, Natasha and Voss, Patrice and Lepore, Franco and Chou, Yi-Yu and Fortin, Madeleine and Gougoux, Frédéric and Lee, Agatha D. and Brun, Caroline and Lassonde, Maryse and Madsen, Sarah K. and Toga, Arthur W. and Thompson, Paul M.},
	month = jan,
	year = {2010},
	pmid = {19643183},
	pmcid = {PMC2764825},
	pages = {134--140},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/7YEFEYNA/Leporé et al. - 2010 - Brain Structure Changes Visualized in Early- and L.pdf:application/pdf}
}

@article{gothe_changes_2002,
	title = {Changes in visual cortex excitability in blind subjects as demonstrated by transcranial magnetic stimulation},
	volume = {125},
	issn = {0006-8950},
	abstract = {Any attempt to restore visual functions in blind subjects with pregeniculate lesions provokes the question of the extent to which deafferented visual cortex is still able to generate conscious visual experience. As a simple approach to assessing activation of the visual cortex, subjects can be asked to report conscious subjective light sensations (phosphenes) elicited by focal transcranial magnetic stimulation (TMS) over the occiput. We hypothesized that such induction of phosphenes can be used as an indicator of residual function of the visual cortex and studied 35 registered blind subjects after partial or complete long-term ({\textgreater}10 years) deafferentation of the visual cortex due to pregeniculate lesions. TMS was applied over the visual cortex in 10 blind subjects with some residual vision (visual acuity {\textless}20/400; Group 1), 15 blind subjects with very poor residual vision (only perception of movement or light; Group 2), 10 blind subjects without any residual vision (Group 3) and 10 healthy controls. A stimulation mapping procedure was performed on a 1 x 1 cm skull surface grid with 130 stimulation points overlying the occipital skull. We analysed the occurrence of phosphenes at each stimulation point with regard to frequency and location of phosphenes in the visual field. Previous experiments have shown that repetitive TMS reliably elicits brief flashes of white or coloured patches of light. Therefore, stimulation was performed with short trains of seven consecutive 15 Hz stimuli applied with an intensity of 1.3 times the motor threshold. Under such conditions, phosphenes occurred in 100\% of subjects in Group 1, in 60\% of Group 2 and in 20\% of Group 3. Phosphene thresholds were normal, but the number of effective stimulation sites was significantly reduced in Groups 2 and 3. The results indicate that in blind subjects there is alteration in TMS-induced activation of the deafferented visual cortex or processes engaged in bringing the artificial cortex input to consciousness. The ability to elicit phosphenes is reduced in subjects with a high degree of visual deafferentation, especially in those without previous visual experience.},
	language = {eng},
	number = {Pt 3},
	journal = {Brain: A Journal of Neurology},
	author = {Gothe, Janna and Brandt, Stephan A. and Irlbacher, Kerstin and Röricht, Simone and Sabel, Bernhard A. and Meyer, Bernd-Ulrich},
	month = mar,
	year = {2002},
	pmid = {11872606},
	keywords = {Blindness, Electric Stimulation, Humans, Phosphenes, Visual Cortex, Adult, Female, Male, Middle Aged, Visual Fields, Transcranial Magnetic Stimulation, Aged, Adolescent, Brain Mapping, Evoked Potentials, Motor, Functional Laterality, Neuronal Plasticity, Recovery of Function, Sensory Deprivation, Space Perception},
	pages = {479--490}
}

@article{rawat_deep_2017,
	title = {Deep {Convolutional} {Neural} {Networks} for {Image} {Classification}: {A} {Comprehensive} {Review}},
	volume = {29},
	issn = {0899-7667},
	shorttitle = {Deep {Convolutional} {Neural} {Networks} for {Image} {Classification}},
	url = {https://doi.org/10.1162/neco_a_00990},
	doi = {10.1162/neco_a_00990},
	abstract = {Convolutional neural networks (CNNs) have been applied to visual tasks since the late 1980s. However, despite a few scattered applications, they were dormant until the mid-2000s when developments in computing power and the advent of large amounts of labeled data, supplemented by improved algorithms, contributed to their advancement and brought them to the forefront of a neural network renaissance that has seen rapid progression since 2012. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art deep learning systems. Along the way, we analyze (1) their early successes, (2) their role in the deep learning renaissance, (3) selected symbolic works that have contributed to their recent popularity, and (4) several improvement attempts by reviewing contributions and challenges of over 300 publications. We also introduce some of their current trends and remaining challenges.},
	number = {9},
	urldate = {2019-05-06},
	journal = {Neural Computation},
	author = {Rawat, Waseem and Wang, Zenghui},
	month = jun,
	year = {2017},
	pages = {2352--2449},
	file = {Snapshot:/Users/wjmn/Zotero/storage/S6DZDW7V/neco_a_00990.html:text/html}
}

@article{bach-y-rita_sensory_2003,
	title = {Sensory substitution and the human–machine interface},
	volume = {7},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661303002900},
	doi = {10.1016/j.tics.2003.10.013},
	abstract = {Recent advances in the instrumentation technology of sensory substitution have presented new opportunities to develop systems for compensation of sensory loss. In sensory substitution (e.g. of sight or vestibular function), information from an artificial receptor is coupled to the brain via a human–machine interface. The brain is able to use this information in place of that usually transmitted from an intact sense organ. Both auditory and tactile systems show promise for practical sensory substitution interface sites. This research provides experimental tools for examining brain plasticity and has implications for perceptual and cognition studies more generally.},
	number = {12},
	urldate = {2019-05-06},
	journal = {Trends in Cognitive Sciences},
	author = {Bach-y-Rita, Paul and W. Kercel, Stephen},
	month = dec,
	year = {2003},
	pages = {541--546},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/8SAUS3VH/S1364661303002900.html:text/html}
}

@inproceedings{sarkar_review_2012,
	title = {Review on image sonification: {A} non-visual scene representation},
	shorttitle = {Review on image sonification},
	doi = {10.1109/RAIT.2012.6194485},
	abstract = {With the advent of image and video representation of visual scenes in digital computer, subsequent necessity of vision-substitution representation of a given image is felt. The medium for non-visual representation of an image is chosen to be sound due to well developed auditory sensing ability of human beings and wide availability of cheap audio hardware. Visionary information of an image can be conveyed to blind and partially sighted persons through auditory representation of the image within some of the known limitations of human hearing system. The research regarding image sonification has mostly evolved through last three decades. The paper also discusses in brief about the reverse mapping, termed as sound visualization. This survey approaches to summarize the methodologies and issues of the implemented and unimplemented experimental systems developed for subjective sonification of image scenes and let researchers accumulate knowledge about the previous direction of researches in this domain.},
	booktitle = {2012 1st {International} {Conference} on {Recent} {Advances} in {Information} {Technology} ({RAIT})},
	author = {Sarkar, R. and Bakshi, S. and Sa, P. K.},
	month = mar,
	year = {2012},
	keywords = {Humans, Visualization, Image color analysis, Auditory system, Acoustics, Auditory image, auditory representation, blind sighted person, data visualisation, Data visualization, human hearing system, image representation, Image representation, image sonification, Non-visual image representation, nonvisual scene representation, partially sighted person, Presses, reverse mapping, Sonification, sound visualization, Stereo vision, video representation, vision-substitution representation, visionary information},
	pages = {86--90},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/Y2PI6GFU/6194485.html:text/html}
}

@article{bachyrita_tactile_2004,
	title = {Tactile {Sensory} {Substitution} {Studies}},
	volume = {1013},
	issn = {1749-6632},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1196/annals.1305.006},
	doi = {10.1196/annals.1305.006},
	abstract = {Abstract: Forty years ago a project to explore late brain plasticity was initiated that was to lead into a broad area of sensory substitution studies. The questions at that time were: Can a person who has never seen learn to see as an adult? Is the brain sufficiently plastic to develop an entirely new sensory system? The short answer to both questions is yes, first clearly demonstrated in 1969 (Bach-y-Rita et al., 1969). To reach that conclusion, it was first necessary to find a way to get visual information to the brain. That took many years and is still the most challenging aspect of the research and the development of practical sensory substitution and augmentation systems. The sensor array is not a problem: a TV camera for blind persons; an accelerometer for persons with vestibular loss; a microphone for deaf persons. These are common and fully developed devices. The problem is the brain-machine interface (BMI). In this short report, only two substitution systems are discussed, vision and vestibular substitution.},
	language = {en},
	number = {1},
	urldate = {2019-05-06},
	journal = {Annals of the New York Academy of Sciences},
	author = {Bach‐Y‐Rita, Paul},
	year = {2004},
	keywords = {blindness, brain plasticity, brain-machine interface, vision substitution},
	pages = {83--91},
	file = {Snapshot:/Users/wjmn/Zotero/storage/ZC7H4K4B/annals.1305.html:text/html}
}

@article{pal_review_1993,
	title = {A review on image segmentation techniques},
	volume = {26},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/003132039390135J},
	doi = {10.1016/0031-3203(93)90135-J},
	abstract = {Many image segmentation techniques are available in the literature. Some of these techniques use only the gray level histogram, some use spatial details while others use fuzzy set theoretic approaches. Most of these techniques are not suitable for noisy environments. Some works have been done using the Markov Random Field (MRF) model which is robust to noise, but is computationally involved. Neural network architectures which help to get the output in real time because of their parallel processing ability, have also been used for segmentation and they work fine even when the noise level is very high. The literature on color image segmentation is not that rich as it is for gray tone images. This paper critically reviews and summarizes some of these techniques. Attempts have been made to cover both fuzzy and non-fuzzy techniques including color image segmentation and neural network based approaches. Adequate attention is paid to segmentation of range images and magnetic resonance images. It also addresses the issue of quantitative evaluation of segmentation results.},
	number = {9},
	urldate = {2019-05-06},
	journal = {Pattern Recognition},
	author = {Pal, Nikhil R and Pal, Sankar K},
	month = sep,
	year = {1993},
	keywords = {Image segmentation, Clustering, Edge detection, Fuzzy sets, Markov Random Field, Relaxation, Thresholding},
	pages = {1277--1294},
	file = {ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/K4YLBQ64/003132039390135J.html:text/html}
}

@article{stratton_vision_1897,
	title = {Vision without inversion of the retinal image},
	volume = {4},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/h0075482},
	abstract = {Investigated adaptation in an inverted visual field. An eight day experiment was conducted on one S. When lenses inverting the visual field were not worn, the eyes were blind folded. The experience was carefully recorded everyday. Six days of the experiment are reported wherein from a feeling of abnormal position of the body, the S learnt to adjust to movement, localization of touch and sound. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychological Review},
	author = {Stratton, George M.},
	year = {1897},
	keywords = {Visual Field, Visual Perception, Light Adaptation, Retinal Image},
	pages = {341--360},
	file = {Snapshot:/Users/wjmn/Zotero/storage/9VGXW7BA/1926-02876-001.html:text/html}
}

@article{grill-spector_human_2004,
	title = {The {Human} {Visual} {Cortex}},
	volume = {27},
	url = {https://doi.org/10.1146/annurev.neuro.27.070203.144220},
	doi = {10.1146/annurev.neuro.27.070203.144220},
	abstract = {The discovery and analysis of cortical visual areas is a major accomplishment of visual neuroscience. In the past decade the use of noninvasive functional imaging, particularly functional magnetic resonance imaging (fMRI), has dramatically increased our detailed knowledge of the functional organization of the human visual cortex and its relation to visual perception. The fMRI method offers a major advantage over other techniques applied in neuroscience by providing a large-scale neuroanatomical perspective that stems from its ability to image the entire brain essentially at once. This bird's eye view has the potential to reveal large-scale principles within the very complex plethora of visual areas. Thus, it could arrange the entire constellation of human visual areas in a unified functional organizational framework. Here we review recent findings and methods employed to uncover the functional properties of the human visual cortex focusing on two themes: functional specialization and hierarchical processing.},
	number = {1},
	urldate = {2019-05-06},
	journal = {Annual Review of Neuroscience},
	author = {Grill-Spector, Kalanit and Malach, Rafael},
	year = {2004},
	pmid = {15217346},
	pages = {649--677},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/WMR5FLJ5/Grill-Spector and Malach - 2004 - The Human Visual Cortex.pdf:application/pdf}
}

@article{bashivan_neural_2018,
	title = {Neural {Population} {Control} via {Deep} {Image} {Synthesis}},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/461525v1},
	doi = {10.1101/461525},
	abstract = {{\textless}p{\textgreater}Particular deep artificial neural networks (ANNs) are today’s most accurate models of the primate brain’s ventral visual stream. Here we report that, using a targeted ANN-driven image synthesis method, new luminous power patterns (i.e. images) can be applied to the primate retinae to predictably push the spiking activity of targeted V4 neural sites beyond naturally occurring levels. More importantly, this method, while not yet perfect, already achieves unprecedented independent control of the activity state of entire \textit{populations} of V4 neural sites, even those with overlapping receptive fields. These results show how the knowledge embedded in today’s ANN models might be used to non-invasively set desired internal brain states at neuron-level resolution, and suggest that more accurate ANN models would produce even more accurate control.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2019-05-07},
	journal = {bioRxiv},
	author = {Bashivan, Pouya and Kar, Kohitij and DiCarlo, James J.},
	month = nov,
	year = {2018},
	pages = {461525},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/CWSIV4KE/Bashivan et al. - 2018 - Neural Population Control via Deep Image Synthesis.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/VBPXISFT/461525v1.html:text/html}
}

@article{toderici_full_2016,
	title = {Full {Resolution} {Image} {Compression} with {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1608.05148},
	abstract = {This paper presents a set of full-resolution lossy image compression methods based on neural networks. Each of the architectures we describe can provide variable compression rates during deployment without requiring retraining of the network: each network need only be trained once. All of our architectures consist of a recurrent neural network (RNN)-based encoder and decoder, a binarizer, and a neural network for entropy coding. We compare RNN types (LSTM, associative LSTM) and introduce a new hybrid of GRU and ResNet. We also study "one-shot" versus additive reconstruction architectures and introduce a new scaled-additive framework. We compare to previous work, showing improvements of 4.3\%-8.8\% AUC (area under the rate-distortion curve), depending on the perceptual metric used. As far as we know, this is the first neural network architecture that is able to outperform JPEG at image compression across most bitrates on the rate-distortion curve on the Kodak dataset images, with and without the aid of entropy coding.},
	urldate = {2019-05-08},
	journal = {arXiv:1608.05148 [cs]},
	author = {Toderici, George and Vincent, Damien and Johnston, Nick and Hwang, Sung Jin and Minnen, David and Shor, Joel and Covell, Michele},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.05148},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Updated with content for CVPR and removed supplemental material to an external link for size limitations},
	file = {arXiv\:1608.05148 PDF:/Users/wjmn/Zotero/storage/7IPXIK8A/Toderici et al. - 2016 - Full Resolution Image Compression with Recurrent N.pdf:application/pdf;arXiv.org Snapshot:/Users/wjmn/Zotero/storage/CG9BSWJI/1608.html:text/html}
}

@article{lecun_convolutional_nodate,
	title = {Convolutional {Networks} for {Images}, {Speech}, and {Time}-{Series}},
	language = {en},
	author = {LeCun, Yann and Bengio, Yoshua and Laboratories, T Bell},
	pages = {15},
	file = {LeCun et al. - Convolutional Networks for Images, Speech, and Tim.pdf:/Users/wjmn/Zotero/storage/UIZKWWTJ/LeCun et al. - Convolutional Networks for Images, Speech, and Tim.pdf:application/pdf}
}

@inproceedings{gatys_image_2016,
	address = {Las Vegas, NV, USA},
	title = {Image {Style} {Transfer} {Using} {Convolutional} {Neural} {Networks}},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780634/},
	doi = {10.1109/CVPR.2016.265},
	abstract = {Rendering the semantic content of an image in different styles is a difﬁcult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous wellknown artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation.},
	language = {en},
	urldate = {2019-05-13},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
	month = jun,
	year = {2016},
	pages = {2414--2423},
	file = {Gatys et al. - 2016 - Image Style Transfer Using Convolutional Neural Ne.pdf:/Users/wjmn/Zotero/storage/JZUWNAKA/Gatys et al. - 2016 - Image Style Transfer Using Convolutional Neural Ne.pdf:application/pdf}
}

@incollection{ciresan_deep_2012,
	title = {Deep {Neural} {Networks} {Segment} {Neuronal} {Membranes} in {Electron} {Microscopy} {Images}},
	url = {http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf},
	urldate = {2019-05-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Ciresan, Dan and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, Jürgen},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {2843--2851},
	file = {NIPS Full Text PDF:/Users/wjmn/Zotero/storage/BLKR8Q8P/Ciresan et al. - 2012 - Deep Neural Networks Segment Neuronal Membranes in.pdf:application/pdf;NIPS Snapshot:/Users/wjmn/Zotero/storage/HIADKVEU/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.html:text/html}
}

@article{ciresan_multi-column_2012,
	title = {Multi-column {Deep} {Neural} {Networks} for {Image} {Classification}},
	url = {http://arxiv.org/abs/1202.2745},
	abstract = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks.},
	urldate = {2019-05-13},
	journal = {arXiv:1202.2745 [cs]},
	author = {Cireşan, Dan and Meier, Ueli and Schmidhuber, Juergen},
	month = feb,
	year = {2012},
	note = {arXiv: 1202.2745},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 20 pages, 14 figures, 8 tables},
	file = {arXiv\:1202.2745 PDF:/Users/wjmn/Zotero/storage/BH5XGM7A/Cireşan et al. - 2012 - Multi-column Deep Neural Networks for Image Classi.pdf:application/pdf;arXiv.org Snapshot:/Users/wjmn/Zotero/storage/CNBNUNN4/1202.html:text/html}
}

@article{thurston_pare_2007,
	title = {Paré and {Prosthetics}: {The} {Early} {History} of {Artificial} {Limbs}},
	volume = {77},
	copyright = {2007 Royal Australasian College of Surgeons},
	issn = {1445-2197},
	shorttitle = {Paré and {Prosthetics}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1445-2197.2007.04330.x},
	doi = {10.1111/j.1445-2197.2007.04330.x},
	abstract = {There is evidence for the use of prostheses from the times of the ancient Egyptians. Prostheses were developed for function, cosmetic appearance and a psycho-spiritual sense of wholeness. Amputation was often feared more than death in some cultures. It was believed that it not only affected the amputee on earth, but also in the afterlife. The ablated limbs were buried and then disinterred and reburied at the time of the amputee’s death so the amputee could be whole for eternal life. One of the earliest examples comes from the 18th dynasty of ancient Egypt in the reign of Amenhotep II in the fifteenth century bc. A mummy in the Cairo Museum has clearly had the great toe of the right foot amputated and replaced with a prosthesis manufactured from leather and wood. The first true rehabilitation aids that could be recognized as prostheses were made during the civilizations of Greece and Rome. During the Dark Ages prostheses for battle and hiding deformity were heavy, crude devices made of available materials - wood, metal and leather. Such were the materials available to Ambroise Paré who invented both upper-limb and lower-limb prostheses. His ‘Le Petit Lorrain’, a mechanical hand operated by catches and springs, was worn by a French Army captain in battle. Subsequent refinements in medicine, surgery and prosthetic science greatly improved amputation surgery and the function of prostheses. What began as a modified crutch with a wooden or leather cup and progressed through many metamorphoses has now developed into a highly sophisticated prosthetic limb made of space-age materials.},
	language = {en},
	number = {12},
	urldate = {2019-05-14},
	journal = {ANZ Journal of Surgery},
	author = {Thurston, Alan J.},
	year = {2007},
	keywords = {amputation, Paré, prosthesis},
	pages = {1114--1119},
	file = {Snapshot:/Users/wjmn/Zotero/storage/65C6FBKU/j.1445-2197.2007.04330.html:text/html}
}

@article{ong_bionic_2012,
	title = {The bionic eye: a review},
	volume = {40},
	issn = {1442-6404},
	shorttitle = {The bionic eye},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1442-9071.2011.02590.x},
	doi = {10.1111/j.1442-9071.2011.02590.x},
	abstract = {Abstract Visual prostheses including artificial retinal devices are a novel and revolutionary approach to the treatment of profound visual loss. The development of the field of visual prosthesis began with cortical prosthetic devices but since then, a variety of devices which target different sites along the visual pathway have been developed with the retinal prosthesis being the most advanced. We present a review of the history of these devices, an update on the current state of play and future prospects of this field.},
	number = {1},
	urldate = {2019-05-14},
	journal = {Clinical \& Experimental Ophthalmology},
	author = {Ong, Jong Min and da Cruz, Lyndon},
	month = jan,
	year = {2012},
	keywords = {bionic, eye, prosthesis, retinal},
	pages = {6--17},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/BKB335RU/Ong and da Cruz - 2012 - The bionic eye a review.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/6Z5HCS2Q/j.1442-9071.2011.02590.html:text/html}
}

@article{rizzo_review_1997,
	title = {{REVIEW} ■ : {Prospects} for a {Visual} {Prosthesis}},
	volume = {3},
	issn = {1073-8584},
	shorttitle = {{REVIEW} ■},
	url = {https://doi.org/10.1177/107385849700300413},
	doi = {10.1177/107385849700300413},
	abstract = {Diseases of the retina and optic nerve are common causes of irreversible blindness. Given the lack of effective treatments, several laboratories are utilizing microelectronic technology to develop either a cortical or retinal prosthesis. Each strategy offers certain advantages, but both face numerous and formidable chal lenges. Consequently, a clinically useful device of either type is still conceptual. The technological means to build prostheses are available, but the ultimate obstacle is the integration of the technology with the brain. This article reviews achievements of the ongoing efforts and focuses on our project to develop a retinal prosthesis. NEUROSCIENTIST 3:251-262, 1997},
	language = {en},
	number = {4},
	urldate = {2019-05-14},
	journal = {The Neuroscientist},
	author = {Rizzo, Joseph F. and Wyatt, John},
	month = jul,
	year = {1997},
	pages = {251--262}
}

@article{weiland_visual_2008,
	title = {Visual {Prosthesis}},
	volume = {96},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2008.922589},
	abstract = {Electronic visual prostheses have demonstrated the ability to restore a rudimentary sense of vision to blind individuals. This review paper will highlight past and recent progress in this field as well as some technical challenges to further advancement. Retinal implants have now been tested in humans by four independent groups. Optic nerve and cortical implants have been also been evaluated in humans. The first implants have achieved remarkable results, including detection of motion and distinguishing objects from a set. To improve on these results, a number of research groups have performed simulations that predict up to 1000 individual pixels may be needed to restore significant functions such as face recognition and reading. In order to achieve a device that can stimulate the visual system in this many locations, issues of power consumption and electronic packaging must be resolved.},
	number = {7},
	journal = {Proceedings of the IEEE},
	author = {Weiland, J. D. and Humayun, M. S.},
	month = jul,
	year = {2008},
	keywords = {artificial organs, bioMEMS, cortical implant, Electrical stimulation, electronic packaging, electronic visual prostheses, eye, face recognition, Humans, implantable medical packaging, Implants, medical implants, microelectronic implants, motion detection, Motion detection, neural prosthesis, Object detection, optic nerve implant, Optical sensors, Power system restoration, Predictive models, prosthetics, Retina, retinal implants, retinal prosthesis, Testing, vision defects, Visual prosthesis},
	pages = {1076--1084},
	file = {IEEE Xplore Abstract Record:/Users/wjmn/Zotero/storage/SBPTI7SL/4539488.html:text/html}
}

@misc{anzctr_first_2018,
	title = {The first safety study of a {Bionic} {Vision} {Prosthesis} in adults with complete and untreatable blindness},
	url = {https://www.anzctr.org.au/Trial/Registration/TrialReview.aspx?id=373899},
	urldate = {2019-05-14},
	author = {ANZCTR},
	year = {2018},
	file = {ANZCTR - Registration:/Users/wjmn/Zotero/storage/CEQARPFM/TrialReview.html:text/html}
}

@misc{secondsight_early_nodate,
	title = {Early {Feasibility} {Study} of the {Orion} {Visual} {Cortical} {Prosthesis} {System} - {Full} {Text} {View} - {ClinicalTrials}.gov},
	url = {https://clinicaltrials.gov/ct2/show/NCT03344848},
	abstract = {Early Feasibility Study of the Orion Visual Cortical Prosthesis System - Full Text View.},
	language = {en},
	urldate = {2019-05-14},
	author = {SecondSight},
	file = {Snapshot:/Users/wjmn/Zotero/storage/JPJBTVRH/NCT03344848.html:text/html}
}

@article{secondsight_second_nodate,
	title = {Second {Sight} {Medical} {Products}, {Inc}. {Presents} {Positive} {Interim} {Results} at the {Fifth} {Annual} {BRAIN} {Initiative}® {Investigators} {Meeting}},
	language = {en},
	author = {SecondSight},
	pages = {2},
	file = {Second Sight Medical Products, Inc. Presents Posit.pdf:/Users/wjmn/Zotero/storage/C4M5FDFL/Second Sight Medical Products, Inc. Presents Posit.pdf:application/pdf}
}

@inproceedings{romero_computer-controlled_2008,
	title = {Computer-{Controlled} {Neurostimulation} for a {Visual} {Implant}},
	abstract = {Current research in therapies for restoring a functional form of sight to the blind includes interfacing electronic neurostimulators with some point of the visual pathway. This approach requires controlling a number of waveform parameters which might vary for every implanted patient and for every channel in an interface that may have hundred or thousands of electrodes. Therefore, the clinical, acute research stage of the implant should be controlled in a flexible and easy way, in order to obtain the information that will lead to a chronic implantable device. We describe such a system, based on a PC connected to an electronic neurostimulator, which delivers bi-phasic pulses to a set of implanted microelectrodes. This platform performs an automated patient-driven procedure to find stimulation thresholds. The system implements a set of physchophysical tests in order to determine the properties of the elicited visual perceptions, and applies an automatic re-mapping of the electrodes to obtain better recognizable patterns of percepts. Our platform can interface some other tools oriented to obtain, in a next research stage, a portable and chronic version of},
	booktitle = {{BIODEVICES}},
	author = {Romero, Samuel F. and Morillas, Christian A. and Pelayo, Francisco J. and Fernández, Eduardo},
	year = {2008},
	keywords = {Gene regulatory network, Higher-order function, Neurostimulation},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/ZBCIQSAW/Romero et al. - 2008 - Computer-Controlled Neurostimulation for a Visual .pdf:application/pdf}
}

@inproceedings{martinez_automatic_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Automatic {Generation} of {Bio}-inspired {Retina}-{Like} {Processing} {Hardware}},
	isbn = {978-3-540-32106-4},
	abstract = {This paper describes a tool devised for automatic design of bioinspired visual processing models using reconfigurable digital hardware. The whole system is indicated for the analysis of vision models, especially those with real–time requirements. We achieve a synthesizable FPGA/ASIC design starting from a high level description of a retina, which is made and simulated through an ad-hoc program. Our tool allows a thorough simulation of the visual model at different abstraction levels, from functional simulation of the visual specifications up to hardware-oriented simulation of the developed FPGA model. The main objective of this work is to build a portable and flexible system for a visual neuro-prosthesis and to stimulate efficiently an array of intra–cortical implanted microelectrodes. A set of parameters can be adjusted in every step of the design flow in order to maximize the design flexibility of the model. Furthermore these parameters allow the different scientists who have to deal with the development to modify a well known characteristic.},
	language = {en},
	booktitle = {Computational {Intelligence} and {Bioinspired} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Martínez, Antonio and Reyneri, Leonardo M. and Pelayo, Francisco J. and Romero, Samuel F. and Morillas, Christian A. and Pino, Begon̈a},
	editor = {Cabestany, Joan and Prieto, Alberto and Sandoval, Francisco},
	year = {2005},
	keywords = {Automatic Generation, Digital Hardware, Functional Simulation, High Level Description, Synthesis Scheme},
	pages = {527--533},
	file = {Springer Full Text PDF:/Users/wjmn/Zotero/storage/Z3X25NMT/Martínez et al. - 2005 - Automatic Generation of Bio-inspired Retina-Like P.pdf:application/pdf}
}

@article{pelayo_translating_2004,
	series = {Computational {Neuroscience}: {Trends} in {Research} 2004},
	title = {Translating image sequences into spike patterns for cortical neuro-stimulation},
	volume = {58-60},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S092523120400147X},
	doi = {10.1016/j.neucom.2004.01.142},
	abstract = {This paper describes a bioinspired preprocessing and coding system devised for producing optimal multi-electrode stimulation at the cortical level, starting from image sequences and working at video rates. A hybrid platform with software and reconfigurable hardware delivers a continuously varying stream of pulses or spike patterns. The main objective of this work is to build a portable system for a visual neuro-prosthesis to stimulate efficiently an array of intra-cortical implanted microelectrodes. A set of parameters can be adjusted in the processing and spike-coding modules to trade-off their technology constraints with the biological plausibility of their functional features.},
	urldate = {2019-05-14},
	journal = {Neurocomputing},
	author = {Pelayo, Francisco J. and Romero, Samuel and Morillas, Christian A. and Martı́nez, Antonio and Ros, Eduardo and Fernández, Eduardo},
	month = jun,
	year = {2004},
	keywords = {Artificial retinas, Neural processing and coding, Reconfigurable computing, Spiking neurons, Visual neuroprostheses},
	pages = {885--892},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/U57KYD2E/Pelayo et al. - 2004 - Translating image sequences into spike patterns fo.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/INJ7IPER/S092523120400147X.html:text/html}
}

@article{morillas_design_2007,
	series = {Papers presented at the {Sixth} {International} {Workshop} on {Information} {Processing} in {Cells} and {Tissues}, {York}, {UK}, 2005},
	title = {A design framework to model retinas},
	volume = {87},
	issn = {0303-2647},
	url = {http://www.sciencedirect.com/science/article/pii/S0303264706001614},
	doi = {10.1016/j.biosystems.2006.09.009},
	abstract = {Neuro-engineering is providing biomedical engineers with technology to interface the nervous system, which is useful to create prosthetic devices to palliate sensorial or motor disabilities. Motivated by the success of cochlear implants for deaf patients, we are now facing the challenge of creating a prosthetic visual system for the blind. An artificial retina whose response to stimuli can be matched to biological ones is required. To make easier the task of modeling, tuning and testing these retinal models, we have created a software tool that allows flexible and parametric definition and testing of retina-like models. The program can be fed with a variety of video or image sources, and the results can be easily compared to biological recordings of retinal ganglionar activity in response to the same stimuli. This tool can be useful, not only for this prosthetic purpose, but for any other research involving bio-inspired image processing with a neuromorphic output.},
	number = {2},
	urldate = {2019-05-14},
	journal = {Biosystems},
	author = {Morillas, Christian A. and Romero, Samuel F. and Martínez, Antonio and Pelayo, Francisco J. and Ros, Eduardo and Fernández, Eduardo},
	month = feb,
	year = {2007},
	keywords = {Bio-inspired image processing, Neuro-engineering, Neuromorphic encoding, Retina modeling, Visual prostheses},
	pages = {156--163},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/5X7B2XAL/Morillas et al. - 2007 - A design framework to model retinas.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/J87Q69GA/S0303264706001614.html:text/html}
}

@article{peterson_cochlear_2010,
	title = {Cochlear implants and spoken language processing abilities: {Review} and assessment of the literature},
	volume = {28},
	issn = {0922-6028},
	shorttitle = {Cochlear implants and spoken language processing abilities},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2947146/},
	doi = {10.3233/RNN-2010-0535},
	abstract = {Cochlear implants (CIs) process sounds electronically and then transmit electric stimulation to the cochlea of individuals with sensorineural deafness, restoring some sensation of auditory perception. Many congenitally deaf CI recipients achieve a high degree of accuracy in speech perception and develop near-normal language skills. Post-lingually deafened implant recipients often regain the ability to understand and use spoken language with or without the aid of visual input (i.e. lip reading). However, there is wide variation in individual outcomes following cochlear implantation, and some CI recipients never develop useable speech and oral language skills. The causes of this enormous variation in outcomes are only partly understood at the present time. The variables most strongly associated with language outcomes are age at implantation and mode of communication in rehabilitation. Thus, some of the more important factors determining success of cochlear implantation are broadly related to neural plasticity that appears to be transiently present in deaf individuals. In this article we review the expected outcomes of cochlear implantation, potential predictors of those outcomes, the basic science regarding critical and sensitive periods, and several new research directions in the field of cochlear implantation.},
	number = {2},
	urldate = {2019-05-14},
	journal = {Restorative neurology and neuroscience},
	author = {Peterson, Nathaniel R. and Pisoni, David B. and Miyamoto, Richard T.},
	month = jan,
	year = {2010},
	pmid = {20404411},
	pmcid = {PMC2947146},
	pages = {237--250},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/KH8PWG8Y/Peterson et al. - 2010 - Cochlear implants and spoken language processing a.pdf:application/pdf}
}

@article{teoh_cochlear_2004,
	title = {Cochlear {Implantation} in {Adults} {With} {Prelingual} {Deafness}. {Part} {II}. {Underlying} {Constraints} {That} {Affect} {Audiological} {Outcomes}},
	volume = {114},
	issn = {0023-852X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3429134/},
	doi = {10.1097/00005537-200410000-00007},
	abstract = {Objectives/Hypothesis
To discuss the underlying physiological and anatomical constraints on audiological performance of late-implanted prelingually deafened adult cochlear implant patients.

Study Design
Retrospective review.

Methods
Published literature on the topic of auditory pathway responses to prolonged congenital deafness was reviewed. In particular, the authors sought to identify the anatomical and physiological changes that take place in both the peripheral and central auditory pathways in response to prolonged deafness, as well as how they are altered by chronic electrical stimulation.

Results
The currently available evidence suggests that the colonization of the auditory cortex by other sensory modalities is the main limiting factor in postimplantation performance, not the pathological degenerative changes of the auditory nerve, cochlear nucleus, or auditory midbrain.

Conclusion
The reviewed evidence, although circumstantial, suggests that emphasizing aurally based educational programs before (with hearing aids) and after cochlear implantation could reduce the cortical colonization phenomenon and potentially improve postimplantation audiological performance of patients with long-term prelingual deafness.},
	number = {10},
	urldate = {2019-05-14},
	journal = {The Laryngoscope},
	author = {Teoh, Su Wooi and Pisoni, David B. and Miyamoto, Richard T.},
	month = oct,
	year = {2004},
	pmid = {15454759},
	pmcid = {PMC3429134},
	pages = {1714--1719},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/8PAUCYLY/Teoh et al. - 2004 - Cochlear Implantation in Adults With Prelingual De.pdf:application/pdf}
}

@article{egmont-petersen_image_2002,
	title = {Image processing with neural networks—a review},
	volume = {35},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789},
	doi = {10.1016/S0031-3203(01)00178-9},
	abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments.},
	number = {10},
	urldate = {2019-05-14},
	journal = {Pattern Recognition},
	author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
	month = oct,
	year = {2002},
	keywords = {Digital image processing, Feature extraction, Image compression, Image understanding, Invariant pattern recognition, Neural networks, Object recognition, Optimization, Preprocessing, Segmentation},
	pages = {2279--2301},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/JBU3NCUP/Egmont-Petersen et al. - 2002 - Image processing with neural networks—a review.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/UWZL4UZZ/S0031320301001789.html:text/html}
}

@incollection{deering_limits_1998,
	title = {The {Limits} of {Human} {Vision}},
	volume = {2},
	abstract = {A model of the perception limits of the human visual system is presented, resulting in an estimate of approximately 15 million variable resolution pixels per eye. Assuming a 60 Hz stereo display with a depth complexity of 6, we make the prediction that a rendering rate of approximately ten billion triangles per second is sufficient to saturate the human visual system. 17 different physically realizable computer display configurations are analyzed to understand their visual perceptions limits. The displays include direct view CRTs, stereo projection displays, multi-walled immersive stereo projection displays, head-mounted displays, as well as standard TV and movie displays for comparison. A theoretical maximum triangle per second rate is also computed for each of these display configurations.},
	language = {en},
	booktitle = {2nd {International} {Immersive} {Projection} {Technology} {Workshop}},
	author = {Deering, Michael F},
	year = {1998},
	pages = {6},
	file = {Deering and Microsystems - The Limits of Human Vision.pdf:/Users/wjmn/Zotero/storage/QXEP59BT/Deering and Microsystems - The Limits of Human Vision.pdf:application/pdf}
}

@article{tehovnik_phosphene_2007,
	title = {Phosphene {Induction} by {Microstimulation} of {Macaque} {V}1},
	volume = {53},
	issn = {0165-0173},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1850969/},
	doi = {10.1016/j.brainresrev.2006.11.001},
	abstract = {Non-human primates are being used to develop a cortical visual prosthesis for the blind. We use the properties of electrical microstimulation of striate cortex (area V1) of macaque monkeys to make inferences about phosphene induction. Our analysis is based on well-established properties of V1: retino-cortical magnification factor, receptive-field size, and the characteristics of hypercolumns. We argue that phosphene size is dependent on the amount of current delivered to V1 and on the retino-cortical magnification factor. We suggest that to improve the correspondence between the site of stimulation within V1 and the visual field location of an elicited phosphene both eyes must be put under experimental control given that phosphene location is retinocentric and given that the vergence angle between the eyes might affect the position of a phosphene in depth. Knowing how electrical microstimulation interacts with cortical tissue to evoke percepts in behaving macaque monkeys is fundamental to the establishment of an effective cortical visual prosthesis for the blind.},
	number = {2},
	urldate = {2019-05-14},
	journal = {Brain research reviews},
	author = {Tehovnik, Edward J. and Slocum, Warren M.},
	month = feb,
	year = {2007},
	pmid = {17173976},
	pmcid = {PMC1850969},
	pages = {337--343},
	file = {PubMed Central Full Text PDF:/Users/wjmn/Zotero/storage/GDXYI9Z6/Tehovnik and Slocum - 2007 - Phosphene Induction by Microstimulation of Macaque.pdf:application/pdf}
}

@article{tehovnik_microstimulation_2007,
	title = {Microstimulation of {V}1 delays visually guided saccades: a parametric evaluation of delay fields},
	volume = {176},
	issn = {0014-4819},
	shorttitle = {Microstimulation of {V}1 delays visually guided saccades},
	doi = {10.1007/s00221-006-0625-1},
	abstract = {Electrical microstimulation of macaque striate cortex (area V1) delays the execution of saccadic eye movements made to a visual target placed in the receptive field of the stimulated neurons. The region of visual space within which saccades are delayed is called a delay field. We examined the effects of changing the parameters of stimulation and target size on the size of a delay field. Rhesus monkeys were required to generate a saccadic eye movement to a punctate and white visual target presented within or outside the receptive field of the neurons under study. On 50\% of trials, a train of stimulation consisting of 0.2-ms anode-first pulses was delivered to the neurons before the onset of the visual target. Stimulations were performed in the operculum at 0.9-2.0 mm below the cortical surface. It was found that increases in current (50-100 microA), pulse frequency (100-300 Hz), or train duration (75-300 ms) increased the size of a delay field and increases in target size (0.1 degrees -0.2 degrees of visual angle) decreased the size of a delay field. Delay fields varied in size between 0.1 and 0.6 degrees of visual angle. These results are related to the properties of phosphenes induced by electrical stimulation of V1 in humans and compared to the interference effects observed following transcranial magnetic stimulation of human V1.},
	language = {eng},
	number = {3},
	journal = {Experimental Brain Research},
	author = {Tehovnik, Edward J. and Slocum, Warren M.},
	month = jan,
	year = {2007},
	pmid = {16896978},
	keywords = {Analysis of Variance, Animals, Behavior, Animal, Dose-Response Relationship, Radiation, Electric Stimulation, Electrodes, Implanted, Evaluation Studies as Topic, Macaca mulatta, Reaction Time, Saccades, Visual Cortex, Visual Fields},
	pages = {413--424}
}

@article{tehovnik_microstimulation_2009,
	title = {Microstimulation of visual cortex to restore vision},
	volume = {175},
	issn = {1875-7855},
	doi = {10.1016/S0079-6123(09)17524-6},
	abstract = {This review argues that one reason why a functional visuo-cortical prosthetic device has not been developed to restore even minimal vision to blind individuals is because there is no animal model to guide the design and development of such a device. Over the past 8 years we have been conducting electrical microstimulation experiments on alert behaving monkeys with the aim of better understanding how electrical stimulation of the striate cortex (area V1) affects oculo- and skeleto-motor behaviors. Based on this work and upon review of the literature, we arrive at several conclusions: (1) As with the development of the cochlear implant, the development of a visuo-cortical prosthesis can be accelerated by using animals to test the perceptual effects of microstimulating V1 in intact and blind monkeys. (2) Although a saccade-based paradigm is very convenient for studying the effectiveness of delivering stimulation to V1 to elicit saccadic eye movements, it is less ideal for probing the volitional state of monkeys, as they perceive electrically induced phosphenes. (3) Electrical stimulation of V1 can delay visually guided saccades generated to a punctate target positioned in the receptive field of the stimulated neurons. We call the region of visual space affected by the stimulation a delay field. The study of delay fields has proven to be an efficient way to study the size and shape of phosphenes generated by stimulation of macaque V1. (4) An alternative approach to ascertain what monkeys see during electrical stimulation of V1 is to have them signal the detection of current with a lever press. Monkeys can readily detect currents of 1-2 microA delivered to V1. In order to evoke featured phosphenes currents of under 5 microA will be necessary. (5) Partially lesioning the retinae of monkeys is superior to completely lesioning the retinae when determining how blindness affects phosphene induction. We finish by proposing a future experimental paradigm designed to determine what monkeys see when stimulation is delivered to V1, by assessing how electrical fields generated through multiple electrodes interact for the production of phosphenes, and by depicting a V1 circuit that could mediate electrically induced phosphenes.},
	language = {eng},
	journal = {Progress in Brain Research},
	author = {Tehovnik, Edward J. and Slocum, Warren M. and Smirnakis, Stelios M. and Tolias, Andreas S.},
	year = {2009},
	pmid = {19660667},
	keywords = {Animals, Blindness, Cortical, Disease Models, Animal, Electric Stimulation, Electric Stimulation Therapy, Electrodes, Implanted, Humans, Macaca, Phosphenes, Prostheses and Implants, Saccades, Visual Cortex, Visual Perception},
	pages = {347--375}
}

@article{tehovnik_phosphene_2005,
	title = {Phosphene induction and the generation of saccadic eye movements by striate cortex},
	volume = {93},
	issn = {0022-3077},
	doi = {10.1152/jn.00736.2004},
	abstract = {The purpose of this review is to critically examine phosphene induction and saccadic eye movement generation by electrical microstimulation of striate cortex (area V1) in humans and monkeys. The following issues are addressed: 1) Properties of electrical stimulation as they pertain to the activation of V1 elements; 2) the induction of phosphenes in sighted and blind human subjects elicited by electrical stimulation using various stimulation parameters and electrode types; 3) the induction of phosphenes with electrical microstimulation of V1 in monkeys; 4) the generation of saccadic eye movements with electrical microstimulation of V1 in monkeys; and 5) the tasks involved for the development of a cortical visual prosthesis for the blind. In this review it is concluded that electrical microstimulation of area V1 in trained monkeys can be used to accelerate the development of an effective prosthetic device for the blind.},
	language = {eng},
	number = {1},
	journal = {Journal of Neurophysiology},
	author = {Tehovnik, E. J. and Slocum, W. M. and Carvey, C. E. and Schiller, P. H.},
	month = jan,
	year = {2005},
	pmid = {15371496},
	keywords = {Animals, Electric Stimulation, Electrodes, Neural Networks (Computer), Neurons, Phosphenes, Psychophysics, Reaction Time, Saccades, Sensory Thresholds, Visual Cortex},
	pages = {1--19}
}

@article{vladusich_brightness_2007,
	title = {Brightness and {Darkness} as {Perceptual} {Dimensions}},
	volume = {3},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030179},
	doi = {10.1371/journal.pcbi.0030179},
	abstract = {A common-sense assumption concerning visual perception states that brightness and darkness cannot coexist at a given spatial location. One corollary of this assumption is that achromatic colors, or perceived grey shades, are contained in a one-dimensional (1-D) space varying from bright to dark. The results of many previous psychophysical studies suggest, by contrast, that achromatic colors are represented as points in a color space composed of two or more perceptual dimensions. The nature of these perceptual dimensions, however, presently remains unclear. Here we provide direct evidence that brightness and darkness form the dimensions of a two-dimensional (2-D) achromatic color space. This color space may play a role in the representation of object surfaces viewed against natural backgrounds, which simultaneously induce both brightness and darkness signals. Our 2-D model generalizes to the chromatic dimensions of color perception, indicating that redness and greenness (blueness and yellowness) also form perceptual dimensions. Collectively, these findings suggest that human color space is composed of six dimensions, rather than the conventional three.},
	language = {en},
	number = {10},
	urldate = {2019-05-14},
	journal = {PLOS Computational Biology},
	author = {Vladusich, Tony and Lucassen, Marcel P. and Cornelissen, Frans W.},
	month = oct,
	year = {2007},
	keywords = {Color vision, Experimental design, Luminance, Perception, Psychophysics, Sensory perception, Signal processing, Skewness},
	pages = {e179},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/72FL6LS7/Vladusich et al. - 2007 - Brightness and Darkness as Perceptual Dimensions.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/XDSJBB4C/article.html:text/html}
}

@article{solomon_machinery_2007,
	title = {The machinery of colour vision},
	volume = {8},
	copyright = {2007 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn2094},
	doi = {10.1038/nrn2094},
	abstract = {Some fundamental principles of colour vision, deduced from perceptual studies, have been understood for a long time. Physiological studies have confirmed the existence of three classes of cone photoreceptors, and of colour-opponent neurons that compare the signals from cones, but modern work has drawn attention to unexpected complexities of early organization: the proportions of cones of different types vary widely among individuals, without great effect on colour vision; the arrangement of different types of cones in the mosaic seems to be random, making it hard to optimize the connections to colour-opponent mechanisms; and new forms of colour-opponent mechanisms have recently been discovered. At a higher level, in the primary visual cortex, recent studies have revealed a simpler organization than had earlier been supposed, and in some respects have made it easier to reconcile physiological and perceptual findings.},
	language = {en},
	number = {4},
	urldate = {2019-05-14},
	journal = {Nature Reviews Neuroscience},
	author = {Solomon, Samuel G. and Lennie, Peter},
	month = apr,
	year = {2007},
	pages = {276--286},
	file = {Snapshot:/Users/wjmn/Zotero/storage/WQTMER93/nrn2094.html:text/html}
}

@article{engel_retinotopic_1997,
	title = {Retinotopic organization in human visual cortex and the spatial precision of functional {MRI}.},
	volume = {7},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/7/2/181/318870},
	doi = {10.1093/cercor/7.2.181},
	abstract = {Abstract.  A method of using functional magnetic resonance imaging (fMRI) to measure retinotopic organization within human cortex is described. The method is ba},
	language = {en},
	number = {2},
	urldate = {2019-05-15},
	journal = {Cerebral Cortex},
	author = {Engel, S. A. and Glover, G. H. and Wandell, B. A.},
	month = mar,
	year = {1997},
	pages = {181--192},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/XQXBAFX3/Engel et al. - 1997 - Retinotopic organization in human visual cortex an.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/KRHN67LF/318870.html:text/html}
}

@article{fox_retinotopic_1987,
	title = {Retinotopic organization of human visual cortex mapped with positron- emission tomography},
	volume = {7},
	copyright = {© 1987 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/7/3/913},
	doi = {10.1523/JNEUROSCI.07-03-00913.1987},
	abstract = {The retinotopic organization of primary visual cortex was mapped in normal human volunteers. Positron-emission tomographic measurements of regional cerebral blood flow were employed to detect focal functional brain activation. Oxygen-15-labeled water, delivered by intravenous bolus, was used as the blood flow tracer to allow multiple stimulated- state (n = 5) and control-state (n = 3) measurements to be acquired for each of 7 subjects. Responses were identified by applying a maximum- detection algorithm to subtraction-format images of the stimulus- induced change in cerebral blood flow. Response locales were described using a standardized system of stereotactic coordinates. Changes in stimulus location (macular, perimacular, peripheral, upper-field, lower- field) caused systematic, highly significant changes in response locale within visual cortex. Discrete extrastriate visual responses were also observed.},
	language = {en},
	number = {3},
	urldate = {2019-05-15},
	journal = {Journal of Neuroscience},
	author = {Fox, P. T. and Miezin, F. M. and Allman, J. M. and Essen, DC Van and Raichle, M. E.},
	month = mar,
	year = {1987},
	pmid = {3494107},
	pages = {913--922},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/W8N34Z88/Fox et al. - 1987 - Retinotopic organization of human visual cortex ma.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/FSELIH92/913.html:text/html}
}

@article{virsu_cortical_1987,
	title = {Cortical magnification and peripheral vision},
	volume = {4},
	copyright = {\&\#169; 1987 Optical Society of America},
	issn = {1520-8532},
	url = {https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-4-8-1568},
	doi = {10.1364/JOSAA.4.001568},
	abstract = {In a generalized form, the cortical magnification theory of peripheral vision predicts that the thresholds of any visual stimuli are similar across the whole visual field if the cortical stimulus representations calculated by means of the cortical magnification factor are similar independently of eccentricity. Failures of the theory in spatial vision were analyzed, and the theory was tested with five visual acuity tasks and two hyperacuity tasks. Almost all increases in thresholds with eccentricity were explained by the theory in five of these tasks, which included the two-dot vernier hyperacuity test, the measurement of visual acuities with gratings, the Snellen E test, and two acuity tests that required either separation between dots or discrimination between two mirror-symmetric forms. The two-dot vernier thresholds could be explained as a special case of orientation discrimination, and orientation discrimination at different eccentricities was in agreement with the cortical magnification theory. The increase of thresholds in peripheral vision was larger than predicted by the theory in the Landolt visual acuity and bisection hyperacuity tests, possibly because of retinal undersampling.},
	language = {EN},
	number = {8},
	urldate = {2019-05-15},
	journal = {JOSA A},
	author = {Virsu, Veijo and Näsänen, Risto and Osmoviita, Kari},
	month = aug,
	year = {1987},
	keywords = {Field size, Peripheral vision, Refractive anomalies, Retinal ganglion cells, Visual acuity, Visual system},
	pages = {1568--1578},
	file = {Snapshot:/Users/wjmn/Zotero/storage/QDEZMKM5/abstract.html:text/html}
}

@article{ben-yishai_theory_1995,
	title = {Theory of orientation tuning in visual cortex.},
	volume = {92},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/92/9/3844},
	doi = {10.1073/pnas.92.9.3844},
	abstract = {The role of intrinsic cortical connections in processing sensory input and in generating behavioral output is poorly understood. We have examined this issue in the context of the tuning of neuronal responses in cortex to the orientation of a visual stimulus. We analytically study a simple network model that incorporates both orientation-selective input from the lateral geniculate nucleus and orientation-specific cortical interactions. Depending on the model parameters, the network exhibits orientation selectivity that originates from within the cortex, by a symmetry-breaking mechanism. In this case, the width of the orientation tuning can be sharp even if the lateral geniculate nucleus inputs are only weakly anisotropic. By using our model, several experimental consequences of this cortical mechanism of orientation tuning are derived. The tuning width is relatively independent of the contrast and angular anisotropy of the visual stimulus. The transient population response to changing of the stimulus orientation exhibits a slow "virtual rotation." Neuronal cross-correlations exhibit long time tails, the sign of which depends on the preferred orientations of the cells and the stimulus orientation.},
	language = {en},
	number = {9},
	urldate = {2019-05-15},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ben-Yishai, R. and Bar-Or, R. L. and Sompolinsky, H.},
	month = apr,
	year = {1995},
	pmid = {7731993},
	pages = {3844--3848},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/BR97RA8Y/Ben-Yishai et al. - 1995 - Theory of orientation tuning in visual cortex..pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/JTXN2YFE/3844.html:text/html}
}

@article{wassle_functional_1991,
	title = {Functional architecture of the mammalian retina},
	volume = {71},
	issn = {0031-9333},
	url = {https://www.physiology.org/doi/abs/10.1152/physrev.1991.71.2.447},
	doi = {10.1152/physrev.1991.71.2.447},
	number = {2},
	urldate = {2019-05-15},
	journal = {Physiological Reviews},
	author = {Wassle, H. and Boycott, B. B.},
	month = apr,
	year = {1991},
	pages = {447--480},
	file = {Snapshot:/Users/wjmn/Zotero/storage/I9CGVW2H/physrev.1991.71.2.html:text/html}
}

@article{grossman_brain_2000,
	title = {Brain {Areas} {Involved} in {Perception} of {Biological} {Motion}},
	volume = {12},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/089892900562417},
	doi = {10.1162/089892900562417},
	abstract = {These experiments use functional magnetic resonance imaging (fMRI) to reveal neural activity uniquely associated with perception of biological motion. We isolated brain areas activated during the viewing of point-light figures, then compared those areas to regions known to be involved in coherent-motion perception and kinetic-boundary perception. Coherent motion activated a region matching previous reports of human MT/MST complex located on the temporo-parieto-occipital junction. Kinetic boundaries activated a region posterior and adjacent to human MT previously identified as the kinetic-occipital (KO) region or the lateral-occipital (LO) complex. The pattern of activation during viewing of biological motion was located within a small region on the ventral bank of the occipital extent of the superior-temporal sulcus (STS). This region is located lateral and anterior to human MT/MST, and anterior to KO. Among our observers, we localized this region more frequently in the right hemisphere than in the left. This was true regardless of whether the point-light figures were presented in the right or left hemifield. A small region in the medial cerebellum was also active when observers viewed biological-motion sequences. Consistent with earlier neuroimaging and single-unit studies, this pattern of results points to the existence of neural mechanisms specialized for analysis of the kinematics defining biological motion.},
	number = {5},
	urldate = {2019-05-15},
	journal = {Journal of Cognitive Neuroscience},
	author = {Grossman, E. and Donnelly, M. and Price, R. and Pickens, D. and Morgan, V. and Neighbor, G. and Blake, R.},
	month = sep,
	year = {2000},
	pages = {711--720},
	file = {Snapshot:/Users/wjmn/Zotero/storage/XS9Z7YSR/089892900562417.html:text/html;Submitted Version:/Users/wjmn/Zotero/storage/F3E9Y8QU/Grossman et al. - 2000 - Brain Areas Involved in Perception of Biological M.pdf:application/pdf}
}

@article{grossman_brain_2002,
	title = {Brain {Areas} {Active} during {Visual} {Perception} of {Biological} {Motion}},
	volume = {35},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627302008978},
	doi = {10.1016/S0896-6273(02)00897-8},
	abstract = {Theories of vision posit that form and motion are represented by neural mechanisms segregated into functionally and anatomically distinct pathways. Using point-light animations of biological motion, we examine the extent to which form and motion pathways are mutually involved in perceiving figures depicted by the spatio-temporal integration of local motion components. Previous work discloses that viewing biological motion selectively activates a region on the posterior superior temporal sulcus (STSp). Here we report that the occipital and fusiform face areas (OFA and FFA) also contain neural signals capable of differentiating biological from nonbiological motion. EBA and LOC, although involved in perception of human form, do not contain neural signals selective for biological motion. Our results suggest that a network of distributed neural areas in the form and motion pathways underlie the perception of biological motion.},
	number = {6},
	urldate = {2019-05-15},
	journal = {Neuron},
	author = {Grossman, Emily D and Blake, Randolph},
	month = sep,
	year = {2002},
	pages = {1167--1175},
	file = {ScienceDirect Full Text PDF:/Users/wjmn/Zotero/storage/4KTGRKEE/Grossman and Blake - 2002 - Brain Areas Active during Visual Perception of Bio.pdf:application/pdf;ScienceDirect Snapshot:/Users/wjmn/Zotero/storage/CR3RH9LF/S0896627302008978.html:text/html}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2019-05-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105},
	file = {NIPS Snapshot:/Users/wjmn/Zotero/storage/7VETUPIZ/4824-imagenet-classification-with-deep-convolutional-neural-networ.html:text/html}
}

@inproceedings{karpathy_large-scale_2014,
	title = {Large-scale {Video} {Classification} with {Convolutional} {Neural} {Networks}},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html},
	urldate = {2019-05-15},
	author = {Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
	year = {2014},
	pages = {1725--1732},
	file = {Full Text PDF:/Users/wjmn/Zotero/storage/4PBBF648/Karpathy et al. - 2014 - Large-scale Video Classification with Convolutiona.pdf:application/pdf;Snapshot:/Users/wjmn/Zotero/storage/GZZUCXFB/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html:text/html}
}

@article{Lecun1998,
  doi = {10.1109/5.726791},
  url = {https://doi.org/10.1109/5.726791},
  year = {1998},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  author = {Y. Lecun and L. Bottou and Y. Bengio and P. Haffner},
  title = {Gradient-based learning applied to document recognition},
  journal = {Proceedings of the {IEEE}}
}
